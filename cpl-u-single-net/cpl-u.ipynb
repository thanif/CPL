{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(1)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "\n",
    "if ros_path in sys.path:\n",
    "\n",
    "    sys.path.remove(ros_path)\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(tensor):\n",
    "    return tensor[0] + tensor[1]\n",
    "\n",
    "def mul_layer(tensor):\n",
    "    return tensor[0] * tensor[1]\n",
    "\n",
    "def div_layer(tensor):\n",
    "    return tensor[0] / tensor[1]\n",
    "\n",
    "def sub_layer(tensor):\n",
    "    return tensor[0] - tensor[1]\n",
    "\n",
    "def neg_layer(tensor):\n",
    "    return -tensor\n",
    "\n",
    "def cos_layer(tensor):\n",
    "    return tf.math.cos(tensor)\n",
    "\n",
    "def sin_layer(tensor):\n",
    "    return tf.math.sin(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 6 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_image (InputLayer)         [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 112, 112, 6)  0           left_image[0][0]                 \n",
      "                                                                 right_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 55, 55, 32)   1728        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 55, 55, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 55, 55, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 53, 53, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 53, 53, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 53, 53, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 53, 53, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 53, 53, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 53, 53, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 26, 26, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 26, 26, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 26, 26, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 26, 26, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 24, 24, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24, 24, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 24, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 11, 11, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 11, 11, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 11, 11, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 11, 11, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 11, 11, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 11, 11, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 11, 11, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 11, 11, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 11, 11, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 11, 11, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 11, 11, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 11, 11, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 11, 11, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 11, 11, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 11, 11, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 11, 11, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 11, 11, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 11, 11, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 11, 11, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 11, 11, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 11, 11, 64)   16384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 11, 11, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 11, 11, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 11, 11, 48)   12288       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 11, 11, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 11, 11, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 11, 11, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 11, 11, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 11, 11, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 11, 11, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 11, 11, 64)   16384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 11, 11, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 11, 11, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 11, 11, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 11, 11, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 11, 11, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 11, 11, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 11, 11, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 11, 11, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 11, 11, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 11, 11, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 11, 11, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 11, 11, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 11, 11, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 48)   13824       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 11, 11, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 11, 11, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 11, 11, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 11, 11, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 11, 11, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 11, 11, 288)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 11, 11, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 11, 11, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 11, 11, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 11, 11, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 11, 11, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 11, 11, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 11, 11, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 11, 11, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 11, 11, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 11, 11, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 11, 11, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 11, 11, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 11, 11, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 11, 11, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 11, 11, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 11, 11, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 11, 11, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 5, 5, 384)    995328      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 5, 5, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 5, 5, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 5, 5, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5, 5, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 5, 5, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 288)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 5, 5, 128)    98304       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 5, 5, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5, 5, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 5, 5, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 5, 5, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 5, 5, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 5, 5, 128)    98304       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 5, 5, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 5, 5, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 5, 5, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 5, 5, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 5, 5, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 5, 5, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 5, 5, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 5, 5, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 5, 5, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 5, 5, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5, 5, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 5, 5, 768)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 5, 5, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 5, 5, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 5, 5, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 5, 5, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 5, 5, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 5, 5, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 5, 5, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 5, 5, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 5, 5, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 5, 5, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 5, 5, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 5, 5, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 5, 5, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 5, 5, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 5, 5, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 5, 5, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 5, 5, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 5, 5, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5, 5, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5, 5, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 5, 5, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 5, 5, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 5, 5, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 5, 5, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 5, 5, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 5, 5, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 5, 5, 768)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 5, 5, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 5, 5, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 5, 5, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 5, 5, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 5, 5, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 5, 5, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 5, 5, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 5, 5, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 5, 5, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 5, 5, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 5, 5, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 5, 5, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 5, 5, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 5, 5, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 5, 5, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 5, 5, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 5, 5, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 5, 5, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 5, 5, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 5, 5, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 5, 5, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 5, 5, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 5, 5, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 5, 5, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5, 5, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 5, 5, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 5, 5, 768)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 5, 5, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 5, 5, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 5, 5, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 5, 5, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 5, 5, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 5, 5, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 5, 5, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 5, 5, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 5, 5, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5, 5, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5, 5, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 5, 5, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 5, 5, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 5, 5, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 5, 5, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 5, 5, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 5, 5, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 5, 5, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 5, 5, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 5, 5, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 5, 5, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 5, 5, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 5, 5, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 5, 5, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 5, 5, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 5, 5, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 5, 5, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 5, 5, 768)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 5, 5, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 5, 5, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 5, 5, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 5, 5, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 5, 5, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 5, 5, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 5, 5, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 5, 5, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 5, 5, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 5, 5, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5, 5, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 5, 5, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 5, 5, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 5, 5, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 5, 5, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 5, 5, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 5, 5, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 5, 5, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 5, 5, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)    0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 2, 2, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 2, 2, 448)    573440      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 2, 2, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 384)    491520      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 2, 2, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 2, 2, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 1280)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 320)    409600      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2, 2, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 2, 2, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 2, 2, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2, 2, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 2, 2, 2048)   0           activation_76[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 448)    917504      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 2, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 2, 2, 384)    786432      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2, 2, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 2, 2, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 2, 2, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 2, 2, 2048)   0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 2, 2, 320)    655360      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 2, 2, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2, 2, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 2, 2, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2, 2, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2, 2, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 2, 2, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 2, 2, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2, 2, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 2, 2, 2048)   0           activation_85[0][0]              \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "phi-flattened (Flatten)         (None, 8192)         0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_fx (Dense)                (None, 84)           10164       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_baseline (Dense)          (None, 84)           10164       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fx (Dense)                      (None, 1)            85          dense_fx[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "baseline (Dense)                (None, 1)            85          dense_baseline[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_disparity (Dense)         (None, 84)           10164       dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_fy (Dense)                (None, 84)           10164       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_v0 (Dense)                (None, 84)           10164       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "disparity (Dense)               (None, 1)            85          dense_disparity[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           fx[0][0]                         \n",
      "                                                                 baseline[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_v (Dense)                 (None, 84)           10164       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fy (Dense)                      (None, 1)            85          dense_fy[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "v0 (Dense)                      (None, 1)            85          dense_v0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_pitch (Dense)             (None, 84)           10164       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "xCam (Lambda)                   (None, 1)            0           lambda[0][0]                     \n",
      "                                                                 disparity[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "v (Dense)                       (None, 1)            85          dense_v[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_u0 (Dense)                (None, 84)           10164       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pitch (Dense)                   (None, 1)            85          dense_pitch[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 fy[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           v0[0][0]                         \n",
      "                                                                 v[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dense_u (Dense)                 (None, 84)           10164       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "u0 (Dense)                      (None, 1)            85          dense_u0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zCam (Lambda)                   (None, 1)            0           lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 fx[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "u (Dense)                       (None, 1)            85          dense_u[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1)            0           xCam[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_tx (Dense)                (None, 84)           10164       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_ty (Dense)                (None, 84)           10164       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_tz (Dense)                (None, 84)           10164       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1)            0           zCam[0][0]                       \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           u[0][0]                          \n",
      "                                                                 u0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1)            0           zCam[0][0]                       \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 1)            85          dense_tx[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            85          dense_ty[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Dense)                       (None, 1)            85          dense_tz[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           lambda_6[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "yCam (Lambda)                   (None, 1)            0           lambda_3[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1)            0           lambda_11[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "xWorld (Lambda)                 (None, 1)            0           lambda_10[0][0]                  \n",
      "                                                                 x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "yWorld (Lambda)                 (None, 1)            0           yCam[0][0]                       \n",
      "                                                                 y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "zWorld (Lambda)                 (None, 1)            0           lambda_16[0][0]                  \n",
      "                                                                 z[0][0]                          \n",
      "==================================================================================================\n",
      "Total params: 33,724,556\n",
      "Trainable params: 33,690,124\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# feature extraction from left image\n",
    "left_img = Input(shape = (112,112,3), name=\"left_image\")\n",
    "\n",
    "# feature extraction from right image\n",
    "right_img = Input(shape = (112,112,3), name=\"right_image\")\n",
    "\n",
    "concat = concatenate([left_img, right_img])\n",
    "\n",
    "phi_model = InceptionV3(weights=None, include_top=False, input_tensor=concat, input_shape=(112,112,6))\n",
    "phi_features = phi_model.output\n",
    "flat = Flatten(name='phi-flattened')(phi_features)\n",
    "\n",
    "\n",
    "# fx\n",
    "dense_1 = Dense(120, activation = 'relu')(flat)\n",
    "dense_2 = Dense(84, activation = 'relu', name='dense_fx')(dense_1)\n",
    "pred_fx = Dense(1, name='fx')(dense_2)\n",
    "\n",
    "# fy\n",
    "dense_3 = Dense(120, activation = 'relu')(flat)\n",
    "dense_4 = Dense(84, activation = 'relu', name='dense_fy')(dense_3)\n",
    "pred_fy = Dense(1, name='fy')(dense_4)\n",
    "\n",
    "# u0\n",
    "dense_5 = Dense(120, activation = 'relu')(flat)\n",
    "dense_6 = Dense(84, activation = 'relu', name='dense_u0')(dense_5)\n",
    "pred_u0 = Dense(1, name='u0')(dense_6)\n",
    "\n",
    "# v0\n",
    "dense_7 = Dense(120, activation = 'relu')(flat)\n",
    "dense_8 = Dense(84, activation = 'relu', name='dense_v0')(dense_7)\n",
    "pred_v0 = Dense(1, name='v0')(dense_8)\n",
    "\n",
    "# baseline\n",
    "dense_9 = Dense(120, activation = 'relu')(flat)\n",
    "dense_10 = Dense(84, activation = 'relu', name='dense_baseline')(dense_9)\n",
    "pred_baseline = Dense(1, name='baseline')(dense_10)\n",
    "\n",
    "# tx\n",
    "dense_11 = Dense(120, activation = 'relu')(flat)\n",
    "dense_12 = Dense(84, activation = 'relu', name='dense_tx')(dense_11)\n",
    "pred_x = Dense(1, name='x')(dense_12)\n",
    "\n",
    "# ty\n",
    "dense_13 = Dense(120, activation = 'relu')(flat)\n",
    "dense_14 = Dense(84, activation = 'relu', name='dense_ty')(dense_13)\n",
    "pred_y = Dense(1, name='y')(dense_14)\n",
    "\n",
    "# tz\n",
    "dense_15 = Dense(120, activation = 'relu')(flat)\n",
    "dense_16 = Dense(84, activation = 'relu', name='dense_tz')(dense_15)\n",
    "pred_z = Dense(1, name='z')(dense_16)\n",
    "\n",
    "# pitch\n",
    "dense_17 = Dense(120, activation = 'relu')(flat)\n",
    "dense_18 = Dense(84, activation = 'relu', name='dense_pitch')(dense_17)\n",
    "pred_pitch = Dense(1, name='pitch')(dense_18)\n",
    "\n",
    "# u\n",
    "dense_19 = Dense(120, activation = 'relu')(flat)\n",
    "dense_20 = Dense(84, activation = 'relu', name='dense_u')(dense_19)\n",
    "pred_u = Dense(1, name='u')(dense_20)\n",
    "\n",
    "# v\n",
    "dense_21 = Dense(120, activation = 'relu')(flat)\n",
    "dense_22 = Dense(84, activation = 'relu', name='dense_v')(dense_21)\n",
    "pred_v = Dense(1, name='v')(dense_22)\n",
    "\n",
    "# disparity\n",
    "dense_23 = Dense(120, activation = 'relu')(flat)\n",
    "dense_24 = Dense(84, activation = 'relu', name='dense_disparity')(dense_23)\n",
    "pred_disparity = Dense(1, name='disparity')(dense_24)\n",
    "\n",
    "# xCam = (self.intrinsic.fx * self.extrinsic.baseline) / disparity\n",
    "mul_1 = Lambda(mul_layer)([pred_fx, pred_baseline])\n",
    "xCam = Lambda(div_layer, name='xCam')([mul_1, pred_disparity])\n",
    "\n",
    "# yCam = - (xCam / self.intrinsic.fx) * (u - self.intrinsic.u0)\n",
    "div_1 = Lambda(div_layer)([xCam, pred_fx])\n",
    "sub_1 = Lambda(sub_layer)([pred_u, pred_u0])\n",
    "yCam = Lambda(mul_layer, name='yCam')([Lambda(neg_layer)(div_1), sub_1])\n",
    "\n",
    "# zCam = (xCam / self.intrinsic.fy) * (self.intrinsic.v0 - v)\n",
    "div_2 = Lambda(div_layer)([xCam, pred_fy])\n",
    "sub_2 = Lambda(sub_layer)([pred_v0, pred_v])\n",
    "zCam = Lambda(mul_layer, name='zCam')([div_2, sub_2])\n",
    "\n",
    "# Y = yCam + self.extrinsic.y\n",
    "pred_yWorld = Lambda(add_layer, name='yWorld')([yCam, pred_y])\n",
    "\n",
    "# X = xCam * math.cos(self.extrinsic.pitch) + zCam * math.sin(self.extrinsic.pitch) + self.extrinsic.x\n",
    "mul_2 = Lambda(mul_layer)([xCam, Lambda(cos_layer)(pred_pitch)])\n",
    "mul_3 = Lambda(mul_layer)([zCam, Lambda(sin_layer)(pred_pitch)])\n",
    "add_1 = Lambda(add_layer)([mul_2, mul_3])\n",
    "pred_xWorld = Lambda(add_layer, name='xWorld')([add_1, pred_x])\n",
    "\n",
    "# Z = - xCam * math.sin(self.extrinsic.pitch) + zCam * math.cos(self.extrinsic.pitch) + self.extrinsic.z\n",
    "mul_4 = Lambda(mul_layer)([Lambda(neg_layer)(xCam), Lambda(sin_layer)(pred_pitch)])\n",
    "mul_5 = Lambda(mul_layer)([zCam, Lambda(cos_layer)(pred_pitch)])\n",
    "add_2 = Lambda(add_layer)([mul_4, mul_5])\n",
    "pred_zWorld = Lambda(add_layer, name='zWorld')([add_2, pred_z])\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[left_img, right_img], outputs=[pred_fx, pred_fy, pred_u0, pred_v0, pred_baseline, pred_disparity, pred_x, pred_y, pred_z, pred_pitch, pred_xWorld,pred_yWorld,pred_zWorld])\n",
    "\n",
    "# set output types\n",
    "target1 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target2 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target3 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target4 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target5 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target6 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target7 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target8 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target9 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target10 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target11 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target12 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target13 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "\n",
    "# get model summary\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"mae\", target_tensors=[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12, target13],optimizer=optimizers.Adam(lr=learning_rate))\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/\"\n",
    "\n",
    "Left_images = np.load(data_path+\"li.npy\")\n",
    "Right_images = np.load(data_path+\"ri.npy\")\n",
    "Fx = np.load(data_path+\"fx.npy\")\n",
    "Fy = np.load(data_path+\"fy.npy\") \n",
    "U0 = np.load(data_path+\"u0.npy\") \n",
    "V0 = np.load(data_path+\"v0.npy\") \n",
    "Baseline = np.load(data_path+\"b.npy\")\n",
    "Disparity = np.load(data_path+\"d.npy\") \n",
    "Tx = np.load(data_path+\"tx.npy\") \n",
    "Ty = np.load(data_path+\"ty.npy\") \n",
    "Tz = np.load(data_path+\"tz.npy\") \n",
    "Pitch = np.load(data_path+\"p.npy\")\n",
    "X = np.load(data_path+\"x.npy\")\n",
    "Y = np.load(data_path+\"y.npy\") \n",
    "Z = np.load(data_path+\"z.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:  86111.9 Test Dataset:  36905.1\n"
     ]
    }
   ],
   "source": [
    "print (\"Training Dataset: \",len(Left_images)*0.7, \"Test Dataset: \", len(Left_images)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86111 samples, validate on 36906 samples\n",
      "Epoch 1/200\n",
      "   32/86111 [..............................] - ETA: 2:59:04 - loss: 905.3947 - fx_loss: 53.1633 - fy_loss: 60.7406 - u0_loss: 53.4648 - v0_loss: 50.6609 - baseline_loss: 77.1480 - disparity_loss: 15.6591 - x_loss: 76.4779 - y_loss: 4.6124 - z_loss: 2.5789 - pitch_loss: 20.5899 - xWorld_loss: 237.8758 - yWorld_loss: 3.8023 - zWorld_loss: 248.6207WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.1537s vs `on_train_batch_begin` time: 1.2868s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1537s vs `on_train_batch_end` time: 2.5528s). Check your callbacks.\n",
      "86111/86111 [==============================] - ETA: 0s - loss: 1112.2118 - fx_loss: 22.6240 - fy_loss: 61.9387 - u0_loss: 2.0068 - v0_loss: 2.3772 - baseline_loss: 83.6987 - disparity_loss: 5.3345 - x_loss: 45.3263 - y_loss: 2.3811 - z_loss: 0.6787 - pitch_loss: 19.1620 - xWorld_loss: 386.6686 - yWorld_loss: 2.2913 - zWorld_loss: 477.7176WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "86111/86111 [==============================] - 1160s 13ms/sample - loss: 1112.2118 - fx_loss: 22.6240 - fy_loss: 61.9387 - u0_loss: 2.0068 - v0_loss: 2.3772 - baseline_loss: 83.6987 - disparity_loss: 5.3345 - x_loss: 45.3263 - y_loss: 2.3811 - z_loss: 0.6787 - pitch_loss: 19.1620 - xWorld_loss: 386.6686 - yWorld_loss: 2.2913 - zWorld_loss: 477.7176 - val_loss: 1085.1513 - val_fx_loss: 50.8266 - val_fy_loss: 75.2855 - val_u0_loss: 26.4663 - val_v0_loss: 31.2198 - val_baseline_loss: 83.8913 - val_disparity_loss: 7.8223 - val_x_loss: 61.2507 - val_y_loss: 1.6716 - val_z_loss: 0.6693 - val_pitch_loss: 18.4256 - val_xWorld_loss: 298.7203 - val_yWorld_loss: 1.6114 - val_zWorld_loss: 427.2561\n",
      "Epoch 2/200\n",
      "86111/86111 [==============================] - 780s 9ms/sample - loss: 1075.6664 - fx_loss: 12.9887 - fy_loss: 57.3138 - u0_loss: 0.7047 - v0_loss: 0.9550 - baseline_loss: 83.6399 - disparity_loss: 2.8366 - x_loss: 42.3140 - y_loss: 1.2621 - z_loss: 0.6660 - pitch_loss: 18.3898 - xWorld_loss: 375.9510 - yWorld_loss: 1.2289 - zWorld_loss: 477.4142 - val_loss: 961.5916 - val_fx_loss: 18.8608 - val_fy_loss: 67.6019 - val_u0_loss: 7.2418 - val_v0_loss: 7.7399 - val_baseline_loss: 83.8172 - val_disparity_loss: 4.0323 - val_x_loss: 45.7852 - val_y_loss: 0.9984 - val_z_loss: 0.6754 - val_pitch_loss: 18.4189 - val_xWorld_loss: 278.2416 - val_yWorld_loss: 0.9882 - val_zWorld_loss: 427.1222\n",
      "Epoch 3/200\n",
      "86111/86111 [==============================] - 873s 10ms/sample - loss: 1074.5210 - fx_loss: 21.1841 - fy_loss: 35.2873 - u0_loss: 0.6144 - v0_loss: 0.9553 - baseline_loss: 83.7064 - disparity_loss: 3.0585 - x_loss: 44.1494 - y_loss: 2.3041 - z_loss: 0.6658 - pitch_loss: 16.5807 - xWorld_loss: 386.8800 - yWorld_loss: 2.0793 - zWorld_loss: 477.0532 - val_loss: 959.2460 - val_fx_loss: 25.7894 - val_fy_loss: 24.8270 - val_u0_loss: 9.6647 - val_v0_loss: 9.6151 - val_baseline_loss: 83.9373 - val_disparity_loss: 3.0892 - val_x_loss: 59.5145 - val_y_loss: 2.8544 - val_z_loss: 0.6677 - val_pitch_loss: 13.7227 - val_xWorld_loss: 297.6518 - val_yWorld_loss: 2.0303 - val_zWorld_loss: 425.9072\n",
      "Epoch 4/200\n",
      "86111/86111 [==============================] - 853s 10ms/sample - loss: 1043.7108 - fx_loss: 15.5258 - fy_loss: 15.5549 - u0_loss: 0.3609 - v0_loss: 0.3777 - baseline_loss: 83.6494 - disparity_loss: 2.8995 - x_loss: 41.0703 - y_loss: 2.4513 - z_loss: 0.6657 - pitch_loss: 15.4117 - xWorld_loss: 387.3927 - yWorld_loss: 1.5496 - zWorld_loss: 476.8058 - val_loss: 1363.0479 - val_fx_loss: 75.8163 - val_fy_loss: 59.7221 - val_u0_loss: 53.2014 - val_v0_loss: 57.9380 - val_baseline_loss: 83.7249 - val_disparity_loss: 2.8356 - val_x_loss: 143.7711 - val_y_loss: 1.5942 - val_z_loss: 0.6681 - val_pitch_loss: 16.5153 - val_xWorld_loss: 359.5830 - val_yWorld_loss: 5.5600 - val_zWorld_loss: 502.3663\n",
      "Epoch 5/200\n",
      "86111/86111 [==============================] - 968s 11ms/sample - loss: 1029.0629 - fx_loss: 11.8038 - fy_loss: 11.6833 - u0_loss: 0.3289 - v0_loss: 0.3100 - baseline_loss: 83.1711 - disparity_loss: 2.7187 - x_loss: 38.9999 - y_loss: 1.3051 - z_loss: 0.6658 - pitch_loss: 15.6702 - xWorld_loss: 384.8772 - yWorld_loss: 1.1957 - zWorld_loss: 476.3304 - val_loss: 973.5328 - val_fx_loss: 22.5339 - val_fy_loss: 16.7913 - val_u0_loss: 3.1605 - val_v0_loss: 17.2565 - val_baseline_loss: 82.4529 - val_disparity_loss: 3.4516 - val_x_loss: 67.7305 - val_y_loss: 0.9299 - val_z_loss: 0.6687 - val_pitch_loss: 21.1849 - val_xWorld_loss: 303.0056 - val_yWorld_loss: 1.5487 - val_zWorld_loss: 432.7573\n",
      "Epoch 6/200\n",
      "86111/86111 [==============================] - 842s 10ms/sample - loss: 984.9512 - fx_loss: 9.5962 - fy_loss: 9.3413 - u0_loss: 0.3824 - v0_loss: 0.3595 - baseline_loss: 79.4927 - disparity_loss: 2.6911 - x_loss: 34.9366 - y_loss: 1.0164 - z_loss: 0.6657 - pitch_loss: 18.3915 - xWorld_loss: 368.9647 - yWorld_loss: 1.0364 - zWorld_loss: 458.0804 - val_loss: 870.5595 - val_fx_loss: 16.4196 - val_fy_loss: 18.7012 - val_u0_loss: 4.0210 - val_v0_loss: 6.6100 - val_baseline_loss: 76.4500 - val_disparity_loss: 2.6308 - val_x_loss: 44.5473 - val_y_loss: 0.8052 - val_z_loss: 0.6677 - val_pitch_loss: 20.7607 - val_xWorld_loss: 269.1398 - val_yWorld_loss: 3.1318 - val_zWorld_loss: 406.6411\n",
      "Epoch 7/200\n",
      "86111/86111 [==============================] - 775s 9ms/sample - loss: 904.1861 - fx_loss: 8.6339 - fy_loss: 8.1787 - u0_loss: 0.5078 - v0_loss: 0.5541 - baseline_loss: 71.0299 - disparity_loss: 3.6511 - x_loss: 29.1314 - y_loss: 0.9070 - z_loss: 0.6657 - pitch_loss: 20.5416 - xWorld_loss: 343.3567 - yWorld_loss: 1.0181 - zWorld_loss: 416.0051 - val_loss: 689.6097 - val_fx_loss: 7.1052 - val_fy_loss: 7.1730 - val_u0_loss: 0.5036 - val_v0_loss: 1.4213 - val_baseline_loss: 66.0563 - val_disparity_loss: 4.7328 - val_x_loss: 24.1152 - val_y_loss: 0.6555 - val_z_loss: 0.6680 - val_pitch_loss: 20.6931 - val_xWorld_loss: 221.5513 - val_yWorld_loss: 0.6739 - val_zWorld_loss: 334.4844\n",
      "Epoch 8/200\n",
      "86111/86111 [==============================] - 802s 9ms/sample - loss: 805.6516 - fx_loss: 7.7055 - fy_loss: 6.9302 - u0_loss: 0.4856 - v0_loss: 0.8655 - baseline_loss: 60.9469 - disparity_loss: 5.9314 - x_loss: 22.0427 - y_loss: 0.7115 - z_loss: 0.6656 - pitch_loss: 20.5568 - xWorld_loss: 308.0440 - yWorld_loss: 1.1197 - zWorld_loss: 369.6415 - val_loss: 674.3636 - val_fx_loss: 18.9021 - val_fy_loss: 14.3060 - val_u0_loss: 5.2988 - val_v0_loss: 9.2104 - val_baseline_loss: 56.1946 - val_disparity_loss: 8.4606 - val_x_loss: 32.4551 - val_y_loss: 0.5510 - val_z_loss: 0.6691 - val_pitch_loss: 20.6103 - val_xWorld_loss: 193.4321 - val_yWorld_loss: 12.5585 - val_zWorld_loss: 301.6593\n",
      "Epoch 9/200\n",
      "86111/86111 [==============================] - 984s 11ms/sample - loss: 758.0294 - fx_loss: 8.6023 - fy_loss: 5.9971 - u0_loss: 0.3584 - v0_loss: 0.8603 - baseline_loss: 52.6503 - disparity_loss: 7.3356 - x_loss: 18.2325 - y_loss: 0.6213 - z_loss: 0.6279 - pitch_loss: 21.4492 - xWorld_loss: 289.5155 - yWorld_loss: 1.1339 - zWorld_loss: 350.6422 - val_loss: 612.7776 - val_fx_loss: 14.6873 - val_fy_loss: 10.7049 - val_u0_loss: 4.8779 - val_v0_loss: 5.0683 - val_baseline_loss: 50.3780 - val_disparity_loss: 8.1398 - val_x_loss: 17.9735 - val_y_loss: 0.7448 - val_z_loss: 0.5515 - val_pitch_loss: 38.7239 - val_xWorld_loss: 182.7504 - val_yWorld_loss: 10.5687 - val_zWorld_loss: 267.5738\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86111/86111 [==============================] - 1259s 15ms/sample - loss: 719.7602 - fx_loss: 7.7332 - fy_loss: 5.3569 - u0_loss: 0.3228 - v0_loss: 0.8534 - baseline_loss: 49.1685 - disparity_loss: 8.8680 - x_loss: 15.8611 - y_loss: 0.5483 - z_loss: 0.5630 - pitch_loss: 21.6187 - xWorld_loss: 273.9725 - yWorld_loss: 1.0861 - zWorld_loss: 333.8036 - val_loss: 777.4974 - val_fx_loss: 25.4525 - val_fy_loss: 9.6587 - val_u0_loss: 10.3628 - val_v0_loss: 4.5751 - val_baseline_loss: 48.3060 - val_disparity_loss: 8.2108 - val_x_loss: 23.6647 - val_y_loss: 0.6895 - val_z_loss: 0.5291 - val_pitch_loss: 26.4910 - val_xWorld_loss: 255.1352 - val_yWorld_loss: 21.3341 - val_zWorld_loss: 343.0139.3326 - v0_loss: 0.8629 - baseline_loss: 49.5406 - disparity_loss: 8.8548 - x_loss: 17.2138 - y_loss - ETA: 3:50 - loss: 675.2566 - fx_loss: 7.9625 - fy_loss: 5.5854 - u0_loss: 0.3329 - v0_loss: 0.8634 - baseline_loss: 49.4489 - disparity_loss: 8.8622 - x_loss: 16.8006 - y_loss: 0.5699 - z_loss: 0.5691 - pitch_loss: 21.7573 - xWorld_loss: 225.0430 - yWorld_loss: 1.1031 - zWorl - ETA: 3:47 - loss: 674.4657 - fx_loss: 7.9582 - fy_loss: 5.5812 - u0_loss: 0.3326 - v0_loss: 0.8616 - baseline_loss: 49.4425 - disparity_loss: 8.8631 - x_loss: 16.7822 - y_loss: 0.5695 - z_loss: 0.5690 - pitch_loss: 21.7586 - xWorld_loss: 224.7631 - yWorld_loss: 1.1016 - zWorld_loss: 335. - ETA: 3:46 - loss: 674.1688 - fx_loss: 7.9552 - fy_loss: 5.5794 - u0_loss: - ETA: 3:00 - loss: 672.0636 - fx_loss: 7.9122 - fy_loss: 5.5171 - u0_loss: 0.3294 - v0_loss: 0.8599 - baseline_loss: 49.3948 - disparity_loss: 8.8578 - x_l - ETA: 2:31 - loss: 666.2360 - fx_loss: 7.8822 - fy_loss: 5.4891 - u0_loss: 0.3284 - v0_loss: 0.8596 - baseline_loss: 49.3437 - disparity_loss: 8.8690 - x_loss: 16.4409 - y_loss: 0.5605 - z_loss: 0.5670 - pitch_loss: 21.7225 - xWorld_los - ETA: 2:19 - loss: 736.4582 - fx_loss: 7.8685 - fy_loss: 5.4760 - u0_loss: 0.3286 - v0_loss: 0.8609 - baseline_loss: 49.3179 - disparity_loss: 8.8551 - x_loss: 16.3928 - y_loss: 0.5596 - z_loss: 0.5668 - pitch_loss: 21.7189 - xWorld_loss: 282.8140 - yWorld_loss: 1.0959 - zWorld_loss - ETA: 2:17 - loss: 735.9155 - fx_loss: - ETA: 1:23 - loss: 738.7014 - fx_loss: 7.8166 - fy_loss: 5.4344 - u0_loss: 0.3264 - v0_loss: 0.8616 - baseline_loss: 49.2551 - disparity_loss: 8.8680 - x_loss: 16.1847 - y_loss: 0.5551  - ETA: 1:01 - loss: 734.1122 - fx_loss: 7.7820 - fy_loss: \n",
      "Epoch 11/200\n",
      "86111/86111 [==============================] - 1296s 15ms/sample - loss: 672.8825 - fx_loss: 6.9672 - fy_loss: 4.7094 - u0_loss: 0.2862 - v0_loss: 0.7985 - baseline_loss: 46.6391 - disparity_loss: 8.3759 - x_loss: 12.6433 - y_loss: 0.4738 - z_loss: 0.5291 - pitch_loss: 20.6926 - xWorld_loss: 262.3059 - yWorld_loss: 1.1532 - zWorld_loss: 307.3016 - val_loss: 935.8767 - val_fx_loss: 35.4634 - val_fy_loss: 19.3274 - val_u0_loss: 26.6087 - val_v0_loss: 27.0278 - val_baseline_loss: 36.8222 - val_disparity_loss: 3.7931 - val_x_loss: 130.2072 - val_y_loss: 0.4969 - val_z_loss: 0.4746 - val_pitch_loss: 20.3126 - val_xWorld_loss: 161.1335 - val_yWorld_loss: 96.8509 - val_zWorld_loss: 377.2477 - u0_loss: 0.3107 - v0_loss: 0.8230 - baseline_loss: 48.0081 - disparity_loss: 8.9981 - x_loss: 13.1205 - y_ - ETA: 9:41 - loss: 737.4522 - fx_loss: 7.4612 - fy_loss: 4.8113 - u0_loss: 0.3102 - v0_loss: 0.8194 - baseline_loss: 47.9842 - disparity_loss: 9.0190 - x_loss: 13.0880 - y_loss: 0.4914 - z_loss: 0.5537 - - ETA: 8:18 - lo - ETA: 2:16 - loss: 683.5055 - fx_loss: 7.2110 - fy_loss: 4.7557 - u0_loss: 0.2937 - v0_loss: 0.8051 - baseline_loss: 47.6370 - disparity_loss: 8.9742 - x_loss: 12.9314 - y_loss: 0.4836 - z_loss: 0.5352 - pitch_loss: 20.7023 - xWorld_los - ETA: 2:04 - loss: 681.4434 - fx_loss: 7.1892 - fy_loss: 4.7583 - u0_loss: 0.2931 - v0_loss: 0.8064 - baseline_loss: 47.5624 - disparity_loss: 8.9227 - x_loss: 12.9157 - y_loss: 0.4839 - z_loss: 0.5346 - pitch_loss: 20.6991 - xWo - ETA: 1:51 - loss: 677.6342 - fx_loss: 7.1602 - fy_loss: 4.7568 - u0_loss: 0.2921 - v0_loss: 0.8030 - baseline_loss: 47.4770 - disparity_loss: 8.8600 - x_loss: 12.8890 - y_loss: 0.4830 - z_loss: 0.5343 - pitch_loss: 20.6986 - xWorld_loss: 263.5038 - yWorld_loss: 1.1 - ETA: 1:45 - loss: 676.2823 - fx_loss: 7.1500 - fy_loss: 4.7557 - u0_loss: 0.2923 - v0_loss: 0.8011 - baseline_loss: 47.4448 - disparity_loss: 8.8329 - x_loss: 12.8962 - y_loss: - ETA: 39s - loss: 679.4701 - fx_loss: 7.0426 - fy_loss: 4.7236 - u0_loss: 0.2890 - v0_loss: 0.7934 - baseline_loss: 46.9189 - disparity_loss: 8.5355 - x_loss: 12.7263 - y_loss: 0.4771 - z_loss: 0.5309 - pitch_loss: 20.6786 - xWorld_loss: 265. - ETA: 33s - loss: 678.8091 - fx_loss: 7.0331 - fy_loss: 4.7227 - u0_loss: 0.2885 - v0_loss: 0.7925 - baseline_loss: 46.8854 - disparity_loss: 8.5126 - - ETA: 18s - loss: 675.7886 - fx_loss: 7.0050 - fy_loss: 4.7155 - u0_loss: 0.2876 - v0_loss: 0.7938 - baseline_loss: 46.7844 - disparity_loss: 8.4487 - x_loss: 12.6920 - y_loss: 0.4756 - z_loss: 0.5299 - pitch_loss: 20.6820 - xWorld_loss: 263.4828 - yWorld_loss: 1.1558 - zWo - ETA: 16s - loss: 676.0308 - fx_loss: 7.0017 - fy_loss: 4.7152 - u0_loss: 0.2874 - v0_loss: 0.7937 - baseline_loss: 46.7759 - disparity_loss: 8.4410 - x_loss: 12.6892 - y_loss: 0.4754\n",
      "Epoch 12/200\n",
      "86111/86111 [==============================] - 1003s 12ms/sample - loss: 634.5890 - fx_loss: 6.4707 - fy_loss: 4.3907 - u0_loss: 0.2543 - v0_loss: 0.7935 - baseline_loss: 30.2549 - disparity_loss: 3.7490 - x_loss: 11.6590 - y_loss: 0.4012 - z_loss: 0.4867 - pitch_loss: 20.6456 - xWorld_loss: 254.9878 - yWorld_loss: 1.3827 - zWorld_loss: 299.1104 - val_loss: 563.1182 - val_fx_loss: 7.9904 - val_fy_loss: 8.3217 - val_u0_loss: 7.1285 - val_v0_loss: 3.8308 - val_baseline_loss: 23.0733 - val_disparity_loss: 3.7896 - val_x_loss: 50.1064 - val_y_loss: 0.9798 - val_z_loss: 0.4733 - val_pitch_loss: 20.7053 - val_xWorld_loss: 148.7009 - val_yWorld_loss: 41.8344 - val_zWorld_loss: 246.1307\n",
      "Epoch 13/200\n",
      "86111/86111 [==============================] - 1013s 12ms/sample - loss: 607.3820 - fx_loss: 5.7442 - fy_loss: 4.3889 - u0_loss: 0.2107 - v0_loss: 0.7633 - baseline_loss: 21.9975 - disparity_loss: 3.7749 - x_loss: 10.1142 - y_loss: 0.3710 - z_loss: 0.4788 - pitch_loss: 20.5335 - xWorld_loss: 249.9758 - yWorld_loss: 1.3365 - zWorld_loss: 287.6920 - val_loss: 796.4956 - val_fx_loss: 9.5490 - val_fy_loss: 17.7071 - val_u0_loss: 12.7848 - val_v0_loss: 13.1842 - val_baseline_loss: 24.8344 - val_disparity_loss: 4.4794 - val_x_loss: 63.8430 - val_y_loss: 1.1915 - val_z_loss: 0.5576 - val_pitch_loss: 20.7194 - val_xWorld_loss: 220.6396 - val_yWorld_loss: 87.2999 - val_zWorld_loss: 319.6611\n",
      "Epoch 14/200\n",
      "86111/86111 [==============================] - 970s 11ms/sample - loss: 608.5898 - fx_loss: 5.9918 - fy_loss: 4.8579 - u0_loss: 0.2059 - v0_loss: 0.8364 - baseline_loss: 18.7597 - disparity_loss: 3.6249 - x_loss: 9.9419 - y_loss: 0.3767 - z_loss: 0.4697 - pitch_loss: 20.5550 - xWorld_loss: 253.3494 - yWorld_loss: 1.2613 - zWorld_loss: 288.3560 - val_loss: 1172.8890 - val_fx_loss: 42.7034 - val_fy_loss: 39.3932 - val_u0_loss: 46.3902 - val_v0_loss: 47.9151 - val_baseline_loss: 12.4336 - val_disparity_loss: 3.1854 - val_x_loss: 159.0002 - val_y_loss: 1.4394 - val_z_loss: 0.2582 - val_pitch_loss: 20.6832 - val_xWorld_loss: 250.5093 - val_yWorld_loss: 303.2723 - val_zWorld_loss: 245.6145\n",
      "Epoch 15/200\n",
      "86111/86111 [==============================] - 858s 10ms/sample - loss: 559.9957 - fx_loss: 4.4924 - fy_loss: 3.7568 - u0_loss: 0.2233 - v0_loss: 0.6808 - baseline_loss: 13.9876 - disparity_loss: 3.7459 - x_loss: 7.9225 - y_loss: 0.2901 - z_loss: 0.2345 - pitch_loss: 20.5009 - xWorld_loss: 235.3795 - yWorld_loss: 1.3625 - zWorld_loss: 267.4152 - val_loss: 752.8498 - val_fx_loss: 14.2819 - val_fy_loss: 17.5948 - val_u0_loss: 23.2151 - val_v0_loss: 27.4504 - val_baseline_loss: 10.9577 - val_disparity_loss: 2.6279 - val_x_loss: 78.0841 - val_y_loss: 0.4971 - val_z_loss: 0.1737 - val_pitch_loss: 20.6675 - val_xWorld_loss: 156.6408 - val_yWorld_loss: 193.9985 - val_zWorld_loss: 206.8795\n",
      "Epoch 16/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86111/86111 [==============================] - 1127s 13ms/sample - loss: 544.5262 - fx_loss: 4.1438 - fy_loss: 3.5187 - u0_loss: 0.1937 - v0_loss: 0.6157 - baseline_loss: 12.0048 - disparity_loss: 3.2768 - x_loss: 7.2309 - y_loss: 0.2738 - z_loss: 0.2216 - pitch_loss: 20.4927 - xWorld_loss: 230.1841 - yWorld_loss: 1.2456 - zWorld_loss: 261.1189 - val_loss: 898.1716 - val_fx_loss: 12.6898 - val_fy_loss: 16.7291 - val_u0_loss: 31.1217 - val_v0_loss: 33.2867 - val_baseline_loss: 8.6245 - val_disparity_loss: 2.5398 - val_x_loss: 91.9234 - val_y_loss: 0.9242 - val_z_loss: 0.1782 - val_pitch_loss: 20.7675 - val_xWorld_loss: 153.3987 - val_yWorld_loss: 325.1123 - val_zWorld_loss: 200.7430\n",
      "Epoch 17/200\n",
      "86111/86111 [==============================] - ETA: 0s - loss: 536.3481 - fx_loss: 4.0842 - fy_loss: 3.2811 - u0_loss: 0.1798 - v0_loss: 0.6565 - baseline_loss: 10.6842 - disparity_loss: 3.0689 - x_loss: 6.8929 - y_loss: 0.2451 - z_loss: 0.2165 - pitch_loss: 20.5302 - xWorld_loss: 229.7173 - yWorld_loss: 1.2164 - zWorld_loss: 255.5727Restoring model weights from the end of the best epoch.\n",
      "86111/86111 [==============================] - 919s 11ms/sample - loss: 536.3481 - fx_loss: 4.0842 - fy_loss: 3.2811 - u0_loss: 0.1798 - v0_loss: 0.6565 - baseline_loss: 10.6842 - disparity_loss: 3.0689 - x_loss: 6.8929 - y_loss: 0.2451 - z_loss: 0.2165 - pitch_loss: 20.5302 - xWorld_loss: 229.7173 - yWorld_loss: 1.2164 - zWorld_loss: 255.5727 - val_loss: 843.9941 - val_fx_loss: 9.6831 - val_fy_loss: 25.2814 - val_u0_loss: 48.1690 - val_v0_loss: 49.5559 - val_baseline_loss: 10.7077 - val_disparity_loss: 7.2926 - val_x_loss: 135.3134 - val_y_loss: 1.4056 - val_z_loss: 0.2285 - val_pitch_loss: 20.7895 - val_xWorld_loss: 253.0869 - val_yWorld_loss: 61.8005 - val_zWorld_loss: 220.5982\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "model_name = 'model_multi_class/'\n",
    "SAVE = \"new_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "# Save\n",
    "output_folder = SAVE + model_name\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "output_log = output_folder + \"Log/\"\n",
    "if not os.path.exists(output_log):\n",
    "    os.makedirs(output_log)\n",
    "\n",
    "output_weight = output_folder + \"Best/\"\n",
    "if not os.path.exists(output_weight):\n",
    "    os.makedirs(output_weight)\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=output_log)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    model_for_saving=model,\n",
    "    filepath=output_weight + \"weights_{epoch:02d}_{val_loss:.2f}.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[Left_images[:int(len(Left_images)*0.7)], Right_images[:int(len(Left_images)*0.7)]],\n",
    "    y=[Fx[:int(len(Left_images)*0.7)], Fy[:int(len(Left_images)*0.7)], U0[:int(len(Left_images)*0.7)], V0[:int(len(Left_images)*0.7)], Baseline[:int(len(Left_images)*0.7)], Disparity[:int(len(Left_images)*0.7)], Tx[:int(len(Left_images)*0.7)], Ty[:int(len(Left_images)*0.7)], Tz[:int(len(Left_images)*0.7)], Pitch[:int(len(Left_images)*0.7)], X[:int(len(Left_images)*0.7)], Y[:int(len(Left_images)*0.7)], Z[:int(len(Left_images)*0.7)]],\n",
    "    batch_size=16,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    validation_data=([Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]], [Fx[int(len(Left_images)*0.7):], Fy[int(len(Left_images)*0.7):], U0[int(len(Left_images)*0.7):], V0[int(len(Left_images)*0.7):], Baseline[int(len(Left_images)*0.7):], Disparity[int(len(Left_images)*0.7):], Tx[int(len(Left_images)*0.7):], Ty[int(len(Left_images)*0.7):], Tz[int(len(Left_images)*0.7):], Pitch[int(len(Left_images)*0.7):], X[int(len(Left_images)*0.7):], Y[int(len(Left_images)*0.7):], Z[int(len(Left_images)*0.7):]]),\n",
    "    callbacks=[tensorboard, checkpointer, early_stopping, csv_logger]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "model.load_weights('./new_logs/20221215-120957/model_multi_class/Best/weights_12_563.12.h5')\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "\n",
    "output = model.predict(\n",
    "    x=[Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]],\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23796, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% Correct')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "th_0 = 0\n",
    "th_1 = 0\n",
    "th_2 = 0\n",
    "th_3 = 0\n",
    "th_4 = 0\n",
    "th_5 = 0\n",
    "\n",
    "percent_correct = []\n",
    "\n",
    "k = 86111\n",
    "\n",
    "for i  in range(np.shape(output)[1]):\n",
    "    \n",
    "    predicted_fov = 2*np.arctan(112/(2*output[0][i][0]))\n",
    "    actual_fov = 2*np.arctan(112/(2*Fx[k]))\n",
    "    \n",
    "    if abs(predicted_fov - actual_fov) <= 0:\n",
    "        \n",
    "        th_0 += 1 \n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 1:\n",
    "        \n",
    "        th_1 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 2:\n",
    "        \n",
    "        th_2 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 3:\n",
    "        \n",
    "        th_3 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 4:\n",
    "        \n",
    "        th_4 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 5:\n",
    "        \n",
    "        th_5 += 1\n",
    "        \n",
    "    k += 1\n",
    "\n",
    "percent_correct.append(th_0/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_1/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_2/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_3/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_4/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_5/np.shape(output)[1]*100)\n",
    "\n",
    "plt.plot([0,1,2,3,4,5],percent_correct)\n",
    "plt.xlabel(\"FOV Error Threshold (degrees)\")\n",
    "plt.ylabel(\"% Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 36277, 36906, 36906, 36906, 36906)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0, th_1, th_2, th_3, th_4, th_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.9829567008074568, 1.0, 1.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0/np.shape(output)[1], th_1/np.shape(output)[1], th_2/np.shape(output)[1], th_3/np.shape(output)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 1.7203366214287756, 'fy': 1.4489545759413487, 'u0': 0.1817660600242544, 'v0': 0.7168212601428754, 'baseline': 2.0212013848911194, 'disparity': 0.6347296211487513, 'x': 0.33405547099747485, 'y': 0.22606784079751763, 'z': 0.553045160380867, 'pitch': 17.526308870852585, 'xworld': 15.08453204150905, 'yworld': 1.7003544984662247, 'zworld': 16.06738446825849}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math \n",
    "\n",
    "def normalize(x):\n",
    "    \n",
    "    return (math.atan(x) + 3.14/2) / 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.8843963428617811, 'fy': 0.9114423831145054, 'u0': 0.7282263956665703, 'v0': 0.6373140539925413, 'baseline': 0.8732234974660816, 'disparity': 0.6210554186664111, 'x': 0.7347879211851821, 'y': 0.7188259027103718, 'z': 0.7334200235350675, 'pitch': 0.9524821243477615, 'xworld': 0.9656370923642681, 'yworld': 0.9002662165885574, 'zworld': 0.9758289870726622}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fx - actual_fx))\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fy - actual_fy))\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_u0 - actual_u0))\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_v0 - actual_v0))\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_baseline - actual_baseline))\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_disparity - actual_disparity))\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tx - actual_tx))\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_ty - actual_ty))\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tz - actual_tz))\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_pitch - actual_pitch))\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_x - actual_x))\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_y - actual_y))\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_z - actual_z))\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.02463748515183124, 'fy': 0.02831664666868909, 'u0': 0.02294115505902206, 'v0': 0.017306714223111433, 'baseline': 0.12978495358614217, 'disparity': 0.01774838413167217, 'x': 0.055404124404127224, 'y': 0.03276949154431778, 'z': 0.07197428159761873, 'pitch': 0.019904880198233815, 'xworld': 0.08421927624064439, 'yworld': 0.018279980683418177, 'zworld': 0.1307571785332731}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "min_fx = 1.9073486e-06\n",
    "max_fx = 3214.9907\n",
    "\n",
    "min_fy = 2.9563904e-05\n",
    "max_fy = 2051.209\n",
    "\n",
    "min_u0 = 1.9073486e-05\n",
    "max_u0 = 2178.9983\n",
    "\n",
    "min_v0 = 3.8146973e-06\n",
    "max_v0 = 2385.7239\n",
    "\n",
    "min_baseline = 4.7683716e-06\n",
    "max_baseline = 22.68721567997021\n",
    "\n",
    "min_disparity = 9.536743e-07\n",
    "max_disparity = 134.60031\n",
    "\n",
    "min_tx = 2.384185791015625e-06\n",
    "max_tx = 22.68721567997021\n",
    "\n",
    "min_ty = 2.3841858e-07\n",
    "max_ty = 33.11693576309983\n",
    "\n",
    "min_tz = 2.3841858e-06\n",
    "max_tz = 17.20185265614626\n",
    "\n",
    "min_pitch = 4.57763671875e-05\n",
    "max_pitch = 4502.9224\n",
    "\n",
    "min_xw = 5.219264654243716e-06\n",
    "max_xw = 386.4486\n",
    "\n",
    "min_yw = 3.8146973e-06\n",
    "max_yw = 1835.1849\n",
    "\n",
    "min_zw = 0.00011349\n",
    "max_zw = 339.17166\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fx - actual_fx) - min_fx)/(max_fx - min_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fy - actual_fy) - min_fy)/(max_fy - min_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_u0 - actual_u0) - min_u0)/(max_u0 - min_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_v0 - actual_v0) - min_v0)/(max_v0 - min_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_baseline - actual_baseline) - min_baseline)/(max_baseline - min_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_disparity - actual_disparity) - min_disparity)/(max_disparity - min_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tx - actual_tx) - min_tx)/(max_tx - min_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_ty - actual_ty) - min_ty)/(max_ty - min_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tz - actual_tz) - min_tz)/(max_tz - min_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_pitch - actual_pitch) - min_pitch)/(max_pitch - min_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_x - actual_x) - min_xw)/(max_xw - min_xw)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_y - actual_y) - min_yw)/(max_yw - min_yw)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_z - actual_z) - min_zw)/(max_zw - min_zw)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.13471030157107214, 'fy': 0.140294650105165, 'u0': 0.1273139933483438, 'v0': 0.0684165966402708, 'baseline': -0.27466576643376706, 'disparity': -0.34537400269033125, 'x': -0.5965470941346421, 'y': 2.2410586293444212, 'z': -0.8206971405645647, 'pitch': -1.6725253668041673, 'xworld': -1.6174449868116738, 'yworld': 95.6907214749043, 'zworld': 5.5329794944341}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "mean_fx = 59.32098482132037\n",
    "\n",
    "mean_fy = 59.32098482132037\n",
    "\n",
    "mean_u0 = 56.0\n",
    "\n",
    "mean_v0 = 56.0\n",
    "\n",
    "mean_baseline = -84.00701782907929\n",
    "\n",
    "mean_disparity = -10.972388226877689\n",
    "\n",
    "mean_tx = -84.00701782907929\n",
    "\n",
    "mean_ty = 0.4372459762640221\n",
    "\n",
    "mean_tz = -0.5766162683574485\n",
    "\n",
    "mean_pitch = -12.380371755270145\n",
    "\n",
    "mean_xw = -91.94288567681566\n",
    "\n",
    "mean_yw = 0.4372459762640221\n",
    "\n",
    "mean_zw = 44.48843272766856\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 86111\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx) / mean_fx\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy) / mean_fy\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0) / mean_u0\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0) / mean_v0\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline) / mean_baseline\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity) / mean_disparity\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx) / mean_tx\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty) / mean_ty\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz) / mean_tz\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch) / mean_pitch\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x) / mean_xw\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y) / mean_yw\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z) / mean_zw\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
