{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(1)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "\n",
    "if ros_path in sys.path:\n",
    "\n",
    "    sys.path.remove(ros_path)\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(tensor):\n",
    "    return tensor[0] + tensor[1]\n",
    "\n",
    "def mul_layer(tensor):\n",
    "    return tensor[0] * tensor[1]\n",
    "\n",
    "def div_layer(tensor):\n",
    "    return tensor[0] / tensor[1]\n",
    "\n",
    "def sub_layer(tensor):\n",
    "    return tensor[0] - tensor[1]\n",
    "\n",
    "def neg_layer(tensor):\n",
    "    return -tensor\n",
    "\n",
    "def cos_layer(tensor):\n",
    "    return tf.math.cos(tensor)\n",
    "\n",
    "def sin_layer(tensor):\n",
    "    return tf.math.sin(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 6 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_image (InputLayer)         [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 112, 112, 6)  0           left_image[0][0]                 \n",
      "                                                                 right_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 55, 55, 32)   1728        concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 55, 55, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 55, 55, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 53, 53, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 53, 53, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 53, 53, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 53, 53, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 53, 53, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 53, 53, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 26, 26, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 26, 26, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 26, 26, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 26, 26, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 24, 24, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 24, 24, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 24, 24, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 11, 11, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 11, 11, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 11, 11, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 11, 11, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 11, 11, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 11, 11, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 11, 11, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 11, 11, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 11, 11, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 11, 11, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 11, 11, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 11, 11, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 11, 11, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 11, 11, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 11, 11, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 11, 11, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 11, 11, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 11, 11, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 11, 11, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 11, 11, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 11, 11, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 11, 11, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 11, 11, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 11, 11, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 11, 11, 64)   16384       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 11, 11, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 11, 11, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 11, 11, 48)   12288       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 11, 11, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 11, 11, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 11, 11, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 11, 11, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 11, 11, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 11, 11, 256)  0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 11, 11, 64)   16384       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 11, 11, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 11, 11, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 11, 11, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 11, 11, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 11, 11, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 11, 11, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 11, 11, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 11, 11, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 11, 11, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 11, 11, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 11, 11, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 11, 11, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 11, 11, 64)   18432       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 11, 11, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 11, 11, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 11, 11, 48)   13824       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 11, 11, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 11, 11, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 11, 11, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 11, 11, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 11, 11, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 11, 11, 288)  0           concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 11, 11, 64)   18432       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 11, 11, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 11, 11, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 11, 11, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 11, 11, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 11, 11, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 11, 11, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 11, 11, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 11, 11, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 11, 11, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 11, 11, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 11, 11, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 11, 11, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 11, 11, 64)   18432       concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 11, 11, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 11, 11, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 11, 11, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 11, 11, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 11, 11, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 5, 5, 384)    995328      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 5, 5, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 5, 5, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 5, 5, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 5, 5, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 5, 5, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 5, 5, 288)    0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 5, 5, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 5, 5, 128)    98304       concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 5, 5, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 5, 5, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 5, 5, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 5, 5, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 5, 5, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 5, 5, 128)    98304       concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 5, 5, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 5, 5, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 5, 5, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 5, 5, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 5, 5, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 5, 5, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 5, 5, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 5, 5, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 5, 5, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 5, 5, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 5, 5, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 5, 5, 768)    0           concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 5, 5, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 5, 5, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 5, 5, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 5, 5, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 5, 5, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 5, 5, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 5, 5, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 5, 5, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 5, 5, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 5, 5, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 5, 5, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 5, 5, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 5, 5, 160)    122880      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 5, 5, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 5, 5, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 5, 5, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 5, 5, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 5, 5, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 5, 5, 160)    122880      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 5, 5, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 5, 5, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 5, 5, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 5, 5, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 5, 5, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 5, 5, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 5, 5, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 5, 5, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 5, 5, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 5, 5, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 5, 5, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 5, 5, 768)    0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 5, 5, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 5, 5, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 5, 5, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 5, 5, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 5, 5, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 5, 5, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 5, 5, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 5, 5, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 5, 5, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 5, 5, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 5, 5, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 5, 5, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 5, 5, 160)    122880      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 5, 5, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 5, 5, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 5, 5, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 5, 5, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 5, 5, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 5, 5, 160)    122880      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 5, 5, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 5, 5, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 5, 5, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 5, 5, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 5, 5, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 5, 5, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 5, 5, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 5, 5, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 5, 5, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 5, 5, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 5, 5, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 5, 5, 768)    0           concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 5, 5, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 5, 5, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 5, 5, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 5, 5, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 5, 5, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 5, 5, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 5, 5, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 5, 5, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 5, 5, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 5, 5, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 5, 5, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 5, 5, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 5, 5, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 5, 5, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 5, 5, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 5, 5, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 5, 5, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 5, 5, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 5, 5, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 5, 5, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 5, 5, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 5, 5, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 5, 5, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 5, 5, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 5, 5, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 5, 5, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 5, 5, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 5, 5, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 5, 5, 768)    0           concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 5, 5, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 5, 5, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 5, 5, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 5, 5, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 5, 5, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 5, 5, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 5, 5, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 5, 5, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 5, 5, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 5, 5, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 5, 5, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 5, 5, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 5, 5, 192)    576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 5, 5, 192)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 5, 5, 192)    258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 5, 5, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 5, 5, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 5, 5, 192)    258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 5, 5, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 5, 5, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 5, 5, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 5, 5, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 2, 2, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 2, 2, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 2, 2, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 2, 2, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 2, 2, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 2, 2, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 2, 2, 768)    0           concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 2, 2, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 2, 2, 448)    573440      concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 2, 2, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 2, 2, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 2, 2, 384)    491520      concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 2, 2, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 2, 2, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 2, 2, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 2, 2, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 2, 2, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 2, 2, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 2, 2, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 2, 2, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 2, 2, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 2, 2, 1280)   0           concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 2, 2, 320)    409600      concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 2, 2, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 2, 2, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 2, 2, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 2, 2, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 2, 2, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 2, 2, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 2, 2, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 2, 2, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 2, 2, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 2, 2, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 2, 2, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 2, 2, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 2, 2, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 2, 2, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 2, 2, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 2, 2, 2048)   0           activation_264[0][0]             \n",
      "                                                                 concatenate_40[0][0]             \n",
      "                                                                 concatenate_41[0][0]             \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 2, 2, 448)    917504      concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 2, 2, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 2, 2, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 2, 2, 384)    786432      concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 2, 2, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 2, 2, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 2, 2, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 2, 2, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 2, 2, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 2, 2, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 2, 2, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 2, 2, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 2, 2, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 2, 2, 2048)   0           concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 2, 2, 320)    655360      concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 2, 2, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 2, 2, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 2, 2, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 2, 2, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 2, 2, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 2, 2, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 2, 2, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 2, 2, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 2, 2, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 2, 2, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 2, 2, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 2, 2, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 2, 2, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 2, 2, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 2, 2, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 2, 2, 2048)   0           activation_273[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "                                                                 concatenate_44[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "phi-flattened (Flatten)         (None, 8192)         0           concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_fx (Dense)                (None, 84)           10164       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_baseline (Dense)          (None, 84)           10164       dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fx (Dense)                      (None, 1)            85          dense_fx[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "baseline (Dense)                (None, 1)            85          dense_baseline[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_disparity (Dense)         (None, 84)           10164       dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_fy (Dense)                (None, 84)           10164       dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_v0 (Dense)                (None, 84)           10164       dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "disparity (Dense)               (None, 1)            85          dense_disparity[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1)            0           fx[0][0]                         \n",
      "                                                                 baseline[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_v (Dense)                 (None, 84)           10164       dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fy (Dense)                      (None, 1)            85          dense_fy[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "v0 (Dense)                      (None, 1)            85          dense_v0[0][0]                   \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dense_pitch (Dense)             (None, 84)           10164       dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "xCam (Lambda)                   (None, 1)            0           lambda_34[0][0]                  \n",
      "                                                                 disparity[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "v (Dense)                       (None, 1)            85          dense_v[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_u0 (Dense)                (None, 84)           10164       dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pitch (Dense)                   (None, 1)            85          dense_pitch[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 fy[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1)            0           v0[0][0]                         \n",
      "                                                                 v[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dense_u (Dense)                 (None, 84)           10164       dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "u0 (Dense)                      (None, 1)            85          dense_u0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zCam (Lambda)                   (None, 1)            0           lambda_38[0][0]                  \n",
      "                                                                 lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 fx[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "u (Dense)                       (None, 1)            85          dense_u[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1)            0           xCam[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_tx (Dense)                (None, 84)           10164       dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_ty (Dense)                (None, 84)           10164       dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_tz (Dense)                (None, 84)           10164       dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1)            0           zCam[0][0]                       \n",
      "                                                                 lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1)            0           lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1)            0           u[0][0]                          \n",
      "                                                                 u0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1)            0           lambda_46[0][0]                  \n",
      "                                                                 lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1)            0           zCam[0][0]                       \n",
      "                                                                 lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 1)            85          dense_tx[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            85          dense_ty[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Dense)                       (None, 1)            85          dense_tz[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1)            0           lambda_40[0][0]                  \n",
      "                                                                 lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "yCam (Lambda)                   (None, 1)            0           lambda_37[0][0]                  \n",
      "                                                                 lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1)            0           lambda_45[0][0]                  \n",
      "                                                                 lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "xWorld (Lambda)                 (None, 1)            0           lambda_44[0][0]                  \n",
      "                                                                 x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "yWorld (Lambda)                 (None, 1)            0           yCam[0][0]                       \n",
      "                                                                 y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "zWorld (Lambda)                 (None, 1)            0           lambda_50[0][0]                  \n",
      "                                                                 z[0][0]                          \n",
      "==================================================================================================\n",
      "Total params: 33,724,556\n",
      "Trainable params: 33,690,124\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# feature extraction from left image\n",
    "left_img = Input(shape = (112,112,3), name=\"left_image\")\n",
    "\n",
    "# feature extraction from right image\n",
    "right_img = Input(shape = (112,112,3), name=\"right_image\")\n",
    "\n",
    "concat = concatenate([left_img, right_img])\n",
    "\n",
    "phi_model = InceptionV3(weights=None, include_top=False, input_tensor=concat, input_shape=(112,112,6))\n",
    "phi_features = phi_model.output\n",
    "flat = Flatten(name='phi-flattened')(phi_features)\n",
    "\n",
    "\n",
    "# fx\n",
    "dense_1 = Dense(120, activation = 'relu')(flat)\n",
    "dense_2 = Dense(84, activation = 'relu', name='dense_fx')(dense_1)\n",
    "pred_fx = Dense(1, name='fx')(dense_2)\n",
    "\n",
    "# fy\n",
    "dense_3 = Dense(120, activation = 'relu')(flat)\n",
    "dense_4 = Dense(84, activation = 'relu', name='dense_fy')(dense_3)\n",
    "pred_fy = Dense(1, name='fy')(dense_4)\n",
    "\n",
    "# u0\n",
    "dense_5 = Dense(120, activation = 'relu')(flat)\n",
    "dense_6 = Dense(84, activation = 'relu', name='dense_u0')(dense_5)\n",
    "pred_u0 = Dense(1, name='u0')(dense_6)\n",
    "\n",
    "# v0\n",
    "dense_7 = Dense(120, activation = 'relu')(flat)\n",
    "dense_8 = Dense(84, activation = 'relu', name='dense_v0')(dense_7)\n",
    "pred_v0 = Dense(1, name='v0')(dense_8)\n",
    "\n",
    "# baseline\n",
    "dense_9 = Dense(120, activation = 'relu')(flat)\n",
    "dense_10 = Dense(84, activation = 'relu', name='dense_baseline')(dense_9)\n",
    "pred_baseline = Dense(1, name='baseline')(dense_10)\n",
    "\n",
    "# tx\n",
    "dense_11 = Dense(120, activation = 'relu')(flat)\n",
    "dense_12 = Dense(84, activation = 'relu', name='dense_tx')(dense_11)\n",
    "pred_x = Dense(1, name='x')(dense_12)\n",
    "\n",
    "# ty\n",
    "dense_13 = Dense(120, activation = 'relu')(flat)\n",
    "dense_14 = Dense(84, activation = 'relu', name='dense_ty')(dense_13)\n",
    "pred_y = Dense(1, name='y')(dense_14)\n",
    "\n",
    "# tz\n",
    "dense_15 = Dense(120, activation = 'relu')(flat)\n",
    "dense_16 = Dense(84, activation = 'relu', name='dense_tz')(dense_15)\n",
    "pred_z = Dense(1, name='z')(dense_16)\n",
    "\n",
    "# pitch\n",
    "dense_17 = Dense(120, activation = 'relu')(flat)\n",
    "dense_18 = Dense(84, activation = 'relu', name='dense_pitch')(dense_17)\n",
    "pred_pitch = Dense(1, name='pitch')(dense_18)\n",
    "\n",
    "# u\n",
    "dense_19 = Dense(120, activation = 'relu')(flat)\n",
    "dense_20 = Dense(84, activation = 'relu', name='dense_u')(dense_19)\n",
    "pred_u = Dense(1, name='u')(dense_20)\n",
    "\n",
    "# v\n",
    "dense_21 = Dense(120, activation = 'relu')(flat)\n",
    "dense_22 = Dense(84, activation = 'relu', name='dense_v')(dense_21)\n",
    "pred_v = Dense(1, name='v')(dense_22)\n",
    "\n",
    "# disparity\n",
    "dense_23 = Dense(120, activation = 'relu')(flat)\n",
    "dense_24 = Dense(84, activation = 'relu', name='dense_disparity')(dense_23)\n",
    "pred_disparity = Dense(1, name='disparity')(dense_24)\n",
    "\n",
    "# xCam = (self.intrinsic.fx * self.extrinsic.baseline) / disparity\n",
    "mul_1 = Lambda(mul_layer)([pred_fx, pred_baseline])\n",
    "xCam = Lambda(div_layer, name='xCam')([mul_1, pred_disparity])\n",
    "\n",
    "# yCam = - (xCam / self.intrinsic.fx) * (u - self.intrinsic.u0)\n",
    "div_1 = Lambda(div_layer)([xCam, pred_fx])\n",
    "sub_1 = Lambda(sub_layer)([pred_u, pred_u0])\n",
    "yCam = Lambda(mul_layer, name='yCam')([Lambda(neg_layer)(div_1), sub_1])\n",
    "\n",
    "# zCam = (xCam / self.intrinsic.fy) * (self.intrinsic.v0 - v)\n",
    "div_2 = Lambda(div_layer)([xCam, pred_fy])\n",
    "sub_2 = Lambda(sub_layer)([pred_v0, pred_v])\n",
    "zCam = Lambda(mul_layer, name='zCam')([div_2, sub_2])\n",
    "\n",
    "# Y = yCam + self.extrinsic.y\n",
    "pred_yWorld = Lambda(add_layer, name='yWorld')([yCam, pred_y])\n",
    "\n",
    "# X = xCam * math.cos(self.extrinsic.pitch) + zCam * math.sin(self.extrinsic.pitch) + self.extrinsic.x\n",
    "mul_2 = Lambda(mul_layer)([xCam, Lambda(cos_layer)(pred_pitch)])\n",
    "mul_3 = Lambda(mul_layer)([zCam, Lambda(sin_layer)(pred_pitch)])\n",
    "add_1 = Lambda(add_layer)([mul_2, mul_3])\n",
    "pred_xWorld = Lambda(add_layer, name='xWorld')([add_1, pred_x])\n",
    "\n",
    "# Z = - xCam * math.sin(self.extrinsic.pitch) + zCam * math.cos(self.extrinsic.pitch) + self.extrinsic.z\n",
    "mul_4 = Lambda(mul_layer)([Lambda(neg_layer)(xCam), Lambda(sin_layer)(pred_pitch)])\n",
    "mul_5 = Lambda(mul_layer)([zCam, Lambda(cos_layer)(pred_pitch)])\n",
    "add_2 = Lambda(add_layer)([mul_4, mul_5])\n",
    "pred_zWorld = Lambda(add_layer, name='zWorld')([add_2, pred_z])\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[left_img, right_img], outputs=[pred_fx, pred_fy, pred_u0, pred_v0, pred_baseline, pred_disparity, pred_x, pred_y, pred_z, pred_pitch, pred_xWorld,pred_yWorld,pred_zWorld])\n",
    "\n",
    "# set output types\n",
    "target1 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target2 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target3 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target4 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target5 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target6 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target7 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target8 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target9 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target10 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target11 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target12 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target13 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "\n",
    "# get model summary\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"mae\", target_tensors=[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12, target13],optimizer=optimizers.Adam(lr=learning_rate))\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/\"\n",
    "\n",
    "Left_images = np.load(data_path+\"li.npy\")\n",
    "Right_images = np.load(data_path+\"ri.npy\")\n",
    "Fx = np.load(data_path+\"fx.npy\")\n",
    "Fy = np.load(data_path+\"fy.npy\") \n",
    "U0 = np.load(data_path+\"u0.npy\") \n",
    "V0 = np.load(data_path+\"v0.npy\") \n",
    "Baseline = np.load(data_path+\"b.npy\")\n",
    "Disparity = np.load(data_path+\"d.npy\") \n",
    "Tx = np.load(data_path+\"tx.npy\") \n",
    "Ty = np.load(data_path+\"ty.npy\") \n",
    "Tz = np.load(data_path+\"tz.npy\") \n",
    "Pitch = np.load(data_path+\"p.npy\")\n",
    "X = np.load(data_path+\"x.npy\")\n",
    "Y = np.load(data_path+\"y.npy\") \n",
    "Z = np.load(data_path+\"z.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:  55524.0 Test Dataset:  23796.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Training Dataset: \",len(Left_images)*0.7, \"Test Dataset: \", len(Left_images)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55524 samples, validate on 23796 samples\n",
      "Epoch 1/200\n",
      "55524/55524 [==============================] - ETA: 0s - loss: 199.5955 - fx_loss: 32.8186 - fy_loss: 32.8500 - u0_loss: 3.0667 - v0_loss: 3.0465 - baseline_loss: 2.7174 - disparity_loss: 0.7398 - x_loss: 1.3317 - y_loss: 1.2358 - z_loss: 1.2837 - pitch_loss: 36.6339 - xWorld_loss: 30.8398 - yWorld_loss: 10.1685 - zWorld_loss: 42.8744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55524/55524 [==============================] - 753s 14ms/sample - loss: 199.5955 - fx_loss: 32.8186 - fy_loss: 32.8500 - u0_loss: 3.0667 - v0_loss: 3.0465 - baseline_loss: 2.7174 - disparity_loss: 0.7398 - x_loss: 1.3317 - y_loss: 1.2358 - z_loss: 1.2837 - pitch_loss: 36.6339 - xWorld_loss: 30.8398 - yWorld_loss: 10.1685 - zWorld_loss: 42.8744 - val_loss: 205.4225 - val_fx_loss: 38.9740 - val_fy_loss: 38.4132 - val_u0_loss: 1.8228 - val_v0_loss: 2.3322 - val_baseline_loss: 2.9468 - val_disparity_loss: 0.4624 - val_x_loss: 1.4437 - val_y_loss: 1.2912 - val_z_loss: 1.6651 - val_pitch_loss: 33.4523 - val_xWorld_loss: 30.9563 - val_yWorld_loss: 9.1898 - val_zWorld_loss: 42.4535\n",
      "Epoch 2/200\n",
      "55524/55524 [==============================] - 599s 11ms/sample - loss: 132.0197 - fx_loss: 13.5205 - fy_loss: 13.6583 - u0_loss: 1.0739 - v0_loss: 1.0299 - baseline_loss: 2.9676 - disparity_loss: 0.2983 - x_loss: 1.4864 - y_loss: 0.9898 - z_loss: 1.4879 - pitch_loss: 16.4331 - xWorld_loss: 29.8850 - yWorld_loss: 7.0789 - zWorld_loss: 42.1013 - val_loss: 118.9951 - val_fx_loss: 8.8437 - val_fy_loss: 8.7418 - val_u0_loss: 1.3880 - val_v0_loss: 1.5707 - val_baseline_loss: 2.9834 - val_disparity_loss: 0.2248 - val_x_loss: 1.3086 - val_y_loss: 0.8182 - val_z_loss: 1.6101 - val_pitch_loss: 14.4089 - val_xWorld_loss: 29.7212 - val_yWorld_loss: 5.1853 - val_zWorld_loss: 42.1791\n",
      "Epoch 3/200\n",
      "55524/55524 [==============================] - 557s 10ms/sample - loss: 111.8619 - fx_loss: 7.2213 - fy_loss: 7.2137 - u0_loss: 0.7421 - v0_loss: 0.7065 - baseline_loss: 2.9745 - disparity_loss: 0.1851 - x_loss: 1.4073 - y_loss: 0.7536 - z_loss: 1.4562 - pitch_loss: 12.6756 - xWorld_loss: 29.5510 - yWorld_loss: 5.2299 - zWorld_loss: 41.7441 - val_loss: 110.3383 - val_fx_loss: 7.2127 - val_fy_loss: 7.7863 - val_u0_loss: 1.5574 - val_v0_loss: 1.6752 - val_baseline_loss: 2.9492 - val_disparity_loss: 0.2298 - val_x_loss: 1.3943 - val_y_loss: 0.7099 - val_z_loss: 1.3387 - val_pitch_loss: 8.9840 - val_xWorld_loss: 29.4771 - val_yWorld_loss: 4.7497 - val_zWorld_loss: 42.2898\n",
      "Epoch 4/200\n",
      "55524/55524 [==============================] - 558s 10ms/sample - loss: 103.0713 - fx_loss: 5.4950 - fy_loss: 5.4253 - u0_loss: 0.6562 - v0_loss: 0.6111 - baseline_loss: 2.9190 - disparity_loss: 0.1666 - x_loss: 1.1542 - y_loss: 0.6634 - z_loss: 1.2674 - pitch_loss: 11.0728 - xWorld_loss: 28.5259 - yWorld_loss: 4.5436 - zWorld_loss: 40.5807 - val_loss: 121.4159 - val_fx_loss: 10.3488 - val_fy_loss: 9.9073 - val_u0_loss: 3.0525 - val_v0_loss: 2.7882 - val_baseline_loss: 2.8995 - val_disparity_loss: 0.3812 - val_x_loss: 1.2130 - val_y_loss: 0.8237 - val_z_loss: 1.3660 - val_pitch_loss: 12.9414 - val_xWorld_loss: 28.8563 - val_yWorld_loss: 5.6137 - val_zWorld_loss: 41.2431\n",
      "Epoch 5/200\n",
      "55524/55524 [==============================] - 561s 10ms/sample - loss: 97.6116 - fx_loss: 4.4192 - fy_loss: 4.3050 - u0_loss: 0.5519 - v0_loss: 0.5315 - baseline_loss: 2.8755 - disparity_loss: 0.1542 - x_loss: 0.9463 - y_loss: 0.5907 - z_loss: 1.1063 - pitch_loss: 12.1587 - xWorld_loss: 27.0745 - yWorld_loss: 3.8472 - zWorld_loss: 39.0697 - val_loss: 114.9416 - val_fx_loss: 13.1153 - val_fy_loss: 12.5958 - val_u0_loss: 0.4170 - val_v0_loss: 0.4559 - val_baseline_loss: 2.8636 - val_disparity_loss: 0.1673 - val_x_loss: 1.1057 - val_y_loss: 0.7639 - val_z_loss: 1.1490 - val_pitch_loss: 10.7876 - val_xWorld_loss: 27.3145 - val_yWorld_loss: 5.2212 - val_zWorld_loss: 38.9733\n",
      "Epoch 6/200\n",
      "55524/55524 [==============================] - 656s 12ms/sample - loss: 92.7353 - fx_loss: 3.8828 - fy_loss: 3.7515 - u0_loss: 0.4601 - v0_loss: 0.4384 - baseline_loss: 2.8359 - disparity_loss: 0.1489 - x_loss: 0.9079 - y_loss: 0.5306 - z_loss: 1.0161 - pitch_loss: 11.3611 - xWorld_loss: 27.1117 - yWorld_loss: 3.4724 - zWorld_loss: 36.8326 - val_loss: 97.5910 - val_fx_loss: 4.4563 - val_fy_loss: 3.6765 - val_u0_loss: 0.5373 - val_v0_loss: 0.7432 - val_baseline_loss: 2.8226 - val_disparity_loss: 0.1653 - val_x_loss: 0.7649 - val_y_loss: 0.4631 - val_z_loss: 0.9269 - val_pitch_loss: 9.7798 - val_xWorld_loss: 30.3998 - val_yWorld_loss: 2.9037 - val_zWorld_loss: 39.9637\n",
      "Epoch 7/200\n",
      "55524/55524 [==============================] - 712s 13ms/sample - loss: 91.3243 - fx_loss: 3.3560 - fy_loss: 3.3141 - u0_loss: 0.4151 - v0_loss: 0.4024 - baseline_loss: 2.8246 - disparity_loss: 0.1372 - x_loss: 0.9293 - y_loss: 0.4990 - z_loss: 1.0655 - pitch_loss: 9.3950 - xWorld_loss: 28.7410 - yWorld_loss: 3.0903 - zWorld_loss: 37.1530 - val_loss: 95.4412 - val_fx_loss: 6.4328 - val_fy_loss: 5.9297 - val_u0_loss: 0.7032 - val_v0_loss: 0.6989 - val_baseline_loss: 2.8135 - val_disparity_loss: 0.1158 - val_x_loss: 1.0890 - val_y_loss: 0.4937 - val_z_loss: 1.0214 - val_pitch_loss: 7.5946 - val_xWorld_loss: 29.7822 - val_yWorld_loss: 2.6743 - val_zWorld_loss: 36.0783\n",
      "Epoch 8/200\n",
      "55524/55524 [==============================] - 700s 13ms/sample - loss: 84.8552 - fx_loss: 3.0575 - fy_loss: 3.0207 - u0_loss: 0.3735 - v0_loss: 0.3599 - baseline_loss: 2.7943 - disparity_loss: 0.1200 - x_loss: 0.8578 - y_loss: 0.4469 - z_loss: 1.0009 - pitch_loss: 9.9485 - xWorld_loss: 26.9545 - yWorld_loss: 2.7337 - zWorld_loss: 33.1950 - val_loss: 84.2937 - val_fx_loss: 3.6172 - val_fy_loss: 2.1912 - val_u0_loss: 1.2777 - val_v0_loss: 1.0400 - val_baseline_loss: 2.7922 - val_disparity_loss: 0.1546 - val_x_loss: 0.7995 - val_y_loss: 0.3659 - val_z_loss: 0.9961 - val_pitch_loss: 9.6988 - val_xWorld_loss: 26.2621 - val_yWorld_loss: 2.2433 - val_zWorld_loss: 32.8949\n",
      "Epoch 9/200\n",
      "55524/55524 [==============================] - 674s 12ms/sample - loss: 84.7034 - fx_loss: 2.7420 - fy_loss: 2.7302 - u0_loss: 0.3314 - v0_loss: 0.3187 - baseline_loss: 2.7890 - disparity_loss: 0.1209 - x_loss: 0.8319 - y_loss: 0.4132 - z_loss: 0.9453 - pitch_loss: 11.7057 - xWorld_loss: 26.7033 - yWorld_loss: 2.5566 - zWorld_loss: 32.5525 - val_loss: 88.9466 - val_fx_loss: 3.5363 - val_fy_loss: 2.0463 - val_u0_loss: 0.9437 - val_v0_loss: 1.2464 - val_baseline_loss: 2.7780 - val_disparity_loss: 0.0935 - val_x_loss: 0.7737 - val_y_loss: 0.3511 - val_z_loss: 0.9445 - val_pitch_loss: 7.6281 - val_xWorld_loss: 28.9166 - val_yWorld_loss: 2.4096 - val_zWorld_loss: 37.2853\n",
      "Epoch 10/200\n",
      "55524/55524 [==============================] - 693s 12ms/sample - loss: 80.2737 - fx_loss: 2.3450 - fy_loss: 2.3071 - u0_loss: 0.3162 - v0_loss: 0.3038 - baseline_loss: 2.7647 - disparity_loss: 0.1051 - x_loss: 0.8244 - y_loss: 0.3936 - z_loss: 0.9886 - pitch_loss: 9.1269 - xWorld_loss: 26.2146 - yWorld_loss: 2.2517 - zWorld_loss: 32.3457 - val_loss: 87.1701 - val_fx_loss: 2.7369 - val_fy_loss: 1.9638 - val_u0_loss: 0.7554 - val_v0_loss: 0.6056 - val_baseline_loss: 2.7686 - val_disparity_loss: 0.0928 - val_x_loss: 0.8263 - val_y_loss: 0.3502 - val_z_loss: 0.9959 - val_pitch_loss: 7.7433 - val_xWorld_loss: 30.4926 - val_yWorld_loss: 2.5301 - val_zWorld_loss: 35.3139\n",
      "Epoch 11/200\n",
      "55524/55524 [==============================] - 711s 13ms/sample - loss: 79.1014 - fx_loss: 2.1768 - fy_loss: 2.1285 - u0_loss: 0.2978 - v0_loss: 0.2785 - baseline_loss: 2.7568 - disparity_loss: 0.0942 - x_loss: 0.7767 - y_loss: 0.3728 - z_loss: 0.9829 - pitch_loss: 8.6286 - xWorld_loss: 26.2589 - yWorld_loss: 2.0932 - zWorld_loss: 32.2591 - val_loss: 82.2367 - val_fx_loss: 3.1992 - val_fy_loss: 2.9898 - val_u0_loss: 0.2387 - val_v0_loss: 0.2778 - val_baseline_loss: 2.7630 - val_disparity_loss: 0.0681 - val_x_loss: 0.7679 - val_y_loss: 0.3902 - val_z_loss: 0.9521 - val_pitch_loss: 8.4546 - val_xWorld_loss: 27.6143 - val_yWorld_loss: 2.2513 - val_zWorld_loss: 32.2554\n",
      "Epoch 12/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55524/55524 [==============================] - 700s 13ms/sample - loss: 78.1416 - fx_loss: 2.0554 - fy_loss: 2.0276 - u0_loss: 0.2928 - v0_loss: 0.2879 - baseline_loss: 2.7307 - disparity_loss: 0.1023 - x_loss: 0.7510 - y_loss: 0.3518 - z_loss: 0.9285 - pitch_loss: 9.7814 - xWorld_loss: 25.3874 - yWorld_loss: 1.9766 - zWorld_loss: 31.4754 - val_loss: 73.0758 - val_fx_loss: 1.9111 - val_fy_loss: 1.9442 - val_u0_loss: 0.3451 - val_v0_loss: 0.5617 - val_baseline_loss: 2.6811 - val_disparity_loss: 0.2416 - val_x_loss: 0.7550 - val_y_loss: 0.3168 - val_z_loss: 0.8497 - val_pitch_loss: 12.6778 - val_xWorld_loss: 22.0365 - val_yWorld_loss: 3.1418 - val_zWorld_loss: 25.6303\n",
      "Epoch 13/200\n",
      "55524/55524 [==============================] - 677s 12ms/sample - loss: 75.1618 - fx_loss: 2.5252 - fy_loss: 2.4851 - u0_loss: 0.2763 - v0_loss: 0.2725 - baseline_loss: 2.6424 - disparity_loss: 0.1510 - x_loss: 0.7042 - y_loss: 0.3657 - z_loss: 0.8819 - pitch_loss: 13.7634 - xWorld_loss: 21.6586 - yWorld_loss: 2.1402 - zWorld_loss: 27.3040 - val_loss: 83.7744 - val_fx_loss: 1.8114 - val_fy_loss: 1.9398 - val_u0_loss: 0.7214 - val_v0_loss: 0.7107 - val_baseline_loss: 2.6249 - val_disparity_loss: 0.1245 - val_x_loss: 0.6746 - val_y_loss: 0.2896 - val_z_loss: 0.9059 - val_pitch_loss: 12.1288 - val_xWorld_loss: 29.1224 - val_yWorld_loss: 1.5545 - val_zWorld_loss: 31.1675\n",
      "Epoch 14/200\n",
      "55524/55524 [==============================] - 712s 13ms/sample - loss: 77.3929 - fx_loss: 2.0730 - fy_loss: 2.0766 - u0_loss: 0.2597 - v0_loss: 0.2527 - baseline_loss: 2.5876 - disparity_loss: 0.1063 - x_loss: 0.6756 - y_loss: 0.3448 - z_loss: 0.8556 - pitch_loss: 11.4241 - xWorld_loss: 24.0786 - yWorld_loss: 1.9000 - zWorld_loss: 30.7651 - val_loss: 87.8184 - val_fx_loss: 2.9479 - val_fy_loss: 2.1332 - val_u0_loss: 0.2341 - val_v0_loss: 0.3319 - val_baseline_loss: 2.6433 - val_disparity_loss: 0.0906 - val_x_loss: 0.6464 - val_y_loss: 0.3075 - val_z_loss: 0.7945 - val_pitch_loss: 10.5936 - val_xWorld_loss: 28.6384 - val_yWorld_loss: 2.2634 - val_zWorld_loss: 36.1937\n",
      "Epoch 15/200\n",
      "55524/55524 [==============================] - 700s 13ms/sample - loss: 78.2797 - fx_loss: 2.1763 - fy_loss: 2.1592 - u0_loss: 0.2569 - v0_loss: 0.2570 - baseline_loss: 2.6248 - disparity_loss: 0.0968 - x_loss: 0.6837 - y_loss: 0.3522 - z_loss: 0.8664 - pitch_loss: 10.7622 - xWorld_loss: 24.7411 - yWorld_loss: 1.9465 - zWorld_loss: 31.3486 - val_loss: 74.8429 - val_fx_loss: 2.5155 - val_fy_loss: 3.2129 - val_u0_loss: 0.6649 - val_v0_loss: 0.5197 - val_baseline_loss: 2.5891 - val_disparity_loss: 0.0964 - val_x_loss: 0.6522 - val_y_loss: 0.2846 - val_z_loss: 0.8581 - val_pitch_loss: 11.0911 - val_xWorld_loss: 22.1594 - val_yWorld_loss: 1.8026 - val_zWorld_loss: 28.4346\n",
      "Epoch 16/200\n",
      "55524/55524 [==============================] - 672s 12ms/sample - loss: 74.6228 - fx_loss: 2.4111 - fy_loss: 2.3991 - u0_loss: 0.2708 - v0_loss: 0.2667 - baseline_loss: 2.5115 - disparity_loss: 0.1217 - x_loss: 0.6786 - y_loss: 0.3545 - z_loss: 0.8681 - pitch_loss: 14.1900 - xWorld_loss: 21.0174 - yWorld_loss: 2.0078 - zWorld_loss: 27.5212 - val_loss: 72.6651 - val_fx_loss: 2.2124 - val_fy_loss: 2.8252 - val_u0_loss: 0.6649 - val_v0_loss: 0.4377 - val_baseline_loss: 2.4285 - val_disparity_loss: 0.1042 - val_x_loss: 0.7488 - val_y_loss: 0.3048 - val_z_loss: 0.8825 - val_pitch_loss: 13.9301 - val_xWorld_loss: 20.1980 - val_yWorld_loss: 1.8177 - val_zWorld_loss: 26.0972\n",
      "Epoch 17/200\n",
      "55524/55524 [==============================] - 562s 10ms/sample - loss: 74.0821 - fx_loss: 2.9723 - fy_loss: 2.9618 - u0_loss: 0.2610 - v0_loss: 0.2448 - baseline_loss: 2.2998 - disparity_loss: 0.1583 - x_loss: 0.6453 - y_loss: 0.3652 - z_loss: 0.8104 - pitch_loss: 18.5884 - xWorld_loss: 18.7539 - yWorld_loss: 2.0857 - zWorld_loss: 23.9437 - val_loss: 90.4039 - val_fx_loss: 3.9461 - val_fy_loss: 4.0299 - val_u0_loss: 0.1843 - val_v0_loss: 0.1315 - val_baseline_loss: 2.0624 - val_disparity_loss: 0.3992 - val_x_loss: 0.5837 - val_y_loss: 0.3917 - val_z_loss: 0.8116 - val_pitch_loss: 22.3882 - val_xWorld_loss: 26.5533 - val_yWorld_loss: 1.9610 - val_zWorld_loss: 26.9447\n",
      "Epoch 18/200\n",
      "55524/55524 [==============================] - 537s 10ms/sample - loss: 83.9717 - fx_loss: 4.0250 - fy_loss: 3.9863 - u0_loss: 0.2506 - v0_loss: 0.2463 - baseline_loss: 1.9818 - disparity_loss: 0.4081 - x_loss: 0.4941 - y_loss: 0.4360 - z_loss: 0.8111 - pitch_loss: 20.6984 - xWorld_loss: 21.5814 - yWorld_loss: 2.5609 - zWorld_loss: 26.4816 - val_loss: 79.3510 - val_fx_loss: 3.8610 - val_fy_loss: 4.3351 - val_u0_loss: 0.6682 - val_v0_loss: 0.7027 - val_baseline_loss: 2.0274 - val_disparity_loss: 0.4255 - val_x_loss: 0.5706 - val_y_loss: 0.4057 - val_z_loss: 0.7307 - val_pitch_loss: 18.5933 - val_xWorld_loss: 22.7951 - val_yWorld_loss: 2.7029 - val_zWorld_loss: 21.5175\n",
      "Epoch 19/200\n",
      "55524/55524 [==============================] - 539s 10ms/sample - loss: 83.3255 - fx_loss: 3.5546 - fy_loss: 3.5745 - u0_loss: 0.2837 - v0_loss: 0.2666 - baseline_loss: 2.1037 - disparity_loss: 0.3543 - x_loss: 0.5768 - y_loss: 0.4161 - z_loss: 0.7613 - pitch_loss: 23.4944 - xWorld_loss: 21.0266 - yWorld_loss: 2.4322 - zWorld_loss: 24.4869 - val_loss: 69.6004 - val_fx_loss: 2.2842 - val_fy_loss: 2.2663 - val_u0_loss: 0.1360 - val_v0_loss: 0.2013 - val_baseline_loss: 2.1182 - val_disparity_loss: 0.2238 - val_x_loss: 0.5211 - val_y_loss: 0.3696 - val_z_loss: 0.7251 - val_pitch_loss: 28.2734 - val_xWorld_loss: 14.3413 - val_yWorld_loss: 2.0776 - val_zWorld_loss: 16.0453\n",
      "Epoch 20/200\n",
      "55524/55524 [==============================] - 541s 10ms/sample - loss: 73.1580 - fx_loss: 2.4241 - fy_loss: 2.3978 - u0_loss: 0.2378 - v0_loss: 0.2336 - baseline_loss: 2.1314 - disparity_loss: 0.2111 - x_loss: 0.5812 - y_loss: 0.3481 - z_loss: 0.7081 - pitch_loss: 19.5192 - xWorld_loss: 20.0067 - yWorld_loss: 2.0603 - zWorld_loss: 22.2956 - val_loss: 67.6306 - val_fx_loss: 1.4947 - val_fy_loss: 1.5681 - val_u0_loss: 0.2371 - val_v0_loss: 0.1320 - val_baseline_loss: 2.1357 - val_disparity_loss: 0.2075 - val_x_loss: 0.5538 - val_y_loss: 0.2642 - val_z_loss: 0.6678 - val_pitch_loss: 16.2361 - val_xWorld_loss: 20.5271 - val_yWorld_loss: 2.2027 - val_zWorld_loss: 21.3879\n",
      "Epoch 21/200\n",
      "55524/55524 [==============================] - 540s 10ms/sample - loss: 69.9269 - fx_loss: 2.0093 - fy_loss: 2.0392 - u0_loss: 0.2182 - v0_loss: 0.2169 - baseline_loss: 2.0914 - disparity_loss: 0.1987 - x_loss: 0.5985 - y_loss: 0.3094 - z_loss: 0.6416 - pitch_loss: 19.5759 - xWorld_loss: 18.9037 - yWorld_loss: 1.8279 - zWorld_loss: 21.3102 - val_loss: 74.6409 - val_fx_loss: 2.1228 - val_fy_loss: 1.9959 - val_u0_loss: 0.4383 - val_v0_loss: 0.4636 - val_baseline_loss: 2.0246 - val_disparity_loss: 0.3444 - val_x_loss: 0.4621 - val_y_loss: 0.2663 - val_z_loss: 0.6256 - val_pitch_loss: 18.1722 - val_xWorld_loss: 24.3207 - val_yWorld_loss: 1.8234 - val_zWorld_loss: 21.5799\n",
      "Epoch 22/200\n",
      "55524/55524 [==============================] - 541s 10ms/sample - loss: 68.9267 - fx_loss: 2.8939 - fy_loss: 2.9239 - u0_loss: 0.2206 - v0_loss: 0.2028 - baseline_loss: 2.0008 - disparity_loss: 0.4314 - x_loss: 0.4356 - y_loss: 0.3466 - z_loss: 0.5886 - pitch_loss: 19.4767 - xWorld_loss: 17.8409 - yWorld_loss: 2.0671 - zWorld_loss: 19.5164 - val_loss: 65.5581 - val_fx_loss: 1.8558 - val_fy_loss: 2.1101 - val_u0_loss: 0.4320 - val_v0_loss: 0.3994 - val_baseline_loss: 2.0037 - val_disparity_loss: 0.4662 - val_x_loss: 0.5702 - val_y_loss: 0.2775 - val_z_loss: 0.5502 - val_pitch_loss: 19.2823 - val_xWorld_loss: 17.2361 - val_yWorld_loss: 1.9531 - val_zWorld_loss: 18.4261\n",
      "Epoch 23/200\n",
      "55524/55524 [==============================] - 546s 10ms/sample - loss: 68.1937 - fx_loss: 2.2705 - fy_loss: 2.2604 - u0_loss: 0.2210 - v0_loss: 0.2009 - baseline_loss: 2.0145 - disparity_loss: 0.6150 - x_loss: 0.4229 - y_loss: 0.3056 - z_loss: 0.6153 - pitch_loss: 17.8344 - xWorld_loss: 18.2777 - yWorld_loss: 1.9383 - zWorld_loss: 21.2405 - val_loss: 58.2156 - val_fx_loss: 1.7200 - val_fy_loss: 1.4483 - val_u0_loss: 0.1818 - val_v0_loss: 0.7169 - val_baseline_loss: 2.0216 - val_disparity_loss: 0.6351 - val_x_loss: 0.3344 - val_y_loss: 0.2262 - val_z_loss: 0.5534 - val_pitch_loss: 17.5257 - val_xWorld_loss: 15.0891 - val_yWorld_loss: 1.7039 - val_zWorld_loss: 16.0803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "55524/55524 [==============================] - 658s 12ms/sample - loss: 65.8180 - fx_loss: 2.0381 - fy_loss: 2.0658 - u0_loss: 0.1955 - v0_loss: 0.1884 - baseline_loss: 1.9818 - disparity_loss: 0.6787 - x_loss: 0.3800 - y_loss: 0.3049 - z_loss: 0.6217 - pitch_loss: 18.8962 - xWorld_loss: 16.4452 - yWorld_loss: 1.8998 - zWorld_loss: 20.1267 - val_loss: 71.9468 - val_fx_loss: 2.4203 - val_fy_loss: 1.8897 - val_u0_loss: 0.1533 - val_v0_loss: 0.6802 - val_baseline_loss: 1.9807 - val_disparity_loss: 0.7115 - val_x_loss: 0.3789 - val_y_loss: 0.2289 - val_z_loss: 0.5466 - val_pitch_loss: 17.5993 - val_xWorld_loss: 20.9867 - val_yWorld_loss: 1.7483 - val_zWorld_loss: 22.6278\n",
      "Epoch 25/200\n",
      "55524/55524 [==============================] - 595s 11ms/sample - loss: 62.3321 - fx_loss: 2.0131 - fy_loss: 2.0604 - u0_loss: 0.1916 - v0_loss: 0.1839 - baseline_loss: 1.9555 - disparity_loss: 0.6506 - x_loss: 0.3343 - y_loss: 0.2854 - z_loss: 0.5572 - pitch_loss: 16.2838 - xWorld_loss: 16.5201 - yWorld_loss: 1.7418 - zWorld_loss: 19.5501 - val_loss: 66.3372 - val_fx_loss: 1.8216 - val_fy_loss: 1.9351 - val_u0_loss: 0.6218 - val_v0_loss: 0.5494 - val_baseline_loss: 1.9207 - val_disparity_loss: 0.6028 - val_x_loss: 0.3231 - val_y_loss: 0.2218 - val_z_loss: 0.5313 - val_pitch_loss: 14.4702 - val_xWorld_loss: 20.6212 - val_yWorld_loss: 1.3243 - val_zWorld_loss: 21.4015\n",
      "Epoch 26/200\n",
      "55524/55524 [==============================] - 539s 10ms/sample - loss: 62.4977 - fx_loss: 2.2868 - fy_loss: 2.2941 - u0_loss: 0.1935 - v0_loss: 0.1829 - baseline_loss: 1.8953 - disparity_loss: 0.5460 - x_loss: 0.3429 - y_loss: 0.3139 - z_loss: 0.5489 - pitch_loss: 17.9433 - xWorld_loss: 15.3577 - yWorld_loss: 1.9052 - zWorld_loss: 18.6909 - val_loss: 87.2429 - val_fx_loss: 1.7364 - val_fy_loss: 2.0373 - val_u0_loss: 0.1539 - val_v0_loss: 0.3244 - val_baseline_loss: 1.8885 - val_disparity_loss: 0.6422 - val_x_loss: 0.3472 - val_y_loss: 0.2737 - val_z_loss: 0.5753 - val_pitch_loss: 17.5256 - val_xWorld_loss: 30.5920 - val_yWorld_loss: 1.8248 - val_zWorld_loss: 29.3608\n",
      "Epoch 27/200\n",
      "55524/55524 [==============================] - 540s 10ms/sample - loss: 62.6382 - fx_loss: 2.0976 - fy_loss: 2.1590 - u0_loss: 0.1886 - v0_loss: 0.1815 - baseline_loss: 1.8307 - disparity_loss: 0.6238 - x_loss: 0.3336 - y_loss: 0.3161 - z_loss: 0.5410 - pitch_loss: 17.7863 - xWorld_loss: 16.1238 - yWorld_loss: 1.9094 - zWorld_loss: 18.5449 - val_loss: 64.2072 - val_fx_loss: 1.9649 - val_fy_loss: 1.9651 - val_u0_loss: 0.1139 - val_v0_loss: 0.6944 - val_baseline_loss: 1.7511 - val_disparity_loss: 0.6990 - val_x_loss: 0.2500 - val_y_loss: 0.2133 - val_z_loss: 0.4092 - val_pitch_loss: 17.3716 - val_xWorld_loss: 19.5230 - val_yWorld_loss: 1.3948 - val_zWorld_loss: 17.8385\n",
      "Epoch 28/200\n",
      "55524/55524 [==============================] - ETA: 0s - loss: 65.2599 - fx_loss: 2.3949 - fy_loss: 2.4408 - u0_loss: 0.2061 - v0_loss: 0.2004 - baseline_loss: 1.7324 - disparity_loss: 0.7774 - x_loss: 0.3195 - y_loss: 0.3019 - z_loss: 0.5089 - pitch_loss: 16.8763 - xWorld_loss: 17.3957 - yWorld_loss: 1.8723 - zWorld_loss: 20.2383Restoring model weights from the end of the best epoch.\n",
      "55524/55524 [==============================] - 544s 10ms/sample - loss: 65.2599 - fx_loss: 2.3949 - fy_loss: 2.4408 - u0_loss: 0.2061 - v0_loss: 0.2004 - baseline_loss: 1.7324 - disparity_loss: 0.7774 - x_loss: 0.3195 - y_loss: 0.3019 - z_loss: 0.5089 - pitch_loss: 16.8763 - xWorld_loss: 17.3957 - yWorld_loss: 1.8723 - zWorld_loss: 20.2383 - val_loss: 90.3328 - val_fx_loss: 1.7243 - val_fy_loss: 3.0631 - val_u0_loss: 0.7666 - val_v0_loss: 0.9432 - val_baseline_loss: 1.6686 - val_disparity_loss: 1.1241 - val_x_loss: 0.3034 - val_y_loss: 0.2893 - val_z_loss: 0.6391 - val_pitch_loss: 14.5287 - val_xWorld_loss: 27.2904 - val_yWorld_loss: 2.0288 - val_zWorld_loss: 35.9649\n",
      "Epoch 00028: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "model_name = 'model_multi_class/'\n",
    "SAVE = \"new_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "# Save\n",
    "output_folder = SAVE + model_name\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "output_log = output_folder + \"Log/\"\n",
    "if not os.path.exists(output_log):\n",
    "    os.makedirs(output_log)\n",
    "\n",
    "output_weight = output_folder + \"Best/\"\n",
    "if not os.path.exists(output_weight):\n",
    "    os.makedirs(output_weight)\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=output_log)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    model_for_saving=model,\n",
    "    filepath=output_weight + \"weights_{epoch:02d}_{val_loss:.2f}.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[Left_images[:int(len(Left_images)*0.7)], Right_images[:int(len(Left_images)*0.7)]],\n",
    "    y=[Fx[:int(len(Left_images)*0.7)], Fy[:int(len(Left_images)*0.7)], U0[:int(len(Left_images)*0.7)], V0[:int(len(Left_images)*0.7)], Baseline[:int(len(Left_images)*0.7)], Disparity[:int(len(Left_images)*0.7)], Tx[:int(len(Left_images)*0.7)], Ty[:int(len(Left_images)*0.7)], Tz[:int(len(Left_images)*0.7)], Pitch[:int(len(Left_images)*0.7)], X[:int(len(Left_images)*0.7)], Y[:int(len(Left_images)*0.7)], Z[:int(len(Left_images)*0.7)]],\n",
    "    batch_size=16,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    validation_data=([Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]], [Fx[int(len(Left_images)*0.7):], Fy[int(len(Left_images)*0.7):], U0[int(len(Left_images)*0.7):], V0[int(len(Left_images)*0.7):], Baseline[int(len(Left_images)*0.7):], Disparity[int(len(Left_images)*0.7):], Tx[int(len(Left_images)*0.7):], Ty[int(len(Left_images)*0.7):], Tz[int(len(Left_images)*0.7):], Pitch[int(len(Left_images)*0.7):], X[int(len(Left_images)*0.7):], Y[int(len(Left_images)*0.7):], Z[int(len(Left_images)*0.7):]]),\n",
    "    callbacks=[tensorboard, checkpointer, early_stopping, csv_logger]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "model.load_weights('./new_logs/20220908-131230/model_multi_class/Best/weights_23_58.22.h5')\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "\n",
    "output = model.predict(\n",
    "    x=[Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]],\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 1.7203366214287756, 'fy': 1.4489545759413487, 'u0': 0.1817660600242544, 'v0': 0.7168212601428754, 'baseline': 2.0212013848911194, 'disparity': 0.6347296211487513, 'x': 0.33405547099747485, 'y': 0.22606784079751763, 'z': 0.553045160380867, 'pitch': 17.526308870852585, 'xworld': 15.08453204150905, 'yworld': 1.7003544984662247, 'zworld': 16.06738446825849}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math \n",
    "\n",
    "def normalize(x):\n",
    "    \n",
    "    return (math.atan(x) + 3.14/2) / 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.8843963428617811, 'fy': 0.9114423831145054, 'u0': 0.7282263956665703, 'v0': 0.6373140539925413, 'baseline': 0.8732234974660816, 'disparity': 0.6210554186664111, 'x': 0.7347879211851821, 'y': 0.7188259027103718, 'z': 0.7334200235350675, 'pitch': 0.9524821243477615, 'xworld': 0.9656370923642681, 'yworld': 0.9002662165885574, 'zworld': 0.9758289870726622}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fx - actual_fx))\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fy - actual_fy))\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_u0 - actual_u0))\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_v0 - actual_v0))\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_baseline - actual_baseline))\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_disparity - actual_disparity))\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tx - actual_tx))\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_ty - actual_ty))\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tz - actual_tz))\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_pitch - actual_pitch))\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_x - actual_x))\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_y - actual_y))\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_z - actual_z))\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.02463748515183124, 'fy': 0.02831664666868909, 'u0': 0.02294115505902206, 'v0': 0.017306714223111433, 'baseline': 0.12978495358614217, 'disparity': 0.01774838413167217, 'x': 0.055404124404127224, 'y': 0.03276949154431778, 'z': 0.07197428159761873, 'pitch': 0.019904880198233815, 'xworld': 0.08421927624064439, 'yworld': 0.018279980683418177, 'zworld': 0.1307571785332731}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "min_fx = 1.9073486e-06\n",
    "max_fx = 3214.9907\n",
    "\n",
    "min_fy = 2.9563904e-05\n",
    "max_fy = 2051.209\n",
    "\n",
    "min_u0 = 1.9073486e-05\n",
    "max_u0 = 2178.9983\n",
    "\n",
    "min_v0 = 3.8146973e-06\n",
    "max_v0 = 2385.7239\n",
    "\n",
    "min_baseline = 4.7683716e-06\n",
    "max_baseline = 22.68721567997021\n",
    "\n",
    "min_disparity = 9.536743e-07\n",
    "max_disparity = 134.60031\n",
    "\n",
    "min_tx = 2.384185791015625e-06\n",
    "max_tx = 22.68721567997021\n",
    "\n",
    "min_ty = 2.3841858e-07\n",
    "max_ty = 33.11693576309983\n",
    "\n",
    "min_tz = 2.3841858e-06\n",
    "max_tz = 17.20185265614626\n",
    "\n",
    "min_pitch = 4.57763671875e-05\n",
    "max_pitch = 4502.9224\n",
    "\n",
    "min_xw = 5.219264654243716e-06\n",
    "max_xw = 386.4486\n",
    "\n",
    "min_yw = 3.8146973e-06\n",
    "max_yw = 1835.1849\n",
    "\n",
    "min_zw = 0.00011349\n",
    "max_zw = 339.17166\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fx - actual_fx) - min_fx)/(max_fx - min_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fy - actual_fy) - min_fy)/(max_fy - min_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_u0 - actual_u0) - min_u0)/(max_u0 - min_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_v0 - actual_v0) - min_v0)/(max_v0 - min_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_baseline - actual_baseline) - min_baseline)/(max_baseline - min_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_disparity - actual_disparity) - min_disparity)/(max_disparity - min_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tx - actual_tx) - min_tx)/(max_tx - min_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_ty - actual_ty) - min_ty)/(max_ty - min_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tz - actual_tz) - min_tz)/(max_tz - min_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_pitch - actual_pitch) - min_pitch)/(max_pitch - min_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_x - actual_x) - min_xw)/(max_xw - min_xw)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_y - actual_y) - min_yw)/(max_yw - min_yw)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_z - actual_z) - min_zw)/(max_zw - min_zw)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.020308686620320718, 'fy': 0.017105003778522292, 'u0': 0.0032458225004331092, 'v0': 0.012800379645408429, 'baseline': 0.6444575063292809, 'disparity': 0.11262231350798388, 'x': 0.10651316460795186, 'y': 0.0687336817981936, 'z': 0.1932888205567041, 'pitch': 0.20729874140885132, 'xworld': 0.4771566168377753, 'yworld': 0.06776246639070894, 'zworld': 0.37619602554163734}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "mean_fx = 84.70939817976283\n",
    "\n",
    "mean_fy = 84.70939817976283\n",
    "\n",
    "mean_u0 = 56.0\n",
    "\n",
    "mean_v0 = 56.0\n",
    "\n",
    "mean_baseline = 3.1362834089762988\n",
    "\n",
    "mean_disparity = 5.6359135359419765\n",
    "\n",
    "mean_tx = 3.1362834089762988\n",
    "\n",
    "mean_ty = 3.2890401748192972\n",
    "\n",
    "mean_tz = 2.8612371827197847\n",
    "\n",
    "mean_pitch = 84.54614220877458\n",
    "\n",
    "mean_xw = 31.613377053172897\n",
    "\n",
    "mean_yw = 25.092866140117593\n",
    "\n",
    "mean_zw = 42.71013880363322\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx) / mean_fx\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy) / mean_fy\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0) / mean_u0\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0) / mean_v0\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline) / mean_baseline\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity) / mean_disparity\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx) / mean_tx\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty) / mean_ty\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz) / mean_tz\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch) / mean_pitch\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x) / mean_xw\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y) / mean_yw\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z) / mean_zw\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
