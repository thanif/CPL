{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(1)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "\n",
    "if ros_path in sys.path:\n",
    "\n",
    "    sys.path.remove(ros_path)\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(tensor):\n",
    "    return tensor[0] + tensor[1]\n",
    "\n",
    "def mul_layer(tensor):\n",
    "    return tensor[0] * tensor[1]\n",
    "\n",
    "def div_layer(tensor):\n",
    "    return tensor[0] / tensor[1]\n",
    "\n",
    "def sub_layer(tensor):\n",
    "    return tensor[0] - tensor[1]\n",
    "\n",
    "def neg_layer(tensor):\n",
    "    return -tensor\n",
    "\n",
    "def cos_layer(tensor):\n",
    "    return tf.math.cos(tensor)\n",
    "\n",
    "def sin_layer(tensor):\n",
    "    return tf.math.sin(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 6 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_image (InputLayer)         [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 112, 112, 6)  0           left_image[0][0]                 \n",
      "                                                                 right_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 55, 55, 32)   1728        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 55, 55, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 55, 55, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 53, 53, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 53, 53, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 53, 53, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 53, 53, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 53, 53, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 53, 53, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 26, 26, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 26, 26, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 26, 26, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 26, 26, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 24, 24, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24, 24, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 24, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 11, 11, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 11, 11, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 11, 11, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 11, 11, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 11, 11, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 11, 11, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 11, 11, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 11, 11, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 11, 11, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 11, 11, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 11, 11, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 11, 11, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 11, 11, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 11, 11, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 11, 11, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 11, 11, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 11, 11, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 11, 11, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 11, 11, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 11, 11, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 11, 11, 64)   16384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 11, 11, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 11, 11, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 11, 11, 48)   12288       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 11, 11, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 11, 11, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 11, 11, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 11, 11, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 11, 11, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 11, 11, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 11, 11, 64)   16384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 11, 11, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 11, 11, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 11, 11, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 11, 11, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 11, 11, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 11, 11, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 11, 11, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 11, 11, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 11, 11, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 11, 11, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 11, 11, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 11, 11, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 11, 11, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 48)   13824       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 11, 11, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 11, 11, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 11, 11, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 11, 11, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 11, 11, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 11, 11, 288)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 11, 11, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 11, 11, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 11, 11, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 11, 11, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 11, 11, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 11, 11, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 11, 11, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 11, 11, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 11, 11, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 11, 11, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 11, 11, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 11, 11, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 11, 11, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 11, 11, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 11, 11, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 11, 11, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 11, 11, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 5, 5, 384)    995328      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 5, 5, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 5, 5, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 5, 5, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5, 5, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 5, 5, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 288)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 5, 5, 128)    98304       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 5, 5, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5, 5, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 5, 5, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 5, 5, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 5, 5, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 5, 5, 128)    98304       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 5, 5, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 5, 5, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 5, 5, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 5, 5, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 5, 5, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 5, 5, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 5, 5, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 5, 5, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 5, 5, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 5, 5, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5, 5, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 5, 5, 768)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 5, 5, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 5, 5, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 5, 5, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 5, 5, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 5, 5, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 5, 5, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 5, 5, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 5, 5, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 5, 5, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 5, 5, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 5, 5, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 5, 5, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 5, 5, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 5, 5, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 5, 5, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 5, 5, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 5, 5, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 5, 5, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5, 5, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5, 5, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 5, 5, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 5, 5, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 5, 5, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 5, 5, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 5, 5, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 5, 5, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 5, 5, 768)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 5, 5, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 5, 5, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 5, 5, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 5, 5, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 5, 5, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 5, 5, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 5, 5, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 5, 5, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 5, 5, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 5, 5, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 5, 5, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 5, 5, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 5, 5, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 5, 5, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 5, 5, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 5, 5, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 5, 5, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 5, 5, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 5, 5, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 5, 5, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 5, 5, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 5, 5, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 5, 5, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 5, 5, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5, 5, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 5, 5, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 5, 5, 768)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 5, 5, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 5, 5, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 5, 5, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 5, 5, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 5, 5, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 5, 5, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 5, 5, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 5, 5, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 5, 5, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5, 5, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5, 5, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 5, 5, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 5, 5, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 5, 5, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 5, 5, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 5, 5, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 5, 5, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 5, 5, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 5, 5, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 5, 5, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 5, 5, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 5, 5, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 5, 5, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 5, 5, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 5, 5, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 5, 5, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 5, 5, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 5, 5, 768)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 5, 5, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 5, 5, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 5, 5, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 5, 5, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 5, 5, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 5, 5, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 5, 5, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 5, 5, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 5, 5, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 5, 5, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5, 5, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 5, 5, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 5, 5, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 5, 5, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 5, 5, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 5, 5, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 5, 5, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 5, 5, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 5, 5, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)    0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 2, 2, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 2, 2, 448)    573440      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 2, 2, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 384)    491520      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 2, 2, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 2, 2, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 1280)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 320)    409600      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2, 2, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 2, 2, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 2, 2, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2, 2, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 2, 2, 2048)   0           activation_76[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 448)    917504      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 2, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 2, 2, 384)    786432      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2, 2, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 2, 2, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 2, 2, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 2, 2, 2048)   0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 2, 2, 320)    655360      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 2, 2, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2, 2, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 2, 2, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2, 2, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2, 2, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 2, 2, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 2, 2, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2, 2, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 2, 2, 2048)   0           activation_85[0][0]              \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "phi-flattened (Flatten)         (None, 8192)         0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_fx (Dense)                (None, 84)           10164       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_baseline (Dense)          (None, 84)           10164       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fx (Dense)                      (None, 1)            85          dense_fx[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "baseline (Dense)                (None, 1)            85          dense_baseline[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_disparity (Dense)         (None, 84)           10164       dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_fy (Dense)                (None, 84)           10164       dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_v0 (Dense)                (None, 84)           10164       dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "disparity (Dense)               (None, 1)            85          dense_disparity[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           fx[0][0]                         \n",
      "                                                                 baseline[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_v (Dense)                 (None, 84)           10164       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fy (Dense)                      (None, 1)            85          dense_fy[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "v0 (Dense)                      (None, 1)            85          dense_v0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_pitch (Dense)             (None, 84)           10164       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "xCam (Lambda)                   (None, 1)            0           lambda[0][0]                     \n",
      "                                                                 disparity[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "v (Dense)                       (None, 1)            85          dense_v[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_u0 (Dense)                (None, 84)           10164       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pitch (Dense)                   (None, 1)            85          dense_pitch[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 fy[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           v0[0][0]                         \n",
      "                                                                 v[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dense_u (Dense)                 (None, 84)           10164       dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "u0 (Dense)                      (None, 1)            85          dense_u0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "zCam (Lambda)                   (None, 1)            0           lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 fx[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "u (Dense)                       (None, 1)            85          dense_u[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1)            0           xCam[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_tx (Dense)                (None, 84)           10164       dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_ty (Dense)                (None, 84)           10164       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_tz (Dense)                (None, 84)           10164       dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           xCam[0][0]                       \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1)            0           zCam[0][0]                       \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           u[0][0]                          \n",
      "                                                                 u0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1)            0           zCam[0][0]                       \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 1)            85          dense_tx[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            85          dense_ty[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Dense)                       (None, 1)            85          dense_tz[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           lambda_6[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "yCam (Lambda)                   (None, 1)            0           lambda_3[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1)            0           lambda_11[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "xWorld (Lambda)                 (None, 1)            0           lambda_10[0][0]                  \n",
      "                                                                 x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "yWorld (Lambda)                 (None, 1)            0           yCam[0][0]                       \n",
      "                                                                 y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "zWorld (Lambda)                 (None, 1)            0           lambda_16[0][0]                  \n",
      "                                                                 z[0][0]                          \n",
      "==================================================================================================\n",
      "Total params: 33,724,556\n",
      "Trainable params: 33,690,124\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# feature extraction from left image\n",
    "left_img = Input(shape = (112,112,3), name=\"left_image\")\n",
    "\n",
    "# feature extraction from right image\n",
    "right_img = Input(shape = (112,112,3), name=\"right_image\")\n",
    "\n",
    "concat = concatenate([left_img, right_img])\n",
    "\n",
    "phi_model = InceptionV3(weights=None, include_top=False, input_tensor=concat, input_shape=(112,112,6))\n",
    "phi_features = phi_model.output\n",
    "flat = Flatten(name='phi-flattened')(phi_features)\n",
    "\n",
    "\n",
    "# fx\n",
    "dense_1 = Dense(120, activation = 'relu')(flat)\n",
    "dense_2 = Dense(84, activation = 'relu', name='dense_fx')(dense_1)\n",
    "pred_fx = Dense(1, name='fx')(dense_2)\n",
    "\n",
    "# fy\n",
    "dense_3 = Dense(120, activation = 'relu')(flat)\n",
    "dense_4 = Dense(84, activation = 'relu', name='dense_fy')(dense_3)\n",
    "pred_fy = Dense(1, name='fy')(dense_4)\n",
    "\n",
    "# u0\n",
    "dense_5 = Dense(120, activation = 'relu')(flat)\n",
    "dense_6 = Dense(84, activation = 'relu', name='dense_u0')(dense_5)\n",
    "pred_u0 = Dense(1, name='u0')(dense_6)\n",
    "\n",
    "# v0\n",
    "dense_7 = Dense(120, activation = 'relu')(flat)\n",
    "dense_8 = Dense(84, activation = 'relu', name='dense_v0')(dense_7)\n",
    "pred_v0 = Dense(1, name='v0')(dense_8)\n",
    "\n",
    "# baseline\n",
    "dense_9 = Dense(120, activation = 'relu')(flat)\n",
    "dense_10 = Dense(84, activation = 'relu', name='dense_baseline')(dense_9)\n",
    "pred_baseline = Dense(1, name='baseline')(dense_10)\n",
    "\n",
    "# tx\n",
    "dense_11 = Dense(120, activation = 'relu')(flat)\n",
    "dense_12 = Dense(84, activation = 'relu', name='dense_tx')(dense_11)\n",
    "pred_x = Dense(1, name='x')(dense_12)\n",
    "\n",
    "# ty\n",
    "dense_13 = Dense(120, activation = 'relu')(flat)\n",
    "dense_14 = Dense(84, activation = 'relu', name='dense_ty')(dense_13)\n",
    "pred_y = Dense(1, name='y')(dense_14)\n",
    "\n",
    "# tz\n",
    "dense_15 = Dense(120, activation = 'relu')(flat)\n",
    "dense_16 = Dense(84, activation = 'relu', name='dense_tz')(dense_15)\n",
    "pred_z = Dense(1, name='z')(dense_16)\n",
    "\n",
    "# pitch\n",
    "dense_17 = Dense(120, activation = 'relu')(flat)\n",
    "dense_18 = Dense(84, activation = 'relu', name='dense_pitch')(dense_17)\n",
    "pred_pitch = Dense(1, name='pitch')(dense_18)\n",
    "\n",
    "# u\n",
    "dense_19 = Dense(120, activation = 'relu')(flat)\n",
    "dense_20 = Dense(84, activation = 'relu', name='dense_u')(dense_19)\n",
    "pred_u = Dense(1, name='u')(dense_20)\n",
    "\n",
    "# v\n",
    "dense_21 = Dense(120, activation = 'relu')(flat)\n",
    "dense_22 = Dense(84, activation = 'relu', name='dense_v')(dense_21)\n",
    "pred_v = Dense(1, name='v')(dense_22)\n",
    "\n",
    "# disparity\n",
    "dense_23 = Dense(120, activation = 'relu')(flat)\n",
    "dense_24 = Dense(84, activation = 'relu', name='dense_disparity')(dense_23)\n",
    "pred_disparity = Dense(1, name='disparity')(dense_24)\n",
    "\n",
    "# xCam = (self.intrinsic.fx * self.extrinsic.baseline) / disparity\n",
    "mul_1 = Lambda(mul_layer)([pred_fx, pred_baseline])\n",
    "xCam = Lambda(div_layer, name='xCam')([mul_1, pred_disparity])\n",
    "\n",
    "# yCam = - (xCam / self.intrinsic.fx) * (u - self.intrinsic.u0)\n",
    "div_1 = Lambda(div_layer)([xCam, pred_fx])\n",
    "sub_1 = Lambda(sub_layer)([pred_u, pred_u0])\n",
    "yCam = Lambda(mul_layer, name='yCam')([Lambda(neg_layer)(div_1), sub_1])\n",
    "\n",
    "# zCam = (xCam / self.intrinsic.fy) * (self.intrinsic.v0 - v)\n",
    "div_2 = Lambda(div_layer)([xCam, pred_fy])\n",
    "sub_2 = Lambda(sub_layer)([pred_v0, pred_v])\n",
    "zCam = Lambda(mul_layer, name='zCam')([div_2, sub_2])\n",
    "\n",
    "# Y = yCam + self.extrinsic.y\n",
    "pred_yWorld = Lambda(add_layer, name='yWorld')([yCam, pred_y])\n",
    "\n",
    "# X = xCam * math.cos(self.extrinsic.pitch) + zCam * math.sin(self.extrinsic.pitch) + self.extrinsic.x\n",
    "mul_2 = Lambda(mul_layer)([xCam, Lambda(cos_layer)(pred_pitch)])\n",
    "mul_3 = Lambda(mul_layer)([zCam, Lambda(sin_layer)(pred_pitch)])\n",
    "add_1 = Lambda(add_layer)([mul_2, mul_3])\n",
    "pred_xWorld = Lambda(add_layer, name='xWorld')([add_1, pred_x])\n",
    "\n",
    "# Z = - xCam * math.sin(self.extrinsic.pitch) + zCam * math.cos(self.extrinsic.pitch) + self.extrinsic.z\n",
    "mul_4 = Lambda(mul_layer)([Lambda(neg_layer)(xCam), Lambda(sin_layer)(pred_pitch)])\n",
    "mul_5 = Lambda(mul_layer)([zCam, Lambda(cos_layer)(pred_pitch)])\n",
    "add_2 = Lambda(add_layer)([mul_4, mul_5])\n",
    "pred_zWorld = Lambda(add_layer, name='zWorld')([add_2, pred_z])\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[left_img, right_img], outputs=[pred_fx, pred_fy, pred_u0, pred_v0, pred_baseline, pred_disparity, pred_x, pred_y, pred_z, pred_pitch, pred_xWorld,pred_yWorld,pred_zWorld])\n",
    "\n",
    "# set output types\n",
    "target1 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target2 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target3 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target4 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target5 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target6 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target7 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target8 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target9 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target10 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target11 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target12 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target13 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "\n",
    "# get model summary\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"mae\", target_tensors=[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12, target13],optimizer=optimizers.Adam(lr=learning_rate))\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/\"\n",
    "\n",
    "Left_images = np.load(data_path+\"li.npy\")\n",
    "Right_images = np.load(data_path+\"ri.npy\")\n",
    "Fx = np.load(data_path+\"fx.npy\")\n",
    "Fy = np.load(data_path+\"fy.npy\") \n",
    "U0 = np.load(data_path+\"u0.npy\") \n",
    "V0 = np.load(data_path+\"v0.npy\") \n",
    "Baseline = np.load(data_path+\"b.npy\")\n",
    "Disparity = np.load(data_path+\"d.npy\") \n",
    "Tx = np.load(data_path+\"tx.npy\") \n",
    "Ty = np.load(data_path+\"ty.npy\") \n",
    "Tz = np.load(data_path+\"tz.npy\") \n",
    "Pitch = np.load(data_path+\"p.npy\")\n",
    "X = np.load(data_path+\"x.npy\")\n",
    "Y = np.load(data_path+\"y.npy\") \n",
    "Z = np.load(data_path+\"z.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:  55524.0 Test Dataset:  23796.0\n"
     ]
    }
   ],
   "source": [
    "print (\"Training Dataset: \",len(Left_images)*0.7, \"Test Dataset: \", len(Left_images)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55524 samples, validate on 23796 samples\n",
      "Epoch 1/200\n",
      "55524/55524 [==============================] - ETA: 0s - loss: 199.5955 - fx_loss: 32.8186 - fy_loss: 32.8500 - u0_loss: 3.0667 - v0_loss: 3.0465 - baseline_loss: 2.7174 - disparity_loss: 0.7398 - x_loss: 1.3317 - y_loss: 1.2358 - z_loss: 1.2837 - pitch_loss: 36.6339 - xWorld_loss: 30.8398 - yWorld_loss: 10.1685 - zWorld_loss: 42.8744"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55524/55524 [==============================] - 753s 14ms/sample - loss: 199.5955 - fx_loss: 32.8186 - fy_loss: 32.8500 - u0_loss: 3.0667 - v0_loss: 3.0465 - baseline_loss: 2.7174 - disparity_loss: 0.7398 - x_loss: 1.3317 - y_loss: 1.2358 - z_loss: 1.2837 - pitch_loss: 36.6339 - xWorld_loss: 30.8398 - yWorld_loss: 10.1685 - zWorld_loss: 42.8744 - val_loss: 205.4225 - val_fx_loss: 38.9740 - val_fy_loss: 38.4132 - val_u0_loss: 1.8228 - val_v0_loss: 2.3322 - val_baseline_loss: 2.9468 - val_disparity_loss: 0.4624 - val_x_loss: 1.4437 - val_y_loss: 1.2912 - val_z_loss: 1.6651 - val_pitch_loss: 33.4523 - val_xWorld_loss: 30.9563 - val_yWorld_loss: 9.1898 - val_zWorld_loss: 42.4535\n",
      "Epoch 2/200\n",
      "55524/55524 [==============================] - 599s 11ms/sample - loss: 132.0197 - fx_loss: 13.5205 - fy_loss: 13.6583 - u0_loss: 1.0739 - v0_loss: 1.0299 - baseline_loss: 2.9676 - disparity_loss: 0.2983 - x_loss: 1.4864 - y_loss: 0.9898 - z_loss: 1.4879 - pitch_loss: 16.4331 - xWorld_loss: 29.8850 - yWorld_loss: 7.0789 - zWorld_loss: 42.1013 - val_loss: 118.9951 - val_fx_loss: 8.8437 - val_fy_loss: 8.7418 - val_u0_loss: 1.3880 - val_v0_loss: 1.5707 - val_baseline_loss: 2.9834 - val_disparity_loss: 0.2248 - val_x_loss: 1.3086 - val_y_loss: 0.8182 - val_z_loss: 1.6101 - val_pitch_loss: 14.4089 - val_xWorld_loss: 29.7212 - val_yWorld_loss: 5.1853 - val_zWorld_loss: 42.1791\n",
      "Epoch 3/200\n",
      "55524/55524 [==============================] - 557s 10ms/sample - loss: 111.8619 - fx_loss: 7.2213 - fy_loss: 7.2137 - u0_loss: 0.7421 - v0_loss: 0.7065 - baseline_loss: 2.9745 - disparity_loss: 0.1851 - x_loss: 1.4073 - y_loss: 0.7536 - z_loss: 1.4562 - pitch_loss: 12.6756 - xWorld_loss: 29.5510 - yWorld_loss: 5.2299 - zWorld_loss: 41.7441 - val_loss: 110.3383 - val_fx_loss: 7.2127 - val_fy_loss: 7.7863 - val_u0_loss: 1.5574 - val_v0_loss: 1.6752 - val_baseline_loss: 2.9492 - val_disparity_loss: 0.2298 - val_x_loss: 1.3943 - val_y_loss: 0.7099 - val_z_loss: 1.3387 - val_pitch_loss: 8.9840 - val_xWorld_loss: 29.4771 - val_yWorld_loss: 4.7497 - val_zWorld_loss: 42.2898\n",
      "Epoch 4/200\n",
      "55524/55524 [==============================] - 558s 10ms/sample - loss: 103.0713 - fx_loss: 5.4950 - fy_loss: 5.4253 - u0_loss: 0.6562 - v0_loss: 0.6111 - baseline_loss: 2.9190 - disparity_loss: 0.1666 - x_loss: 1.1542 - y_loss: 0.6634 - z_loss: 1.2674 - pitch_loss: 11.0728 - xWorld_loss: 28.5259 - yWorld_loss: 4.5436 - zWorld_loss: 40.5807 - val_loss: 121.4159 - val_fx_loss: 10.3488 - val_fy_loss: 9.9073 - val_u0_loss: 3.0525 - val_v0_loss: 2.7882 - val_baseline_loss: 2.8995 - val_disparity_loss: 0.3812 - val_x_loss: 1.2130 - val_y_loss: 0.8237 - val_z_loss: 1.3660 - val_pitch_loss: 12.9414 - val_xWorld_loss: 28.8563 - val_yWorld_loss: 5.6137 - val_zWorld_loss: 41.2431\n",
      "Epoch 5/200\n",
      "55524/55524 [==============================] - 561s 10ms/sample - loss: 97.6116 - fx_loss: 4.4192 - fy_loss: 4.3050 - u0_loss: 0.5519 - v0_loss: 0.5315 - baseline_loss: 2.8755 - disparity_loss: 0.1542 - x_loss: 0.9463 - y_loss: 0.5907 - z_loss: 1.1063 - pitch_loss: 12.1587 - xWorld_loss: 27.0745 - yWorld_loss: 3.8472 - zWorld_loss: 39.0697 - val_loss: 114.9416 - val_fx_loss: 13.1153 - val_fy_loss: 12.5958 - val_u0_loss: 0.4170 - val_v0_loss: 0.4559 - val_baseline_loss: 2.8636 - val_disparity_loss: 0.1673 - val_x_loss: 1.1057 - val_y_loss: 0.7639 - val_z_loss: 1.1490 - val_pitch_loss: 10.7876 - val_xWorld_loss: 27.3145 - val_yWorld_loss: 5.2212 - val_zWorld_loss: 38.9733\n",
      "Epoch 6/200\n",
      "55524/55524 [==============================] - 656s 12ms/sample - loss: 92.7353 - fx_loss: 3.8828 - fy_loss: 3.7515 - u0_loss: 0.4601 - v0_loss: 0.4384 - baseline_loss: 2.8359 - disparity_loss: 0.1489 - x_loss: 0.9079 - y_loss: 0.5306 - z_loss: 1.0161 - pitch_loss: 11.3611 - xWorld_loss: 27.1117 - yWorld_loss: 3.4724 - zWorld_loss: 36.8326 - val_loss: 97.5910 - val_fx_loss: 4.4563 - val_fy_loss: 3.6765 - val_u0_loss: 0.5373 - val_v0_loss: 0.7432 - val_baseline_loss: 2.8226 - val_disparity_loss: 0.1653 - val_x_loss: 0.7649 - val_y_loss: 0.4631 - val_z_loss: 0.9269 - val_pitch_loss: 9.7798 - val_xWorld_loss: 30.3998 - val_yWorld_loss: 2.9037 - val_zWorld_loss: 39.9637\n",
      "Epoch 7/200\n",
      "55524/55524 [==============================] - 712s 13ms/sample - loss: 91.3243 - fx_loss: 3.3560 - fy_loss: 3.3141 - u0_loss: 0.4151 - v0_loss: 0.4024 - baseline_loss: 2.8246 - disparity_loss: 0.1372 - x_loss: 0.9293 - y_loss: 0.4990 - z_loss: 1.0655 - pitch_loss: 9.3950 - xWorld_loss: 28.7410 - yWorld_loss: 3.0903 - zWorld_loss: 37.1530 - val_loss: 95.4412 - val_fx_loss: 6.4328 - val_fy_loss: 5.9297 - val_u0_loss: 0.7032 - val_v0_loss: 0.6989 - val_baseline_loss: 2.8135 - val_disparity_loss: 0.1158 - val_x_loss: 1.0890 - val_y_loss: 0.4937 - val_z_loss: 1.0214 - val_pitch_loss: 7.5946 - val_xWorld_loss: 29.7822 - val_yWorld_loss: 2.6743 - val_zWorld_loss: 36.0783\n",
      "Epoch 8/200\n",
      "55524/55524 [==============================] - 700s 13ms/sample - loss: 84.8552 - fx_loss: 3.0575 - fy_loss: 3.0207 - u0_loss: 0.3735 - v0_loss: 0.3599 - baseline_loss: 2.7943 - disparity_loss: 0.1200 - x_loss: 0.8578 - y_loss: 0.4469 - z_loss: 1.0009 - pitch_loss: 9.9485 - xWorld_loss: 26.9545 - yWorld_loss: 2.7337 - zWorld_loss: 33.1950 - val_loss: 84.2937 - val_fx_loss: 3.6172 - val_fy_loss: 2.1912 - val_u0_loss: 1.2777 - val_v0_loss: 1.0400 - val_baseline_loss: 2.7922 - val_disparity_loss: 0.1546 - val_x_loss: 0.7995 - val_y_loss: 0.3659 - val_z_loss: 0.9961 - val_pitch_loss: 9.6988 - val_xWorld_loss: 26.2621 - val_yWorld_loss: 2.2433 - val_zWorld_loss: 32.8949\n",
      "Epoch 9/200\n",
      "55524/55524 [==============================] - 674s 12ms/sample - loss: 84.7034 - fx_loss: 2.7420 - fy_loss: 2.7302 - u0_loss: 0.3314 - v0_loss: 0.3187 - baseline_loss: 2.7890 - disparity_loss: 0.1209 - x_loss: 0.8319 - y_loss: 0.4132 - z_loss: 0.9453 - pitch_loss: 11.7057 - xWorld_loss: 26.7033 - yWorld_loss: 2.5566 - zWorld_loss: 32.5525 - val_loss: 88.9466 - val_fx_loss: 3.5363 - val_fy_loss: 2.0463 - val_u0_loss: 0.9437 - val_v0_loss: 1.2464 - val_baseline_loss: 2.7780 - val_disparity_loss: 0.0935 - val_x_loss: 0.7737 - val_y_loss: 0.3511 - val_z_loss: 0.9445 - val_pitch_loss: 7.6281 - val_xWorld_loss: 28.9166 - val_yWorld_loss: 2.4096 - val_zWorld_loss: 37.2853\n",
      "Epoch 10/200\n",
      "55524/55524 [==============================] - 693s 12ms/sample - loss: 80.2737 - fx_loss: 2.3450 - fy_loss: 2.3071 - u0_loss: 0.3162 - v0_loss: 0.3038 - baseline_loss: 2.7647 - disparity_loss: 0.1051 - x_loss: 0.8244 - y_loss: 0.3936 - z_loss: 0.9886 - pitch_loss: 9.1269 - xWorld_loss: 26.2146 - yWorld_loss: 2.2517 - zWorld_loss: 32.3457 - val_loss: 87.1701 - val_fx_loss: 2.7369 - val_fy_loss: 1.9638 - val_u0_loss: 0.7554 - val_v0_loss: 0.6056 - val_baseline_loss: 2.7686 - val_disparity_loss: 0.0928 - val_x_loss: 0.8263 - val_y_loss: 0.3502 - val_z_loss: 0.9959 - val_pitch_loss: 7.7433 - val_xWorld_loss: 30.4926 - val_yWorld_loss: 2.5301 - val_zWorld_loss: 35.3139\n",
      "Epoch 11/200\n",
      "55524/55524 [==============================] - 711s 13ms/sample - loss: 79.1014 - fx_loss: 2.1768 - fy_loss: 2.1285 - u0_loss: 0.2978 - v0_loss: 0.2785 - baseline_loss: 2.7568 - disparity_loss: 0.0942 - x_loss: 0.7767 - y_loss: 0.3728 - z_loss: 0.9829 - pitch_loss: 8.6286 - xWorld_loss: 26.2589 - yWorld_loss: 2.0932 - zWorld_loss: 32.2591 - val_loss: 82.2367 - val_fx_loss: 3.1992 - val_fy_loss: 2.9898 - val_u0_loss: 0.2387 - val_v0_loss: 0.2778 - val_baseline_loss: 2.7630 - val_disparity_loss: 0.0681 - val_x_loss: 0.7679 - val_y_loss: 0.3902 - val_z_loss: 0.9521 - val_pitch_loss: 8.4546 - val_xWorld_loss: 27.6143 - val_yWorld_loss: 2.2513 - val_zWorld_loss: 32.2554\n",
      "Epoch 12/200\n",
      "55524/55524 [==============================] - 700s 13ms/sample - loss: 78.1416 - fx_loss: 2.0554 - fy_loss: 2.0276 - u0_loss: 0.2928 - v0_loss: 0.2879 - baseline_loss: 2.7307 - disparity_loss: 0.1023 - x_loss: 0.7510 - y_loss: 0.3518 - z_loss: 0.9285 - pitch_loss: 9.7814 - xWorld_loss: 25.3874 - yWorld_loss: 1.9766 - zWorld_loss: 31.4754 - val_loss: 73.0758 - val_fx_loss: 1.9111 - val_fy_loss: 1.9442 - val_u0_loss: 0.3451 - val_v0_loss: 0.5617 - val_baseline_loss: 2.6811 - val_disparity_loss: 0.2416 - val_x_loss: 0.7550 - val_y_loss: 0.3168 - val_z_loss: 0.8497 - val_pitch_loss: 12.6778 - val_xWorld_loss: 22.0365 - val_yWorld_loss: 3.1418 - val_zWorld_loss: 25.6303\n",
      "Epoch 13/200\n",
      "55524/55524 [==============================] - 677s 12ms/sample - loss: 75.1618 - fx_loss: 2.5252 - fy_loss: 2.4851 - u0_loss: 0.2763 - v0_loss: 0.2725 - baseline_loss: 2.6424 - disparity_loss: 0.1510 - x_loss: 0.7042 - y_loss: 0.3657 - z_loss: 0.8819 - pitch_loss: 13.7634 - xWorld_loss: 21.6586 - yWorld_loss: 2.1402 - zWorld_loss: 27.3040 - val_loss: 83.7744 - val_fx_loss: 1.8114 - val_fy_loss: 1.9398 - val_u0_loss: 0.7214 - val_v0_loss: 0.7107 - val_baseline_loss: 2.6249 - val_disparity_loss: 0.1245 - val_x_loss: 0.6746 - val_y_loss: 0.2896 - val_z_loss: 0.9059 - val_pitch_loss: 12.1288 - val_xWorld_loss: 29.1224 - val_yWorld_loss: 1.5545 - val_zWorld_loss: 31.1675\n",
      "Epoch 14/200\n",
      "55524/55524 [==============================] - 712s 13ms/sample - loss: 77.3929 - fx_loss: 2.0730 - fy_loss: 2.0766 - u0_loss: 0.2597 - v0_loss: 0.2527 - baseline_loss: 2.5876 - disparity_loss: 0.1063 - x_loss: 0.6756 - y_loss: 0.3448 - z_loss: 0.8556 - pitch_loss: 11.4241 - xWorld_loss: 24.0786 - yWorld_loss: 1.9000 - zWorld_loss: 30.7651 - val_loss: 87.8184 - val_fx_loss: 2.9479 - val_fy_loss: 2.1332 - val_u0_loss: 0.2341 - val_v0_loss: 0.3319 - val_baseline_loss: 2.6433 - val_disparity_loss: 0.0906 - val_x_loss: 0.6464 - val_y_loss: 0.3075 - val_z_loss: 0.7945 - val_pitch_loss: 10.5936 - val_xWorld_loss: 28.6384 - val_yWorld_loss: 2.2634 - val_zWorld_loss: 36.1937\n",
      "Epoch 15/200\n",
      "55524/55524 [==============================] - 700s 13ms/sample - loss: 78.2797 - fx_loss: 2.1763 - fy_loss: 2.1592 - u0_loss: 0.2569 - v0_loss: 0.2570 - baseline_loss: 2.6248 - disparity_loss: 0.0968 - x_loss: 0.6837 - y_loss: 0.3522 - z_loss: 0.8664 - pitch_loss: 10.7622 - xWorld_loss: 24.7411 - yWorld_loss: 1.9465 - zWorld_loss: 31.3486 - val_loss: 74.8429 - val_fx_loss: 2.5155 - val_fy_loss: 3.2129 - val_u0_loss: 0.6649 - val_v0_loss: 0.5197 - val_baseline_loss: 2.5891 - val_disparity_loss: 0.0964 - val_x_loss: 0.6522 - val_y_loss: 0.2846 - val_z_loss: 0.8581 - val_pitch_loss: 11.0911 - val_xWorld_loss: 22.1594 - val_yWorld_loss: 1.8026 - val_zWorld_loss: 28.4346\n",
      "Epoch 16/200\n",
      "55524/55524 [==============================] - 672s 12ms/sample - loss: 74.6228 - fx_loss: 2.4111 - fy_loss: 2.3991 - u0_loss: 0.2708 - v0_loss: 0.2667 - baseline_loss: 2.5115 - disparity_loss: 0.1217 - x_loss: 0.6786 - y_loss: 0.3545 - z_loss: 0.8681 - pitch_loss: 14.1900 - xWorld_loss: 21.0174 - yWorld_loss: 2.0078 - zWorld_loss: 27.5212 - val_loss: 72.6651 - val_fx_loss: 2.2124 - val_fy_loss: 2.8252 - val_u0_loss: 0.6649 - val_v0_loss: 0.4377 - val_baseline_loss: 2.4285 - val_disparity_loss: 0.1042 - val_x_loss: 0.7488 - val_y_loss: 0.3048 - val_z_loss: 0.8825 - val_pitch_loss: 13.9301 - val_xWorld_loss: 20.1980 - val_yWorld_loss: 1.8177 - val_zWorld_loss: 26.0972\n",
      "Epoch 17/200\n",
      "55524/55524 [==============================] - 562s 10ms/sample - loss: 74.0821 - fx_loss: 2.9723 - fy_loss: 2.9618 - u0_loss: 0.2610 - v0_loss: 0.2448 - baseline_loss: 2.2998 - disparity_loss: 0.1583 - x_loss: 0.6453 - y_loss: 0.3652 - z_loss: 0.8104 - pitch_loss: 18.5884 - xWorld_loss: 18.7539 - yWorld_loss: 2.0857 - zWorld_loss: 23.9437 - val_loss: 90.4039 - val_fx_loss: 3.9461 - val_fy_loss: 4.0299 - val_u0_loss: 0.1843 - val_v0_loss: 0.1315 - val_baseline_loss: 2.0624 - val_disparity_loss: 0.3992 - val_x_loss: 0.5837 - val_y_loss: 0.3917 - val_z_loss: 0.8116 - val_pitch_loss: 22.3882 - val_xWorld_loss: 26.5533 - val_yWorld_loss: 1.9610 - val_zWorld_loss: 26.9447\n",
      "Epoch 18/200\n",
      "55524/55524 [==============================] - 537s 10ms/sample - loss: 83.9717 - fx_loss: 4.0250 - fy_loss: 3.9863 - u0_loss: 0.2506 - v0_loss: 0.2463 - baseline_loss: 1.9818 - disparity_loss: 0.4081 - x_loss: 0.4941 - y_loss: 0.4360 - z_loss: 0.8111 - pitch_loss: 20.6984 - xWorld_loss: 21.5814 - yWorld_loss: 2.5609 - zWorld_loss: 26.4816 - val_loss: 79.3510 - val_fx_loss: 3.8610 - val_fy_loss: 4.3351 - val_u0_loss: 0.6682 - val_v0_loss: 0.7027 - val_baseline_loss: 2.0274 - val_disparity_loss: 0.4255 - val_x_loss: 0.5706 - val_y_loss: 0.4057 - val_z_loss: 0.7307 - val_pitch_loss: 18.5933 - val_xWorld_loss: 22.7951 - val_yWorld_loss: 2.7029 - val_zWorld_loss: 21.5175\n",
      "Epoch 19/200\n",
      "55524/55524 [==============================] - 539s 10ms/sample - loss: 83.3255 - fx_loss: 3.5546 - fy_loss: 3.5745 - u0_loss: 0.2837 - v0_loss: 0.2666 - baseline_loss: 2.1037 - disparity_loss: 0.3543 - x_loss: 0.5768 - y_loss: 0.4161 - z_loss: 0.7613 - pitch_loss: 23.4944 - xWorld_loss: 21.0266 - yWorld_loss: 2.4322 - zWorld_loss: 24.4869 - val_loss: 69.6004 - val_fx_loss: 2.2842 - val_fy_loss: 2.2663 - val_u0_loss: 0.1360 - val_v0_loss: 0.2013 - val_baseline_loss: 2.1182 - val_disparity_loss: 0.2238 - val_x_loss: 0.5211 - val_y_loss: 0.3696 - val_z_loss: 0.7251 - val_pitch_loss: 28.2734 - val_xWorld_loss: 14.3413 - val_yWorld_loss: 2.0776 - val_zWorld_loss: 16.0453\n",
      "Epoch 20/200\n",
      "55524/55524 [==============================] - 541s 10ms/sample - loss: 73.1580 - fx_loss: 2.4241 - fy_loss: 2.3978 - u0_loss: 0.2378 - v0_loss: 0.2336 - baseline_loss: 2.1314 - disparity_loss: 0.2111 - x_loss: 0.5812 - y_loss: 0.3481 - z_loss: 0.7081 - pitch_loss: 19.5192 - xWorld_loss: 20.0067 - yWorld_loss: 2.0603 - zWorld_loss: 22.2956 - val_loss: 67.6306 - val_fx_loss: 1.4947 - val_fy_loss: 1.5681 - val_u0_loss: 0.2371 - val_v0_loss: 0.1320 - val_baseline_loss: 2.1357 - val_disparity_loss: 0.2075 - val_x_loss: 0.5538 - val_y_loss: 0.2642 - val_z_loss: 0.6678 - val_pitch_loss: 16.2361 - val_xWorld_loss: 20.5271 - val_yWorld_loss: 2.2027 - val_zWorld_loss: 21.3879\n",
      "Epoch 21/200\n",
      "55524/55524 [==============================] - 540s 10ms/sample - loss: 69.9269 - fx_loss: 2.0093 - fy_loss: 2.0392 - u0_loss: 0.2182 - v0_loss: 0.2169 - baseline_loss: 2.0914 - disparity_loss: 0.1987 - x_loss: 0.5985 - y_loss: 0.3094 - z_loss: 0.6416 - pitch_loss: 19.5759 - xWorld_loss: 18.9037 - yWorld_loss: 1.8279 - zWorld_loss: 21.3102 - val_loss: 74.6409 - val_fx_loss: 2.1228 - val_fy_loss: 1.9959 - val_u0_loss: 0.4383 - val_v0_loss: 0.4636 - val_baseline_loss: 2.0246 - val_disparity_loss: 0.3444 - val_x_loss: 0.4621 - val_y_loss: 0.2663 - val_z_loss: 0.6256 - val_pitch_loss: 18.1722 - val_xWorld_loss: 24.3207 - val_yWorld_loss: 1.8234 - val_zWorld_loss: 21.5799\n",
      "Epoch 22/200\n",
      "55524/55524 [==============================] - 541s 10ms/sample - loss: 68.9267 - fx_loss: 2.8939 - fy_loss: 2.9239 - u0_loss: 0.2206 - v0_loss: 0.2028 - baseline_loss: 2.0008 - disparity_loss: 0.4314 - x_loss: 0.4356 - y_loss: 0.3466 - z_loss: 0.5886 - pitch_loss: 19.4767 - xWorld_loss: 17.8409 - yWorld_loss: 2.0671 - zWorld_loss: 19.5164 - val_loss: 65.5581 - val_fx_loss: 1.8558 - val_fy_loss: 2.1101 - val_u0_loss: 0.4320 - val_v0_loss: 0.3994 - val_baseline_loss: 2.0037 - val_disparity_loss: 0.4662 - val_x_loss: 0.5702 - val_y_loss: 0.2775 - val_z_loss: 0.5502 - val_pitch_loss: 19.2823 - val_xWorld_loss: 17.2361 - val_yWorld_loss: 1.9531 - val_zWorld_loss: 18.4261\n",
      "Epoch 23/200\n",
      "55524/55524 [==============================] - 546s 10ms/sample - loss: 68.1937 - fx_loss: 2.2705 - fy_loss: 2.2604 - u0_loss: 0.2210 - v0_loss: 0.2009 - baseline_loss: 2.0145 - disparity_loss: 0.6150 - x_loss: 0.4229 - y_loss: 0.3056 - z_loss: 0.6153 - pitch_loss: 17.8344 - xWorld_loss: 18.2777 - yWorld_loss: 1.9383 - zWorld_loss: 21.2405 - val_loss: 58.2156 - val_fx_loss: 1.7200 - val_fy_loss: 1.4483 - val_u0_loss: 0.1818 - val_v0_loss: 0.7169 - val_baseline_loss: 2.0216 - val_disparity_loss: 0.6351 - val_x_loss: 0.3344 - val_y_loss: 0.2262 - val_z_loss: 0.5534 - val_pitch_loss: 17.5257 - val_xWorld_loss: 15.0891 - val_yWorld_loss: 1.7039 - val_zWorld_loss: 16.0803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200\n",
      "55524/55524 [==============================] - 658s 12ms/sample - loss: 65.8180 - fx_loss: 2.0381 - fy_loss: 2.0658 - u0_loss: 0.1955 - v0_loss: 0.1884 - baseline_loss: 1.9818 - disparity_loss: 0.6787 - x_loss: 0.3800 - y_loss: 0.3049 - z_loss: 0.6217 - pitch_loss: 18.8962 - xWorld_loss: 16.4452 - yWorld_loss: 1.8998 - zWorld_loss: 20.1267 - val_loss: 71.9468 - val_fx_loss: 2.4203 - val_fy_loss: 1.8897 - val_u0_loss: 0.1533 - val_v0_loss: 0.6802 - val_baseline_loss: 1.9807 - val_disparity_loss: 0.7115 - val_x_loss: 0.3789 - val_y_loss: 0.2289 - val_z_loss: 0.5466 - val_pitch_loss: 17.5993 - val_xWorld_loss: 20.9867 - val_yWorld_loss: 1.7483 - val_zWorld_loss: 22.6278\n",
      "Epoch 25/200\n",
      "55524/55524 [==============================] - 595s 11ms/sample - loss: 62.3321 - fx_loss: 2.0131 - fy_loss: 2.0604 - u0_loss: 0.1916 - v0_loss: 0.1839 - baseline_loss: 1.9555 - disparity_loss: 0.6506 - x_loss: 0.3343 - y_loss: 0.2854 - z_loss: 0.5572 - pitch_loss: 16.2838 - xWorld_loss: 16.5201 - yWorld_loss: 1.7418 - zWorld_loss: 19.5501 - val_loss: 66.3372 - val_fx_loss: 1.8216 - val_fy_loss: 1.9351 - val_u0_loss: 0.6218 - val_v0_loss: 0.5494 - val_baseline_loss: 1.9207 - val_disparity_loss: 0.6028 - val_x_loss: 0.3231 - val_y_loss: 0.2218 - val_z_loss: 0.5313 - val_pitch_loss: 14.4702 - val_xWorld_loss: 20.6212 - val_yWorld_loss: 1.3243 - val_zWorld_loss: 21.4015\n",
      "Epoch 26/200\n",
      "55524/55524 [==============================] - 539s 10ms/sample - loss: 62.4977 - fx_loss: 2.2868 - fy_loss: 2.2941 - u0_loss: 0.1935 - v0_loss: 0.1829 - baseline_loss: 1.8953 - disparity_loss: 0.5460 - x_loss: 0.3429 - y_loss: 0.3139 - z_loss: 0.5489 - pitch_loss: 17.9433 - xWorld_loss: 15.3577 - yWorld_loss: 1.9052 - zWorld_loss: 18.6909 - val_loss: 87.2429 - val_fx_loss: 1.7364 - val_fy_loss: 2.0373 - val_u0_loss: 0.1539 - val_v0_loss: 0.3244 - val_baseline_loss: 1.8885 - val_disparity_loss: 0.6422 - val_x_loss: 0.3472 - val_y_loss: 0.2737 - val_z_loss: 0.5753 - val_pitch_loss: 17.5256 - val_xWorld_loss: 30.5920 - val_yWorld_loss: 1.8248 - val_zWorld_loss: 29.3608\n",
      "Epoch 27/200\n",
      "55524/55524 [==============================] - 540s 10ms/sample - loss: 62.6382 - fx_loss: 2.0976 - fy_loss: 2.1590 - u0_loss: 0.1886 - v0_loss: 0.1815 - baseline_loss: 1.8307 - disparity_loss: 0.6238 - x_loss: 0.3336 - y_loss: 0.3161 - z_loss: 0.5410 - pitch_loss: 17.7863 - xWorld_loss: 16.1238 - yWorld_loss: 1.9094 - zWorld_loss: 18.5449 - val_loss: 64.2072 - val_fx_loss: 1.9649 - val_fy_loss: 1.9651 - val_u0_loss: 0.1139 - val_v0_loss: 0.6944 - val_baseline_loss: 1.7511 - val_disparity_loss: 0.6990 - val_x_loss: 0.2500 - val_y_loss: 0.2133 - val_z_loss: 0.4092 - val_pitch_loss: 17.3716 - val_xWorld_loss: 19.5230 - val_yWorld_loss: 1.3948 - val_zWorld_loss: 17.8385\n",
      "Epoch 28/200\n",
      "55524/55524 [==============================] - ETA: 0s - loss: 65.2599 - fx_loss: 2.3949 - fy_loss: 2.4408 - u0_loss: 0.2061 - v0_loss: 0.2004 - baseline_loss: 1.7324 - disparity_loss: 0.7774 - x_loss: 0.3195 - y_loss: 0.3019 - z_loss: 0.5089 - pitch_loss: 16.8763 - xWorld_loss: 17.3957 - yWorld_loss: 1.8723 - zWorld_loss: 20.2383Restoring model weights from the end of the best epoch.\n",
      "55524/55524 [==============================] - 544s 10ms/sample - loss: 65.2599 - fx_loss: 2.3949 - fy_loss: 2.4408 - u0_loss: 0.2061 - v0_loss: 0.2004 - baseline_loss: 1.7324 - disparity_loss: 0.7774 - x_loss: 0.3195 - y_loss: 0.3019 - z_loss: 0.5089 - pitch_loss: 16.8763 - xWorld_loss: 17.3957 - yWorld_loss: 1.8723 - zWorld_loss: 20.2383 - val_loss: 90.3328 - val_fx_loss: 1.7243 - val_fy_loss: 3.0631 - val_u0_loss: 0.7666 - val_v0_loss: 0.9432 - val_baseline_loss: 1.6686 - val_disparity_loss: 1.1241 - val_x_loss: 0.3034 - val_y_loss: 0.2893 - val_z_loss: 0.6391 - val_pitch_loss: 14.5287 - val_xWorld_loss: 27.2904 - val_yWorld_loss: 2.0288 - val_zWorld_loss: 35.9649\n",
      "Epoch 00028: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "model_name = 'model_multi_class/'\n",
    "SAVE = \"new_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "# Save\n",
    "output_folder = SAVE + model_name\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "output_log = output_folder + \"Log/\"\n",
    "if not os.path.exists(output_log):\n",
    "    os.makedirs(output_log)\n",
    "\n",
    "output_weight = output_folder + \"Best/\"\n",
    "if not os.path.exists(output_weight):\n",
    "    os.makedirs(output_weight)\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=output_log)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    model_for_saving=model,\n",
    "    filepath=output_weight + \"weights_{epoch:02d}_{val_loss:.2f}.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[Left_images[:int(len(Left_images)*0.7)], Right_images[:int(len(Left_images)*0.7)]],\n",
    "    y=[Fx[:int(len(Left_images)*0.7)], Fy[:int(len(Left_images)*0.7)], U0[:int(len(Left_images)*0.7)], V0[:int(len(Left_images)*0.7)], Baseline[:int(len(Left_images)*0.7)], Disparity[:int(len(Left_images)*0.7)], Tx[:int(len(Left_images)*0.7)], Ty[:int(len(Left_images)*0.7)], Tz[:int(len(Left_images)*0.7)], Pitch[:int(len(Left_images)*0.7)], X[:int(len(Left_images)*0.7)], Y[:int(len(Left_images)*0.7)], Z[:int(len(Left_images)*0.7)]],\n",
    "    batch_size=16,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    validation_data=([Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]], [Fx[int(len(Left_images)*0.7):], Fy[int(len(Left_images)*0.7):], U0[int(len(Left_images)*0.7):], V0[int(len(Left_images)*0.7):], Baseline[int(len(Left_images)*0.7):], Disparity[int(len(Left_images)*0.7):], Tx[int(len(Left_images)*0.7):], Ty[int(len(Left_images)*0.7):], Tz[int(len(Left_images)*0.7):], Pitch[int(len(Left_images)*0.7):], X[int(len(Left_images)*0.7):], Y[int(len(Left_images)*0.7):], Z[int(len(Left_images)*0.7):]]),\n",
    "    callbacks=[tensorboard, checkpointer, early_stopping, csv_logger]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "model.load_weights('./new_logs/20220908-131230/model_multi_class/Best/weights_23_58.22.h5')\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "\n",
    "output = model.predict(\n",
    "    x=[Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]],\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23796, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% Correct')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "th_0 = 0\n",
    "th_1 = 0\n",
    "th_2 = 0\n",
    "th_3 = 0\n",
    "th_4 = 0\n",
    "th_5 = 0\n",
    "\n",
    "percent_correct = []\n",
    "\n",
    "k = 55524\n",
    "\n",
    "for i  in range(np.shape(output)[1]):\n",
    "    \n",
    "    predicted_fov = 2*np.arctan(112/(2*output[0][i][0]))\n",
    "    actual_fov = 2*np.arctan(112/(2*Fx[k]))\n",
    "    \n",
    "    if abs(predicted_fov - actual_fov) <= 0:\n",
    "        \n",
    "        th_0 += 1 \n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 1:\n",
    "        \n",
    "        th_1 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 2:\n",
    "        \n",
    "        th_2 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 3:\n",
    "        \n",
    "        th_3 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 4:\n",
    "        \n",
    "        th_4 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 5:\n",
    "        \n",
    "        th_5 += 1\n",
    "        \n",
    "    k += 1\n",
    "\n",
    "percent_correct.append(th_0/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_1/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_2/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_3/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_4/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_5/np.shape(output)[1]*100)\n",
    "\n",
    "plt.plot([0,1,2,3,4,5],percent_correct)\n",
    "plt.xlabel(\"FOV Error Threshold (degrees)\")\n",
    "plt.ylabel(\"% Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 23737, 23794, 23796, 23796, 23796)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0, th_1, th_2, th_3, th_4, th_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.9975205916960834, 0.9999159522608841, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0/np.shape(output)[1], th_1/np.shape(output)[1], th_2/np.shape(output)[1], th_3/np.shape(output)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 1.7203366214287756, 'fy': 1.4489545759413487, 'u0': 0.1817660600242544, 'v0': 0.7168212601428754, 'baseline': 2.0212013848911194, 'disparity': 0.6347296211487513, 'x': 0.33405547099747485, 'y': 0.22606784079751763, 'z': 0.553045160380867, 'pitch': 17.526308870852585, 'xworld': 15.08453204150905, 'yworld': 1.7003544984662247, 'zworld': 16.06738446825849}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math \n",
    "\n",
    "def normalize(x):\n",
    "    \n",
    "    return (math.atan(x) + 3.14/2) / 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.8843963428617811, 'fy': 0.9114423831145054, 'u0': 0.7282263956665703, 'v0': 0.6373140539925413, 'baseline': 0.8732234974660816, 'disparity': 0.6210554186664111, 'x': 0.7347879211851821, 'y': 0.7188259027103718, 'z': 0.7334200235350675, 'pitch': 0.9524821243477615, 'xworld': 0.9656370923642681, 'yworld': 0.9002662165885574, 'zworld': 0.9758289870726622}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fx - actual_fx))\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fy - actual_fy))\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_u0 - actual_u0))\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_v0 - actual_v0))\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_baseline - actual_baseline))\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_disparity - actual_disparity))\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tx - actual_tx))\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_ty - actual_ty))\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tz - actual_tz))\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_pitch - actual_pitch))\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_x - actual_x))\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_y - actual_y))\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_z - actual_z))\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.02463748515183124, 'fy': 0.02831664666868909, 'u0': 0.02294115505902206, 'v0': 0.017306714223111433, 'baseline': 0.12978495358614217, 'disparity': 0.01774838413167217, 'x': 0.055404124404127224, 'y': 0.03276949154431778, 'z': 0.07197428159761873, 'pitch': 0.019904880198233815, 'xworld': 0.08421927624064439, 'yworld': 0.018279980683418177, 'zworld': 0.1307571785332731}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "min_fx = 1.9073486e-06\n",
    "max_fx = 3214.9907\n",
    "\n",
    "min_fy = 2.9563904e-05\n",
    "max_fy = 2051.209\n",
    "\n",
    "min_u0 = 1.9073486e-05\n",
    "max_u0 = 2178.9983\n",
    "\n",
    "min_v0 = 3.8146973e-06\n",
    "max_v0 = 2385.7239\n",
    "\n",
    "min_baseline = 4.7683716e-06\n",
    "max_baseline = 22.68721567997021\n",
    "\n",
    "min_disparity = 9.536743e-07\n",
    "max_disparity = 134.60031\n",
    "\n",
    "min_tx = 2.384185791015625e-06\n",
    "max_tx = 22.68721567997021\n",
    "\n",
    "min_ty = 2.3841858e-07\n",
    "max_ty = 33.11693576309983\n",
    "\n",
    "min_tz = 2.3841858e-06\n",
    "max_tz = 17.20185265614626\n",
    "\n",
    "min_pitch = 4.57763671875e-05\n",
    "max_pitch = 4502.9224\n",
    "\n",
    "min_xw = 5.219264654243716e-06\n",
    "max_xw = 386.4486\n",
    "\n",
    "min_yw = 3.8146973e-06\n",
    "max_yw = 1835.1849\n",
    "\n",
    "min_zw = 0.00011349\n",
    "max_zw = 339.17166\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fx - actual_fx) - min_fx)/(max_fx - min_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fy - actual_fy) - min_fy)/(max_fy - min_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_u0 - actual_u0) - min_u0)/(max_u0 - min_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_v0 - actual_v0) - min_v0)/(max_v0 - min_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_baseline - actual_baseline) - min_baseline)/(max_baseline - min_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_disparity - actual_disparity) - min_disparity)/(max_disparity - min_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tx - actual_tx) - min_tx)/(max_tx - min_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_ty - actual_ty) - min_ty)/(max_ty - min_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tz - actual_tz) - min_tz)/(max_tz - min_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_pitch - actual_pitch) - min_pitch)/(max_pitch - min_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_x - actual_x) - min_xw)/(max_xw - min_xw)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_y - actual_y) - min_yw)/(max_yw - min_yw)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_z - actual_z) - min_zw)/(max_zw - min_zw)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.020308686620320718, 'fy': 0.017105003778522292, 'u0': 0.0032458225004331092, 'v0': 0.012800379645408429, 'baseline': 0.6444575063292809, 'disparity': 0.11262231350798388, 'x': 0.10651316460795186, 'y': 0.0687336817981936, 'z': 0.1932888205567041, 'pitch': 0.20729874140885132, 'xworld': 0.4771566168377753, 'yworld': 0.06776246639070894, 'zworld': 0.37619602554163734}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "mean_fx = 84.70939817976283\n",
    "\n",
    "mean_fy = 84.70939817976283\n",
    "\n",
    "mean_u0 = 56.0\n",
    "\n",
    "mean_v0 = 56.0\n",
    "\n",
    "mean_baseline = 3.1362834089762988\n",
    "\n",
    "mean_disparity = 5.6359135359419765\n",
    "\n",
    "mean_tx = 3.1362834089762988\n",
    "\n",
    "mean_ty = 3.2890401748192972\n",
    "\n",
    "mean_tz = 2.8612371827197847\n",
    "\n",
    "mean_pitch = 84.54614220877458\n",
    "\n",
    "mean_xw = 31.613377053172897\n",
    "\n",
    "mean_yw = 25.092866140117593\n",
    "\n",
    "mean_zw = 42.71013880363322\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx) / mean_fx\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy) / mean_fy\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0) / mean_u0\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0) / mean_v0\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline) / mean_baseline\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity) / mean_disparity\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx) / mean_tx\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty) / mean_ty\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz) / mean_tz\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch) / mean_pitch\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x) / mean_xw\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y) / mean_yw\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z) / mean_zw\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
