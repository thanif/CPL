# Camera-Calibration-through-Camera-Projection-Loss

Implementation of the paper "Camera Calibration through Camera Projection Loss": https://arxiv.org/pdf/2110.03479.pdf

Camera calibration is a necessity in various tasks including 3D reconstruction, hand-eye coordination for a robotic interaction, autonomous driving, etc. In this work we propose a novel method to predict extrinsic (baseline, pitch, and translation), intrinsic (focal length and principal point offset) parameters using an image pair. Unlike existing methods, instead of designing an end-to-end solution, we proposed a new representation that incorporates camera model equations as a
neural network in multi-task learning framework. We estimate the desired parameters via novel camera projection loss (CPL) that uses the camera model neural network to reconstruct the 3D points and uses the reconstruction loss to estimate the camera parameters. To the best of our knowledge, ours is the first method to jointly estimate both the intrinsic and extrinsic parameters via a multi-task learning methodology that combines analytical equations in learning framework
for the estimation of camera parameters. We also proposed a novel CVGL Camera Calibration dataset using CARLA Simulator. Empirically, we demonstrate that our proposed approach achieves better performance with respect to both deep learning-based and traditional methods on 8 out of 10 parameters evaluated using both synthetic and real data.

# Code for Camera  Calibration through Camera Projection Loss

Data_Preparation/data_preparation.ipynb converts the actual data into npy format used for experiments.

Data_Preparation/normalization_values.ipynb contains the normalization values used for evaluation.

Each model has been trained on the CVGL Camera Calibration Dataset while Tsinghua-Daimler Dataset (Real) has been used only for testing. 
Each folder contains 2 ipython notebooks, one for CVGL Dataset while the other for Tsinghua-Daimler Dataset (Real).

# Code for Multi-task Learning  for Camera Calibration

## Cityscapes Dataset has been added for evaluation

Data_Preparation/data_preparation_cityscapes.ipynb converts the actual data into npy format used for experiments.

Data_Preparation/normalization_values_cs.ipynb contains the normalization values used for evaluation.

Each folder contains a file ending with cs representing cityscapes dataset

# Weights and Logs for Camera Calibration through Camera Projection Loss

MTL-CPL-A: https://drive.google.com/drive/folders/16zR4Hn21VIgREbCr3AQlAAGMB6rT5rdw?usp=sharing

Deep-Homo: https://drive.google.com/drive/folders/1lrl1ccWgqRyb41rtZOW7CiL0DRA4SsF-?usp=sharing

MTL-Baseline: https://drive.google.com/drive/folders/1riHN9KyYmu06Pxvm7IXTiGGCdonAE5GO?usp=sharing

MTL-CPL-U: https://drive.google.com/drive/folders/1m1UHBzman_XJuF45HLeBHw1R3pbwdTif?usp=sharing

# Weights and Logs for Multi-task Learning for Camera Calibration

All the  weights are availale here: https://drive.google.com/drive/folders/1IJpjBnRmH_MXEsdFk6FYvU3guIrBehoG?usp=share_link

# Datasets

CVGL Camera Calibration Dataset without preprocessing: https://drive.google.com/drive/folders/11e0n1_W59PisKjmED3Ma6MKL8sJWinGZ?usp=sharing

CVGL Camera Calibration Dataset format used for experiments: https://drive.google.com/drive/folders/1ScuaGjZSXslYPkFzGJMLzTze5QScvMKA?usp=sharing

Tsinghua-Daimler Dataset (Real Dataset): http://www.gavrila.net/Datasets/Daimler_Pedestrian_Benchmark_D/Tsinghua-Daimler_Cyclist_Detec/tsinghua-daimler_cyclist_detec.html

Cityscapes Dataset (Real Dataset): https://www.cityscapes-dataset.com

# CVGL Camera Calibration Dataset

The dataset has been collected using the CARLA Simulator gear server available here: https://drive.google.com/file/d/1X52PXqT0phEi5WEWAISAQYZs-Ivx4VoE/view

The data collector used is available here: https://github.com/carla-simulator/data-collector

The dataset consists of 49 camera configurations with town 1 having 25 configurations while town 2 having 24 configurations. The parameters modified for generating the configurations include fov, x, y, z, pitch, yaw, and roll. Here, fov is the field of view, (x, y, z) is the translation while (pitch, yaw, and roll) is the rotation between the cameras. The total number of image pairs is 79,320, out of which 18,083 belong to Town 1 while 61,237 belong to Town 2, the difference in the number of images is due to the length of the tracks.

For each episode, there is a file named params.txt containing the following parameters: fov, x, y, z, pitch, yaw, roll.

Focal Length is computed as follows: img_size[0]/(2 * np.tan(fov * np.pi/360))

U0 and V0 are computed as: img_size[0]/2

Baseline is equal to the translation in x-axis.

Disparity value is computed using the following:

stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)

disparity_map = stereo.compute(l_im, r_im)

disparity_value = np.mean(disparity_map)

xcam, ycam, zcam are computed as follows:

xcam = (focal_length * x) / disparity_value
 
ycam = - (xcam / focal_length) * (5 - U0)
                
zcam = (xcam / focal_length) * (V0 - 5)

xworld, yworld, zworld are computed as follows:

yworld = ycam + y

xworld = xcam * math.cos(pitch) + zcam * math.sin(pitch) + x

zworld = - xcam * math.sin(pitch) + zcam * math.cos(pitch) + z

# Results from Camera Calibration through Camera Projection Loss

<div align="center">
    <img src="Results/results.png" </img> 
</div>

# Results from  Multi-task Learning for Camera Calibration

<div align="center">
    <img src="Results/results_2.jpg" </img> 
</div>

Some related articles are as follows:

How I got my MS Thesis Idea: https://thanifbutt.medium.com/how-i-got-my-thesis-idea-b64160a04d47

CVGL Camera Calibration Dataset: https://thanifbutt.medium.com/fast-lums-camera-calibration-dataset-98363918fcf6

Camera Calibration through Camera Projection Loss: https://thanifbutt.medium.com/camera-calibration-through-camera-projection-loss-e704ae6dbb29

# Citation

```
@article{butt2021camera,
  title={Camera Calibration through Camera Projection Loss},
  author={Butt, Talha Hanif and Taj, Murtaza},
  journal={arXiv preprint arXiv:2110.03479},
  year={2021}
}
```
