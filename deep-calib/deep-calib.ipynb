{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(1)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "\n",
    "if ros_path in sys.path:\n",
    "\n",
    "    sys.path.remove(ros_path)\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate, Dropout, Conv2D, MaxPooling2D, Flatten, Lambda, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from scipy.special import softmax\n",
    "from tensorflow.keras import optimizers\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_image (InputLayer)         [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 55, 55, 32)   864         left_image[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 55, 55, 32)   96          conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 55, 55, 32)   0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 53, 53, 32)   9216        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 53, 53, 32)   96          conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 53, 53, 32)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 53, 53, 64)   18432       activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 53, 53, 64)   192         conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 53, 53, 64)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 26, 26, 64)   0           activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 26, 26, 80)   5120        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 26, 26, 80)   240         conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 26, 26, 80)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 24, 24, 192)  138240      activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 24, 24, 192)  576         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 24, 24, 192)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 11, 11, 192)  0           activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 11, 11, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 11, 11, 64)   192         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 11, 11, 64)   0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 11, 11, 48)   9216        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 11, 11, 96)   55296       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 11, 11, 48)   144         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 11, 11, 96)   288         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 11, 11, 48)   0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 11, 11, 96)   0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 11, 11, 192)  0           max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 11, 11, 64)   12288       max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 11, 11, 64)   76800       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 11, 11, 96)   82944       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 11, 11, 32)   6144        average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 11, 11, 64)   192         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 11, 11, 64)   192         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 11, 11, 96)   288         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 11, 11, 32)   96          conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 11, 11, 64)   0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 11, 11, 64)   0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 11, 11, 96)   0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 11, 11, 32)   0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 11, 11, 256)  0           activation_193[0][0]             \n",
      "                                                                 activation_195[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 11, 11, 64)   16384       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 11, 11, 64)   192         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 11, 11, 64)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 11, 11, 48)   12288       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 11, 11, 96)   55296       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 11, 11, 48)   144         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 11, 11, 96)   288         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 11, 11, 48)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 11, 11, 96)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 11, 11, 256)  0           concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 11, 11, 64)   16384       concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 11, 11, 64)   76800       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 11, 11, 96)   82944       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 11, 11, 64)   16384       average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 11, 11, 64)   192         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 11, 11, 64)   192         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 11, 11, 96)   288         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 11, 11, 64)   192         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 11, 11, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 11, 11, 64)   0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 11, 11, 96)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 11, 11, 64)   0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 11, 11, 288)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "                                                                 activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 11, 11, 64)   18432       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 11, 11, 64)   192         conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 11, 11, 64)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 11, 11, 48)   13824       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 11, 11, 96)   55296       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 11, 11, 48)   144         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 11, 11, 96)   288         conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 11, 11, 48)   0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 11, 11, 96)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 11, 11, 288)  0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 11, 11, 64)   18432       concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 11, 11, 64)   76800       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 11, 11, 96)   82944       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 11, 11, 64)   18432       average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 11, 11, 64)   192         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 11, 11, 64)   192         conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 11, 11, 96)   288         conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 11, 11, 64)   192         conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 11, 11, 64)   0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 11, 11, 64)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 11, 11, 96)   0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 11, 11, 64)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 11, 11, 288)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 11, 11, 64)   18432       concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 11, 11, 64)   192         conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 11, 11, 64)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 11, 11, 96)   55296       activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 11, 11, 96)   288         conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 11, 11, 96)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 5, 5, 384)    995328      concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 5, 5, 96)     82944       activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 5, 5, 384)    1152        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 5, 5, 96)     288         conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 5, 5, 384)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 5, 5, 96)     0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 5, 5, 288)    0           concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 5, 5, 768)    0           activation_214[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 5, 5, 128)    98304       concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 5, 5, 128)    384         conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 5, 5, 128)    0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 5, 5, 128)    114688      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 5, 5, 128)    384         conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 5, 5, 128)    0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 5, 5, 128)    98304       concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 5, 5, 128)    114688      activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 5, 5, 128)    384         conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 5, 5, 128)    384         conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 5, 5, 128)    0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 5, 5, 128)    0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 5, 5, 128)    114688      activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 5, 5, 128)    114688      activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 5, 5, 128)    384         conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 5, 5, 128)    384         conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 5, 5, 128)    0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 5, 5, 128)    0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 5, 5, 768)    0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 5, 5, 192)    172032      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 5, 5, 192)    172032      activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 5, 5, 192)    147456      average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 5, 5, 192)    576         conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 5, 5, 192)    576         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 5, 5, 192)    576         conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 5, 5, 192)    576         conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 5, 5, 192)    0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 5, 5, 192)    0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 5, 5, 192)    0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 5, 5, 192)    0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 5, 5, 768)    0           activation_218[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_226[0][0]             \n",
      "                                                                 activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 5, 5, 160)    122880      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 5, 5, 160)    480         conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 5, 5, 160)    0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 5, 5, 160)    179200      activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 5, 5, 160)    480         conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 5, 5, 160)    0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 5, 5, 160)    122880      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 5, 5, 160)    179200      activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 5, 5, 160)    480         conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 5, 5, 160)    480         conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 5, 5, 160)    0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 5, 5, 160)    0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 5, 5, 160)    179200      activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 5, 5, 160)    179200      activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 5, 5, 160)    480         conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 5, 5, 160)    480         conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 5, 5, 160)    0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 5, 5, 160)    0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 5, 5, 768)    0           concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 5, 5, 192)    215040      activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 5, 5, 192)    215040      activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 5, 5, 192)    147456      average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 5, 5, 192)    576         conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 5, 5, 192)    576         conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 5, 5, 192)    576         conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 5, 5, 192)    576         conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 5, 5, 192)    0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 5, 5, 192)    0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 5, 5, 192)    0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 5, 5, 192)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 5, 5, 768)    0           activation_228[0][0]             \n",
      "                                                                 activation_231[0][0]             \n",
      "                                                                 activation_236[0][0]             \n",
      "                                                                 activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 5, 5, 160)    122880      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 5, 5, 160)    480         conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 5, 5, 160)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 5, 5, 160)    179200      activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 5, 5, 160)    480         conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 5, 5, 160)    0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 5, 5, 160)    122880      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 5, 5, 160)    179200      activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 5, 5, 160)    480         conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 5, 5, 160)    480         conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 5, 5, 160)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 5, 5, 160)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 5, 5, 160)    179200      activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 5, 5, 160)    179200      activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 5, 5, 160)    480         conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 5, 5, 160)    480         conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 5, 5, 160)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 5, 5, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 5, 5, 768)    0           concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 5, 5, 192)    215040      activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 5, 5, 192)    215040      activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 5, 5, 192)    147456      average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 5, 5, 192)    576         conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 5, 5, 192)    576         conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 5, 5, 192)    576         conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 5, 5, 192)    576         conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 5, 5, 192)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 5, 5, 192)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 5, 5, 192)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 5, 5, 192)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 5, 5, 768)    0           activation_238[0][0]             \n",
      "                                                                 activation_241[0][0]             \n",
      "                                                                 activation_246[0][0]             \n",
      "                                                                 activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 5, 5, 192)    576         conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 5, 5, 192)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 5, 5, 192)    258048      activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 5, 5, 192)    576         conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 5, 5, 192)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 5, 5, 192)    258048      activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 5, 5, 192)    576         conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 5, 5, 192)    576         conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 5, 5, 192)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 5, 5, 192)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 5, 5, 192)    258048      activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 5, 5, 192)    258048      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 5, 5, 192)    576         conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 5, 5, 192)    576         conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 5, 5, 192)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 5, 5, 192)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 5, 5, 768)    0           concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 5, 5, 192)    258048      activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 5, 5, 192)    258048      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_257 (Conv2D)             (None, 5, 5, 192)    147456      average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 5, 5, 192)    576         conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 5, 5, 192)    576         conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 5, 5, 192)    576         conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 5, 5, 192)    576         conv2d_257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 5, 5, 192)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 5, 5, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 5, 5, 192)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 5, 5, 192)    0           batch_normalization_257[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 5, 5, 768)    0           activation_248[0][0]             \n",
      "                                                                 activation_251[0][0]             \n",
      "                                                                 activation_256[0][0]             \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_260 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_260 (BatchN (None, 5, 5, 192)    576         conv2d_260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 5, 5, 192)    0           batch_normalization_260[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_261 (Conv2D)             (None, 5, 5, 192)    258048      activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_261 (BatchN (None, 5, 5, 192)    576         conv2d_261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 5, 5, 192)    0           batch_normalization_261[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_258 (Conv2D)             (None, 5, 5, 192)    147456      concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_262 (Conv2D)             (None, 5, 5, 192)    258048      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 5, 5, 192)    576         conv2d_258[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_262 (BatchN (None, 5, 5, 192)    576         conv2d_262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 5, 5, 192)    0           batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 5, 5, 192)    0           batch_normalization_262[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_259 (Conv2D)             (None, 2, 2, 320)    552960      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_263 (Conv2D)             (None, 2, 2, 192)    331776      activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_259 (BatchN (None, 2, 2, 320)    960         conv2d_259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_263 (BatchN (None, 2, 2, 192)    576         conv2d_263[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 2, 2, 320)    0           batch_normalization_259[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 2, 2, 192)    0           batch_normalization_263[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 2, 2, 768)    0           concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 2, 2, 1280)   0           activation_259[0][0]             \n",
      "                                                                 activation_263[0][0]             \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_268 (Conv2D)             (None, 2, 2, 448)    573440      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_268 (BatchN (None, 2, 2, 448)    1344        conv2d_268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 2, 2, 448)    0           batch_normalization_268[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_265 (Conv2D)             (None, 2, 2, 384)    491520      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_269 (Conv2D)             (None, 2, 2, 384)    1548288     activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_265 (BatchN (None, 2, 2, 384)    1152        conv2d_265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_269 (BatchN (None, 2, 2, 384)    1152        conv2d_269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 2, 2, 384)    0           batch_normalization_265[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 2, 2, 384)    0           batch_normalization_269[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_266 (Conv2D)             (None, 2, 2, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_267 (Conv2D)             (None, 2, 2, 384)    442368      activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_270 (Conv2D)             (None, 2, 2, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_271 (Conv2D)             (None, 2, 2, 384)    442368      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 2, 2, 1280)   0           concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_264 (Conv2D)             (None, 2, 2, 320)    409600      concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_266 (BatchN (None, 2, 2, 384)    1152        conv2d_266[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_267 (BatchN (None, 2, 2, 384)    1152        conv2d_267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_270 (BatchN (None, 2, 2, 384)    1152        conv2d_270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_271 (BatchN (None, 2, 2, 384)    1152        conv2d_271[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_272 (Conv2D)             (None, 2, 2, 192)    245760      average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_264 (BatchN (None, 2, 2, 320)    960         conv2d_264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 2, 2, 384)    0           batch_normalization_266[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 2, 2, 384)    0           batch_normalization_267[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 2, 2, 384)    0           batch_normalization_270[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 2, 2, 384)    0           batch_normalization_271[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_272 (BatchN (None, 2, 2, 192)    576         conv2d_272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 2, 2, 320)    0           batch_normalization_264[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 2, 2, 768)    0           activation_266[0][0]             \n",
      "                                                                 activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 2, 2, 768)    0           activation_270[0][0]             \n",
      "                                                                 activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 2, 2, 192)    0           batch_normalization_272[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 2, 2, 2048)   0           activation_264[0][0]             \n",
      "                                                                 concatenate_39[0][0]             \n",
      "                                                                 concatenate_40[0][0]             \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_277 (Conv2D)             (None, 2, 2, 448)    917504      concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_277 (BatchN (None, 2, 2, 448)    1344        conv2d_277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 2, 2, 448)    0           batch_normalization_277[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_274 (Conv2D)             (None, 2, 2, 384)    786432      concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_278 (Conv2D)             (None, 2, 2, 384)    1548288     activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_274 (BatchN (None, 2, 2, 384)    1152        conv2d_274[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_278 (BatchN (None, 2, 2, 384)    1152        conv2d_278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 2, 2, 384)    0           batch_normalization_274[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 2, 2, 384)    0           batch_normalization_278[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_275 (Conv2D)             (None, 2, 2, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_276 (Conv2D)             (None, 2, 2, 384)    442368      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_279 (Conv2D)             (None, 2, 2, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_280 (Conv2D)             (None, 2, 2, 384)    442368      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 2, 2, 2048)   0           concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_273 (Conv2D)             (None, 2, 2, 320)    655360      concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_275 (BatchN (None, 2, 2, 384)    1152        conv2d_275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_276 (BatchN (None, 2, 2, 384)    1152        conv2d_276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_279 (BatchN (None, 2, 2, 384)    1152        conv2d_279[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_280 (BatchN (None, 2, 2, 384)    1152        conv2d_280[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_281 (Conv2D)             (None, 2, 2, 192)    393216      average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_273 (BatchN (None, 2, 2, 320)    960         conv2d_273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 2, 2, 384)    0           batch_normalization_275[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 2, 2, 384)    0           batch_normalization_276[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 2, 2, 384)    0           batch_normalization_279[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 2, 2, 384)    0           batch_normalization_280[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_281 (BatchN (None, 2, 2, 192)    576         conv2d_281[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 2, 2, 320)    0           batch_normalization_273[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 2, 2, 768)    0           activation_275[0][0]             \n",
      "                                                                 activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 2, 2, 768)    0           activation_279[0][0]             \n",
      "                                                                 activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 2, 2, 192)    0           batch_normalization_281[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 2, 2, 2048)   0           activation_273[0][0]             \n",
      "                                                                 concatenate_42[0][0]             \n",
      "                                                                 concatenate_43[0][0]             \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "left-phi-flattened (Flatten)    (None, 8192)         0           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "fx (Dense)                      (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fy (Dense)                      (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "u0 (Dense)                      (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "v0 (Dense)                      (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "baseline (Dense)                (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "disparity (Dense)               (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "z (Dense)                       (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "pitch (Dense)                   (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "xWorld (Dense)                  (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "yWorld (Dense)                  (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "zWorld (Dense)                  (None, 1)            8193        left-phi-flattened[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 21,909,293\n",
      "Trainable params: 21,874,861\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# feature extraction from left image\n",
    "left_img = Input(shape = (112,112,3), name=\"left_image\")\n",
    "\n",
    "left_phi_model = InceptionV3(weights='imagenet', include_top=False, input_tensor=left_img, input_shape=(112,112,3))\n",
    "left_phi_features = left_phi_model.output\n",
    "left_flat = Flatten(name='left-phi-flattened')(left_phi_features)\n",
    "\n",
    "# fx\n",
    "pred_fx = Dense(1, name='fx')(left_flat)\n",
    "\n",
    "# fy\n",
    "pred_fy = Dense(1, name='fy')(left_flat)\n",
    "\n",
    "# u0\n",
    "pred_u0 = Dense(1, name='u0')(left_flat)\n",
    "\n",
    "# v0\n",
    "pred_v0 = Dense(1, name='v0')(left_flat)\n",
    "\n",
    "# baseline\n",
    "pred_baseline = Dense(1, name='baseline')(left_flat)\n",
    "\n",
    "# tx\n",
    "pred_x = Dense(1, name='x')(left_flat)\n",
    "\n",
    "# ty\n",
    "pred_y = Dense(1, name='y')(left_flat)\n",
    "\n",
    "# tz\n",
    "pred_z = Dense(1, name='z')(left_flat)\n",
    "\n",
    "# pitch\n",
    "pred_pitch = Dense(1, name='pitch')(left_flat)\n",
    "\n",
    "# u\n",
    "pred_u = Dense(1, name='u')(left_flat)\n",
    "\n",
    "# v\n",
    "pred_v = Dense(1, name='v')(left_flat)\n",
    "\n",
    "# disparity\n",
    "pred_disparity = Dense(1, name='disparity')(left_flat)\n",
    "\n",
    "# yWorld\n",
    "pred_yWorld = Dense(1, name='yWorld')(left_flat)\n",
    "\n",
    "# xWorld\n",
    "pred_xWorld = Dense(1, name='xWorld')(left_flat)\n",
    "\n",
    "# zWorld\n",
    "pred_zWorld = Dense(1, name='zWorld')(left_flat)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[left_img], outputs=[pred_fx, pred_fy, pred_u0, pred_v0, pred_baseline, pred_disparity, pred_x, pred_y, pred_z, pred_pitch, pred_xWorld,pred_yWorld,pred_zWorld])\n",
    "\n",
    "# set output types\n",
    "target1 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target2 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target3 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target4 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target5 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target6 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target7 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target8 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target9 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target10 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target11 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target12 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target13 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "\n",
    "# get model summary\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"mae\", target_tensors=[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12, target13],optimizer=optimizers.Adam(lr=learning_rate))\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/\"\n",
    "\n",
    "Left_images = np.load(data_path+\"li.npy\")\n",
    "Right_images = np.load(data_path+\"ri.npy\")\n",
    "Fx = np.load(data_path+\"fx.npy\")\n",
    "Fy = np.load(data_path+\"fy.npy\") \n",
    "U0 = np.load(data_path+\"u0.npy\") \n",
    "V0 = np.load(data_path+\"v0.npy\") \n",
    "Baseline = np.load(data_path+\"b.npy\")\n",
    "Disparity = np.load(data_path+\"d.npy\") \n",
    "Tx = np.load(data_path+\"tx.npy\") \n",
    "Ty = np.load(data_path+\"ty.npy\") \n",
    "Tz = np.load(data_path+\"tz.npy\") \n",
    "Pitch = np.load(data_path+\"p.npy\")\n",
    "X = np.load(data_path+\"x.npy\")\n",
    "Y = np.load(data_path+\"y.npy\") \n",
    "Z = np.load(data_path+\"z.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86111 samples, validate on 36906 samples\n",
      "Epoch 1/200\n",
      "   32/86111 [..............................] - ETA: 2:22:39 - loss: 1034.7142 - fx_loss: 58.6676 - fy_loss: 59.1204 - u0_loss: 53.7839 - v0_loss: 54.6601 - baseline_loss: 68.0538 - disparity_loss: 9.8704 - x_loss: 68.4266 - y_loss: 2.2686 - z_loss: 1.0561 - pitch_loss: 18.2414 - xWorld_loss: 315.8716 - yWorld_loss: 2.2806 - zWorld_loss: 322.4132WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.3286s vs `on_train_batch_begin` time: 2.0190s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3286s vs `on_train_batch_end` time: 0.8191s). Check your callbacks.\n",
      "86111/86111 [==============================] - ETA: 0s - loss: 866.3806 - fx_loss: 4.2116 - fy_loss: 4.2165 - u0_loss: 1.2536 - v0_loss: 1.2552 - baseline_loss: 36.3979 - disparity_loss: 2.7610 - x_loss: 36.3980 - y_loss: 0.6322 - z_loss: 0.8648 - pitch_loss: 14.1794 - xWorld_loss: 341.8773 - yWorld_loss: 0.6457 - zWorld_loss: 421.6817WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "86111/86111 [==============================] - 954s 11ms/sample - loss: 866.3806 - fx_loss: 4.2116 - fy_loss: 4.2165 - u0_loss: 1.2536 - v0_loss: 1.2552 - baseline_loss: 36.3979 - disparity_loss: 2.7610 - x_loss: 36.3980 - y_loss: 0.6322 - z_loss: 0.8648 - pitch_loss: 14.1794 - xWorld_loss: 341.8773 - yWorld_loss: 0.6457 - zWorld_loss: 421.6817 - val_loss: 634.3483 - val_fx_loss: 2.4406 - val_fy_loss: 2.3289 - val_u0_loss: 0.6898 - val_v0_loss: 0.6882 - val_baseline_loss: 29.7513 - val_disparity_loss: 2.4417 - val_x_loss: 29.7126 - val_y_loss: 0.4139 - val_z_loss: 0.6985 - val_pitch_loss: 11.8389 - val_xWorld_loss: 230.3932 - val_yWorld_loss: 0.4334 - val_zWorld_loss: 322.4580\n",
      "Epoch 2/200\n",
      "86111/86111 [==============================] - 818s 10ms/sample - loss: 722.6641 - fx_loss: 2.1729 - fy_loss: 2.1685 - u0_loss: 0.6969 - v0_loss: 0.6958 - baseline_loss: 25.8132 - disparity_loss: 2.5584 - x_loss: 25.8191 - y_loss: 0.4530 - z_loss: 0.7434 - pitch_loss: 10.2854 - xWorld_loss: 300.1632 - yWorld_loss: 0.4613 - zWorld_loss: 350.6283 - val_loss: 571.0720 - val_fx_loss: 2.1639 - val_fy_loss: 2.1267 - val_u0_loss: 1.0436 - val_v0_loss: 1.1462 - val_baseline_loss: 26.0507 - val_disparity_loss: 2.3671 - val_x_loss: 26.4723 - val_y_loss: 0.4016 - val_z_loss: 0.6626 - val_pitch_loss: 9.1878 - val_xWorld_loss: 202.4354 - val_yWorld_loss: 0.3305 - val_zWorld_loss: 296.6389\n",
      "Epoch 3/200\n",
      "86111/86111 [==============================] - 828s 10ms/sample - loss: 660.8125 - fx_loss: 1.7039 - fy_loss: 1.7023 - u0_loss: 0.5803 - v0_loss: 0.5789 - baseline_loss: 22.0558 - disparity_loss: 2.3540 - x_loss: 22.0558 - y_loss: 0.4030 - z_loss: 0.6799 - pitch_loss: 8.7363 - xWorld_loss: 275.4352 - yWorld_loss: 0.4135 - zWorld_loss: 324.1103 - val_loss: 519.5805 - val_fx_loss: 1.5251 - val_fy_loss: 1.3812 - val_u0_loss: 0.8802 - val_v0_loss: 0.5744 - val_baseline_loss: 22.4422 - val_disparity_loss: 2.4162 - val_x_loss: 22.4662 - val_y_loss: 0.5313 - val_z_loss: 0.5490 - val_pitch_loss: 8.5543 - val_xWorld_loss: 185.4443 - val_yWorld_loss: 0.4388 - val_zWorld_loss: 272.5200\n",
      "Epoch 4/200\n",
      "86111/86111 [==============================] - 822s 10ms/sample - loss: 631.4318 - fx_loss: 1.4192 - fy_loss: 1.4198 - u0_loss: 0.5086 - v0_loss: 0.5057 - baseline_loss: 20.0926 - disparity_loss: 2.2540 - x_loss: 20.0912 - y_loss: 0.3788 - z_loss: 0.6397 - pitch_loss: 8.0109 - xWorld_loss: 264.6646 - yWorld_loss: 0.3788 - zWorld_loss: 311.0666 - val_loss: 483.0526 - val_fx_loss: 1.4412 - val_fy_loss: 1.5268 - val_u0_loss: 0.8642 - val_v0_loss: 0.2842 - val_baseline_loss: 19.8258 - val_disparity_loss: 2.1424 - val_x_loss: 20.1034 - val_y_loss: 0.2969 - val_z_loss: 0.6177 - val_pitch_loss: 8.0641 - val_xWorld_loss: 171.5375 - val_yWorld_loss: 0.2665 - val_zWorld_loss: 256.0672\n",
      "Epoch 5/200\n",
      "86111/86111 [==============================] - 826s 10ms/sample - loss: 610.9125 - fx_loss: 1.2703 - fy_loss: 1.2737 - u0_loss: 0.4648 - v0_loss: 0.4636 - baseline_loss: 18.6761 - disparity_loss: 2.1807 - x_loss: 18.6713 - y_loss: 0.3457 - z_loss: 0.5918 - pitch_loss: 7.3288 - xWorld_loss: 257.7603 - yWorld_loss: 0.3560 - zWorld_loss: 301.5263 - val_loss: 474.2366 - val_fx_loss: 1.2775 - val_fy_loss: 1.2380 - val_u0_loss: 0.6284 - val_v0_loss: 0.5764 - val_baseline_loss: 19.4882 - val_disparity_loss: 2.1024 - val_x_loss: 19.3767 - val_y_loss: 0.2859 - val_z_loss: 0.4874 - val_pitch_loss: 7.4301 - val_xWorld_loss: 163.0269 - val_yWorld_loss: 0.3073 - val_zWorld_loss: 258.0066\n",
      "Epoch 6/200\n",
      "86111/86111 [==============================] - 825s 10ms/sample - loss: 596.2857 - fx_loss: 1.1464 - fy_loss: 1.1456 - u0_loss: 0.4369 - v0_loss: 0.4445 - baseline_loss: 17.5852 - disparity_loss: 2.0932 - x_loss: 17.5838 - y_loss: 0.3291 - z_loss: 0.5726 - pitch_loss: 6.9141 - xWorld_loss: 251.4000 - yWorld_loss: 0.3363 - zWorld_loss: 296.2932 - val_loss: 472.5822 - val_fx_loss: 1.0799 - val_fy_loss: 1.2952 - val_u0_loss: 0.8286 - val_v0_loss: 0.8143 - val_baseline_loss: 19.4686 - val_disparity_loss: 2.0420 - val_x_loss: 19.4051 - val_y_loss: 0.2235 - val_z_loss: 0.6144 - val_pitch_loss: 7.5960 - val_xWorld_loss: 166.6157 - val_yWorld_loss: 0.2883 - val_zWorld_loss: 252.2515\n",
      "Epoch 7/200\n",
      "86111/86111 [==============================] - 825s 10ms/sample - loss: 584.0413 - fx_loss: 1.0856 - fy_loss: 1.0845 - u0_loss: 0.4151 - v0_loss: 0.4183 - baseline_loss: 16.6620 - disparity_loss: 2.0499 - x_loss: 16.6584 - y_loss: 0.3200 - z_loss: 0.5540 - pitch_loss: 6.5505 - xWorld_loss: 247.1158 - yWorld_loss: 0.3118 - zWorld_loss: 290.8113 - val_loss: 464.8112 - val_fx_loss: 1.2873 - val_fy_loss: 1.4189 - val_u0_loss: 0.6126 - val_v0_loss: 0.8126 - val_baseline_loss: 18.2455 - val_disparity_loss: 2.0891 - val_x_loss: 18.3211 - val_y_loss: 0.3580 - val_z_loss: 0.4718 - val_pitch_loss: 6.8670 - val_xWorld_loss: 161.9891 - val_yWorld_loss: 0.3717 - val_zWorld_loss: 251.9462\n",
      "Epoch 8/200\n",
      "86111/86111 [==============================] - 831s 10ms/sample - loss: 572.5265 - fx_loss: 0.9877 - fy_loss: 0.9842 - u0_loss: 0.3871 - v0_loss: 0.3947 - baseline_loss: 15.7467 - disparity_loss: 2.0107 - x_loss: 15.7468 - y_loss: 0.2916 - z_loss: 0.5231 - pitch_loss: 6.1764 - xWorld_loss: 243.0805 - yWorld_loss: 0.2976 - zWorld_loss: 285.8966 - val_loss: 440.9646 - val_fx_loss: 1.5998 - val_fy_loss: 1.6794 - val_u0_loss: 0.5157 - val_v0_loss: 0.9212 - val_baseline_loss: 16.8138 - val_disparity_loss: 1.9481 - val_x_loss: 16.8146 - val_y_loss: 0.1847 - val_z_loss: 0.4718 - val_pitch_loss: 6.4548 - val_xWorld_loss: 152.3928 - val_yWorld_loss: 0.2142 - val_zWorld_loss: 240.9426\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86111/86111 [==============================] - 1064s 12ms/sample - loss: 560.9210 - fx_loss: 0.9591 - fy_loss: 0.9557 - u0_loss: 0.3715 - v0_loss: 0.3684 - baseline_loss: 14.8753 - disparity_loss: 1.9652 - x_loss: 14.8765 - y_loss: 0.2825 - z_loss: 0.4962 - pitch_loss: 5.7900 - xWorld_loss: 238.4467 - yWorld_loss: 0.2846 - zWorld_loss: 281.2481 - val_loss: 428.2204 - val_fx_loss: 0.8480 - val_fy_loss: 1.0416 - val_u0_loss: 0.4538 - val_v0_loss: 0.5055 - val_baseline_loss: 15.4839 - val_disparity_loss: 1.8814 - val_x_loss: 15.6504 - val_y_loss: 0.3069 - val_z_loss: 0.5263 - val_pitch_loss: 6.1941 - val_xWorld_loss: 148.7522 - val_yWorld_loss: 0.5105 - val_zWorld_loss: 236.0231\n",
      "Epoch 10/200\n",
      "86111/86111 [==============================] - 1061s 12ms/sample - loss: 551.3904 - fx_loss: 0.8842 - fy_loss: 0.8904 - u0_loss: 0.3535 - v0_loss: 0.3539 - baseline_loss: 13.9987 - disparity_loss: 1.9037 - x_loss: 14.0049 - y_loss: 0.2771 - z_loss: 0.4762 - pitch_loss: 5.4948 - xWorld_loss: 235.4934 - yWorld_loss: 0.2811 - zWorld_loss: 276.9775 - val_loss: 428.1968 - val_fx_loss: 0.8660 - val_fy_loss: 1.2197 - val_u0_loss: 0.8453 - val_v0_loss: 0.5416 - val_baseline_loss: 15.4567 - val_disparity_loss: 2.0388 - val_x_loss: 15.4181 - val_y_loss: 0.2865 - val_z_loss: 0.5117 - val_pitch_loss: 5.8905 - val_xWorld_loss: 150.5829 - val_yWorld_loss: 0.2050 - val_zWorld_loss: 234.2863\n",
      "Epoch 11/200\n",
      "86111/86111 [==============================] - 999s 12ms/sample - loss: 541.0356 - fx_loss: 0.8390 - fy_loss: 0.8363 - u0_loss: 0.3473 - v0_loss: 0.3422 - baseline_loss: 13.2728 - disparity_loss: 1.8649 - x_loss: 13.2759 - y_loss: 0.2601 - z_loss: 0.4613 - pitch_loss: 5.2065 - xWorld_loss: 231.6197 - yWorld_loss: 0.2612 - zWorld_loss: 272.4446 - val_loss: 438.9739 - val_fx_loss: 1.5112 - val_fy_loss: 1.5817 - val_u0_loss: 0.4426 - val_v0_loss: 0.5279 - val_baseline_loss: 16.9160 - val_disparity_loss: 1.8577 - val_x_loss: 16.7012 - val_y_loss: 0.3153 - val_z_loss: 0.4163 - val_pitch_loss: 6.4167 - val_xWorld_loss: 155.0338 - val_yWorld_loss: 0.1574 - val_zWorld_loss: 237.1344\n",
      "Epoch 12/200\n",
      "86111/86111 [==============================] - 822s 10ms/sample - loss: 536.1723 - fx_loss: 0.8167 - fy_loss: 0.8219 - u0_loss: 0.3307 - v0_loss: 0.3311 - baseline_loss: 13.0060 - disparity_loss: 1.8402 - x_loss: 13.0068 - y_loss: 0.2538 - z_loss: 0.4403 - pitch_loss: 5.0422 - xWorld_loss: 229.0933 - yWorld_loss: 0.2542 - zWorld_loss: 270.9332 - val_loss: 428.1718 - val_fx_loss: 0.7788 - val_fy_loss: 0.8165 - val_u0_loss: 0.7518 - val_v0_loss: 0.5876 - val_baseline_loss: 15.0888 - val_disparity_loss: 1.8946 - val_x_loss: 15.0689 - val_y_loss: 0.2859 - val_z_loss: 0.4168 - val_pitch_loss: 5.6079 - val_xWorld_loss: 149.1817 - val_yWorld_loss: 0.2636 - val_zWorld_loss: 237.4053\n",
      "Epoch 13/200\n",
      "86111/86111 [==============================] - 821s 10ms/sample - loss: 532.1431 - fx_loss: 0.7679 - fy_loss: 0.7683 - u0_loss: 0.3234 - v0_loss: 0.3234 - baseline_loss: 12.6527 - disparity_loss: 1.8134 - x_loss: 12.6484 - y_loss: 0.2459 - z_loss: 0.4334 - pitch_loss: 4.8880 - xWorld_loss: 228.1790 - yWorld_loss: 0.2455 - zWorld_loss: 268.8517 - val_loss: 441.6963 - val_fx_loss: 1.0270 - val_fy_loss: 1.0021 - val_u0_loss: 0.4379 - val_v0_loss: 0.5249 - val_baseline_loss: 16.6127 - val_disparity_loss: 1.8789 - val_x_loss: 16.7452 - val_y_loss: 0.1990 - val_z_loss: 0.4430 - val_pitch_loss: 6.1514 - val_xWorld_loss: 155.3154 - val_yWorld_loss: 0.2811 - val_zWorld_loss: 241.0340\n",
      "Epoch 14/200\n",
      "86111/86111 [==============================] - 822s 10ms/sample - loss: 524.8491 - fx_loss: 0.7372 - fy_loss: 0.7386 - u0_loss: 0.3059 - v0_loss: 0.3120 - baseline_loss: 12.1192 - disparity_loss: 1.7965 - x_loss: 12.1198 - y_loss: 0.2464 - z_loss: 0.4142 - pitch_loss: 4.6580 - xWorld_loss: 225.3552 - yWorld_loss: 0.2356 - zWorld_loss: 265.8070 - val_loss: 413.1937 - val_fx_loss: 1.1766 - val_fy_loss: 1.4341 - val_u0_loss: 0.5103 - val_v0_loss: 0.5640 - val_baseline_loss: 14.8839 - val_disparity_loss: 1.7478 - val_x_loss: 15.1136 - val_y_loss: 0.2344 - val_z_loss: 0.4250 - val_pitch_loss: 5.5246 - val_xWorld_loss: 142.7557 - val_yWorld_loss: 0.4331 - val_zWorld_loss: 228.3475\n",
      "Epoch 15/200\n",
      "86111/86111 [==============================] - 822s 10ms/sample - loss: 520.7318 - fx_loss: 0.7407 - fy_loss: 0.7349 - u0_loss: 0.3078 - v0_loss: 0.3024 - baseline_loss: 11.7503 - disparity_loss: 1.7719 - x_loss: 11.7488 - y_loss: 0.2354 - z_loss: 0.4008 - pitch_loss: 4.4738 - xWorld_loss: 223.5204 - yWorld_loss: 0.2271 - zWorld_loss: 264.5147 - val_loss: 406.4460 - val_fx_loss: 1.0188 - val_fy_loss: 1.2846 - val_u0_loss: 0.7054 - val_v0_loss: 0.7129 - val_baseline_loss: 14.8629 - val_disparity_loss: 2.2284 - val_x_loss: 14.7758 - val_y_loss: 0.1516 - val_z_loss: 0.3548 - val_pitch_loss: 5.2450 - val_xWorld_loss: 139.4596 - val_yWorld_loss: 0.2556 - val_zWorld_loss: 225.4002\n",
      "Epoch 16/200\n",
      "86111/86111 [==============================] - 820s 10ms/sample - loss: 514.8219 - fx_loss: 0.7050 - fy_loss: 0.7029 - u0_loss: 0.2905 - v0_loss: 0.2904 - baseline_loss: 11.3940 - disparity_loss: 1.7441 - x_loss: 11.3907 - y_loss: 0.2240 - z_loss: 0.3885 - pitch_loss: 4.3698 - xWorld_loss: 221.1480 - yWorld_loss: 0.2321 - zWorld_loss: 261.9383 - val_loss: 408.0938 - val_fx_loss: 1.3720 - val_fy_loss: 1.2822 - val_u0_loss: 0.6313 - val_v0_loss: 0.6694 - val_baseline_loss: 14.4933 - val_disparity_loss: 1.8559 - val_x_loss: 14.6850 - val_y_loss: 0.2140 - val_z_loss: 0.4595 - val_pitch_loss: 5.4666 - val_xWorld_loss: 140.4076 - val_yWorld_loss: 0.1455 - val_zWorld_loss: 226.3789\n",
      "Epoch 17/200\n",
      "86111/86111 [==============================] - 821s 10ms/sample - loss: 510.7876 - fx_loss: 0.6696 - fy_loss: 0.6674 - u0_loss: 0.2840 - v0_loss: 0.2853 - baseline_loss: 11.2212 - disparity_loss: 1.7138 - x_loss: 11.2268 - y_loss: 0.2245 - z_loss: 0.3818 - pitch_loss: 4.2656 - xWorld_loss: 219.3688 - yWorld_loss: 0.2107 - zWorld_loss: 260.2681 - val_loss: 394.0187 - val_fx_loss: 0.7566 - val_fy_loss: 0.7509 - val_u0_loss: 1.0899 - val_v0_loss: 0.7964 - val_baseline_loss: 13.6699 - val_disparity_loss: 1.9294 - val_x_loss: 13.7069 - val_y_loss: 0.1456 - val_z_loss: 0.3443 - val_pitch_loss: 4.9898 - val_xWorld_loss: 135.5494 - val_yWorld_loss: 0.2404 - val_zWorld_loss: 220.0414\n",
      "Epoch 18/200\n",
      "86111/86111 [==============================] - 1138s 13ms/sample - loss: 506.1120 - fx_loss: 0.6401 - fy_loss: 0.6431 - u0_loss: 0.2749 - v0_loss: 0.2747 - baseline_loss: 10.7644 - disparity_loss: 1.7106 - x_loss: 10.7668 - y_loss: 0.2179 - z_loss: 0.3713 - pitch_loss: 4.1183 - xWorld_loss: 217.7322 - yWorld_loss: 0.2197 - zWorld_loss: 258.3744 - val_loss: 397.6462 - val_fx_loss: 0.8166 - val_fy_loss: 0.6309 - val_u0_loss: 0.5807 - val_v0_loss: 0.3574 - val_baseline_loss: 13.5337 - val_disparity_loss: 1.7097 - val_x_loss: 13.4176 - val_y_loss: 0.2059 - val_z_loss: 0.3975 - val_pitch_loss: 4.8782 - val_xWorld_loss: 136.2891 - val_yWorld_loss: 0.1963 - val_zWorld_loss: 224.5882\n",
      "Epoch 19/200\n",
      "86111/86111 [==============================] - 941s 11ms/sample - loss: 502.7532 - fx_loss: 0.6517 - fy_loss: 0.6517 - u0_loss: 0.2774 - v0_loss: 0.2774 - baseline_loss: 10.5271 - disparity_loss: 1.6933 - x_loss: 10.5268 - y_loss: 0.2107 - z_loss: 0.3714 - pitch_loss: 4.0507 - xWorld_loss: 216.7005 - yWorld_loss: 0.2078 - zWorld_loss: 256.6058 - val_loss: 390.5118 - val_fx_loss: 0.9407 - val_fy_loss: 1.2128 - val_u0_loss: 0.6171 - val_v0_loss: 0.8700 - val_baseline_loss: 13.4028 - val_disparity_loss: 1.6992 - val_x_loss: 13.4700 - val_y_loss: 0.1992 - val_z_loss: 0.4227 - val_pitch_loss: 5.1155 - val_xWorld_loss: 134.2238 - val_yWorld_loss: 0.2657 - val_zWorld_loss: 218.0433\n",
      "Epoch 20/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86111/86111 [==============================] - 983s 11ms/sample - loss: 497.1991 - fx_loss: 0.6198 - fy_loss: 0.6216 - u0_loss: 0.2649 - v0_loss: 0.2693 - baseline_loss: 10.2246 - disparity_loss: 1.6747 - x_loss: 10.2236 - y_loss: 0.2075 - z_loss: 0.3540 - pitch_loss: 3.8960 - xWorld_loss: 214.7411 - yWorld_loss: 0.2023 - zWorld_loss: 253.8961 - val_loss: 394.2239 - val_fx_loss: 1.0691 - val_fy_loss: 1.2902 - val_u0_loss: 0.6062 - val_v0_loss: 0.6992 - val_baseline_loss: 13.1887 - val_disparity_loss: 1.6928 - val_x_loss: 13.2008 - val_y_loss: 0.1759 - val_z_loss: 0.5081 - val_pitch_loss: 4.7735 - val_xWorld_loss: 135.6011 - val_yWorld_loss: 0.1963 - val_zWorld_loss: 221.2239\n",
      "Epoch 21/200\n",
      "86111/86111 [==============================] - 859s 10ms/sample - loss: 490.8220 - fx_loss: 0.6061 - fy_loss: 0.6067 - u0_loss: 0.2633 - v0_loss: 0.2597 - baseline_loss: 9.8132 - disparity_loss: 1.6428 - x_loss: 9.8149 - y_loss: 0.2028 - z_loss: 0.3420 - pitch_loss: 3.7252 - xWorld_loss: 212.5668 - yWorld_loss: 0.2020 - zWorld_loss: 250.7728 - val_loss: 378.3180 - val_fx_loss: 0.7892 - val_fy_loss: 0.8298 - val_u0_loss: 0.5519 - val_v0_loss: 0.6510 - val_baseline_loss: 12.3906 - val_disparity_loss: 1.7163 - val_x_loss: 12.6745 - val_y_loss: 0.2129 - val_z_loss: 0.3005 - val_pitch_loss: 4.5528 - val_xWorld_loss: 130.2249 - val_yWorld_loss: 0.2324 - val_zWorld_loss: 213.1732\n",
      "Epoch 22/200\n",
      "86111/86111 [==============================] - 820s 10ms/sample - loss: 486.9648 - fx_loss: 0.6106 - fy_loss: 0.6066 - u0_loss: 0.2718 - v0_loss: 0.2705 - baseline_loss: 9.5657 - disparity_loss: 1.6370 - x_loss: 9.5685 - y_loss: 0.2069 - z_loss: 0.3405 - pitch_loss: 3.6418 - xWorld_loss: 210.9064 - yWorld_loss: 0.2055 - zWorld_loss: 249.1316 - val_loss: 381.8399 - val_fx_loss: 1.1460 - val_fy_loss: 1.3630 - val_u0_loss: 0.5928 - val_v0_loss: 0.7582 - val_baseline_loss: 12.9117 - val_disparity_loss: 1.6463 - val_x_loss: 12.8589 - val_y_loss: 0.1453 - val_z_loss: 0.3521 - val_pitch_loss: 4.5303 - val_xWorld_loss: 131.0611 - val_yWorld_loss: 0.1490 - val_zWorld_loss: 214.3092\n",
      "Epoch 23/200\n",
      "86111/86111 [==============================] - 820s 10ms/sample - loss: 483.9054 - fx_loss: 0.5787 - fy_loss: 0.5833 - u0_loss: 0.2516 - v0_loss: 0.2513 - baseline_loss: 9.3502 - disparity_loss: 1.6173 - x_loss: 9.3504 - y_loss: 0.1922 - z_loss: 0.3331 - pitch_loss: 3.5672 - xWorld_loss: 209.8969 - yWorld_loss: 0.2004 - zWorld_loss: 247.7287 - val_loss: 384.2643 - val_fx_loss: 0.6454 - val_fy_loss: 0.6888 - val_u0_loss: 0.4788 - val_v0_loss: 0.6064 - val_baseline_loss: 12.5706 - val_disparity_loss: 1.6645 - val_x_loss: 12.4880 - val_y_loss: 0.2028 - val_z_loss: 0.3528 - val_pitch_loss: 4.5653 - val_xWorld_loss: 132.6350 - val_yWorld_loss: 0.1730 - val_zWorld_loss: 217.2017\n",
      "Epoch 24/200\n",
      "86111/86111 [==============================] - 818s 10ms/sample - loss: 485.3485 - fx_loss: 0.5648 - fy_loss: 0.5621 - u0_loss: 0.2471 - v0_loss: 0.2509 - baseline_loss: 9.4893 - disparity_loss: 1.6005 - x_loss: 9.4883 - y_loss: 0.1988 - z_loss: 0.3349 - pitch_loss: 3.5781 - xWorld_loss: 210.7444 - yWorld_loss: 0.1872 - zWorld_loss: 248.0990 - val_loss: 381.4966 - val_fx_loss: 1.1089 - val_fy_loss: 1.2127 - val_u0_loss: 0.6988 - val_v0_loss: 0.7094 - val_baseline_loss: 12.3868 - val_disparity_loss: 1.7493 - val_x_loss: 12.5110 - val_y_loss: 0.1573 - val_z_loss: 0.3472 - val_pitch_loss: 4.3526 - val_xWorld_loss: 131.7710 - val_yWorld_loss: 0.1958 - val_zWorld_loss: 214.4327\n",
      "Epoch 25/200\n",
      "86111/86111 [==============================] - 818s 10ms/sample - loss: 478.5023 - fx_loss: 0.5491 - fy_loss: 0.5488 - u0_loss: 0.2466 - v0_loss: 0.2430 - baseline_loss: 8.9516 - disparity_loss: 1.6007 - x_loss: 8.9508 - y_loss: 0.1904 - z_loss: 0.3150 - pitch_loss: 3.3885 - xWorld_loss: 207.9469 - yWorld_loss: 0.1894 - zWorld_loss: 245.3786 - val_loss: 373.5886 - val_fx_loss: 0.5714 - val_fy_loss: 0.9514 - val_u0_loss: 0.4947 - val_v0_loss: 0.3844 - val_baseline_loss: 12.2640 - val_disparity_loss: 1.7321 - val_x_loss: 12.0425 - val_y_loss: 0.1347 - val_z_loss: 0.3163 - val_pitch_loss: 4.5629 - val_xWorld_loss: 128.5403 - val_yWorld_loss: 0.1191 - val_zWorld_loss: 211.4810\n",
      "Epoch 26/200\n",
      "86111/86111 [==============================] - 917s 11ms/sample - loss: 477.5694 - fx_loss: 0.5551 - fy_loss: 0.5546 - u0_loss: 0.2458 - v0_loss: 0.2419 - baseline_loss: 8.9180 - disparity_loss: 1.5942 - x_loss: 8.9215 - y_loss: 0.1870 - z_loss: 0.3144 - pitch_loss: 3.3701 - xWorld_loss: 207.6489 - yWorld_loss: 0.1873 - zWorld_loss: 244.8271 - val_loss: 379.3290 - val_fx_loss: 0.6163 - val_fy_loss: 0.7824 - val_u0_loss: 0.5057 - val_v0_loss: 0.5818 - val_baseline_loss: 12.5701 - val_disparity_loss: 1.6191 - val_x_loss: 12.5521 - val_y_loss: 0.1371 - val_z_loss: 0.3353 - val_pitch_loss: 4.5361 - val_xWorld_loss: 131.8826 - val_yWorld_loss: 0.1681 - val_zWorld_loss: 213.0014\n",
      "Epoch 27/200\n",
      "86111/86111 [==============================] - 1074s 12ms/sample - loss: 474.2463 - fx_loss: 0.5327 - fy_loss: 0.5346 - u0_loss: 0.2450 - v0_loss: 0.2386 - baseline_loss: 8.6932 - disparity_loss: 1.5649 - x_loss: 8.6951 - y_loss: 0.1846 - z_loss: 0.3146 - pitch_loss: 3.2951 - xWorld_loss: 206.5701 - yWorld_loss: 0.1842 - zWorld_loss: 243.1901 - val_loss: 373.0462 - val_fx_loss: 0.8574 - val_fy_loss: 0.9367 - val_u0_loss: 0.7145 - val_v0_loss: 0.6437 - val_baseline_loss: 11.9152 - val_disparity_loss: 1.6748 - val_x_loss: 11.9561 - val_y_loss: 0.2004 - val_z_loss: 0.3725 - val_pitch_loss: 4.4700 - val_xWorld_loss: 129.2836 - val_yWorld_loss: 0.2098 - val_zWorld_loss: 209.8005\n",
      "Epoch 28/200\n",
      "86111/86111 [==============================] - 974s 11ms/sample - loss: 470.0359 - fx_loss: 0.5098 - fy_loss: 0.5106 - u0_loss: 0.2344 - v0_loss: 0.2361 - baseline_loss: 8.3887 - disparity_loss: 1.5535 - x_loss: 8.3952 - y_loss: 0.1870 - z_loss: 0.3035 - pitch_loss: 3.1976 - xWorld_loss: 204.9122 - yWorld_loss: 0.1806 - zWorld_loss: 241.4223 - val_loss: 382.2559 - val_fx_loss: 1.0170 - val_fy_loss: 1.0728 - val_u0_loss: 0.6828 - val_v0_loss: 0.9336 - val_baseline_loss: 12.8504 - val_disparity_loss: 1.6533 - val_x_loss: 12.7827 - val_y_loss: 0.2051 - val_z_loss: 0.3234 - val_pitch_loss: 4.5180 - val_xWorld_loss: 130.2166 - val_yWorld_loss: 0.1309 - val_zWorld_loss: 215.81772361 - baseline_loss: 8.3886 - disparity_loss: 1.5533 - x_loss: 8.3951 - y_loss: 0.1870 - z_loss: 0.3035 - pitch_loss: 3.1976 - xWorld_loss: 204.9532 - yWorld_loss: 0.1806 - zWorld_loss: 24\n",
      "Epoch 29/200\n",
      "86111/86111 [==============================] - 935s 11ms/sample - loss: 466.6075 - fx_loss: 0.5206 - fy_loss: 0.5217 - u0_loss: 0.2276 - v0_loss: 0.2356 - baseline_loss: 8.1196 - disparity_loss: 1.5442 - x_loss: 8.1185 - y_loss: 0.1763 - z_loss: 0.2946 - pitch_loss: 3.0867 - xWorld_loss: 203.7258 - yWorld_loss: 0.1799 - zWorld_loss: 239.8520 - val_loss: 391.7190 - val_fx_loss: 0.9385 - val_fy_loss: 0.8491 - val_u0_loss: 0.2676 - val_v0_loss: 0.3464 - val_baseline_loss: 13.0966 - val_disparity_loss: 1.7693 - val_x_loss: 13.2450 - val_y_loss: 0.1486 - val_z_loss: 0.4592 - val_pitch_loss: 4.7933 - val_xWorld_loss: 136.8757 - val_yWorld_loss: 0.1560 - val_zWorld_loss: 218.7658\n",
      "Epoch 30/200\n",
      "86111/86111 [==============================] - 965s 11ms/sample - loss: 466.4214 - fx_loss: 0.5163 - fy_loss: 0.5165 - u0_loss: 0.2301 - v0_loss: 0.2277 - baseline_loss: 8.1143 - disparity_loss: 1.5313 - x_loss: 8.1164 - y_loss: 0.1798 - z_loss: 0.2979 - pitch_loss: 3.0536 - xWorld_loss: 203.6597 - yWorld_loss: 0.1772 - zWorld_loss: 239.7955 - val_loss: 369.4316 - val_fx_loss: 0.7327 - val_fy_loss: 0.8333 - val_u0_loss: 0.7229 - val_v0_loss: 0.6730 - val_baseline_loss: 11.8433 - val_disparity_loss: 1.6070 - val_x_loss: 11.9835 - val_y_loss: 0.2158 - val_z_loss: 0.3385 - val_pitch_loss: 4.0975 - val_xWorld_loss: 126.9280 - val_yWorld_loss: 0.1216 - val_zWorld_loss: 209.3306\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86111/86111 [==============================] - 850s 10ms/sample - loss: 464.0911 - fx_loss: 0.5071 - fy_loss: 0.5069 - u0_loss: 0.2255 - v0_loss: 0.2327 - baseline_loss: 8.0723 - disparity_loss: 1.5253 - x_loss: 8.0725 - y_loss: 0.1724 - z_loss: 0.2872 - pitch_loss: 3.0461 - xWorld_loss: 202.6930 - yWorld_loss: 0.1753 - zWorld_loss: 238.5718 - val_loss: 371.8591 - val_fx_loss: 0.6305 - val_fy_loss: 0.8787 - val_u0_loss: 0.4862 - val_v0_loss: 0.5075 - val_baseline_loss: 11.7022 - val_disparity_loss: 1.8153 - val_x_loss: 11.6562 - val_y_loss: 0.1422 - val_z_loss: 0.3070 - val_pitch_loss: 4.2687 - val_xWorld_loss: 129.1388 - val_yWorld_loss: 0.1965 - val_zWorld_loss: 210.0927\n",
      "Epoch 32/200\n",
      "86111/86111 [==============================] - 828s 10ms/sample - loss: 462.8076 - fx_loss: 0.5067 - fy_loss: 0.5073 - u0_loss: 0.2280 - v0_loss: 0.2216 - baseline_loss: 7.9363 - disparity_loss: 1.5235 - x_loss: 7.9353 - y_loss: 0.1729 - z_loss: 0.2862 - pitch_loss: 2.9899 - xWorld_loss: 202.5746 - yWorld_loss: 0.1738 - zWorld_loss: 237.7518 - val_loss: 378.5184 - val_fx_loss: 1.2859 - val_fy_loss: 1.2728 - val_u0_loss: 0.5919 - val_v0_loss: 0.7054 - val_baseline_loss: 12.7783 - val_disparity_loss: 1.5832 - val_x_loss: 12.7986 - val_y_loss: 0.1636 - val_z_loss: 0.3682 - val_pitch_loss: 4.6554 - val_xWorld_loss: 131.2926 - val_yWorld_loss: 0.1752 - val_zWorld_loss: 210.7907\n",
      "Epoch 33/200\n",
      "86111/86111 [==============================] - 828s 10ms/sample - loss: 457.9567 - fx_loss: 0.4990 - fy_loss: 0.4979 - u0_loss: 0.2241 - v0_loss: 0.2299 - baseline_loss: 7.6713 - disparity_loss: 1.5062 - x_loss: 7.6700 - y_loss: 0.1760 - z_loss: 0.2799 - pitch_loss: 2.8970 - xWorld_loss: 200.8375 - yWorld_loss: 0.1703 - zWorld_loss: 235.2948 - val_loss: 365.6845 - val_fx_loss: 0.9301 - val_fy_loss: 0.7846 - val_u0_loss: 0.5446 - val_v0_loss: 0.7491 - val_baseline_loss: 11.4071 - val_disparity_loss: 1.6142 - val_x_loss: 11.5218 - val_y_loss: 0.1720 - val_z_loss: 0.3693 - val_pitch_loss: 4.0915 - val_xWorld_loss: 126.7103 - val_yWorld_loss: 0.1740 - val_zWorld_loss: 206.6722\n",
      "Epoch 34/200\n",
      "86111/86111 [==============================] - 826s 10ms/sample - loss: 453.3217 - fx_loss: 0.4845 - fy_loss: 0.4871 - u0_loss: 0.2212 - v0_loss: 0.2175 - baseline_loss: 7.3467 - disparity_loss: 1.4898 - x_loss: 7.3450 - y_loss: 0.1707 - z_loss: 0.2745 - pitch_loss: 2.8083 - xWorld_loss: 199.1886 - yWorld_loss: 0.1718 - zWorld_loss: 233.1127 - val_loss: 363.4517 - val_fx_loss: 0.6328 - val_fy_loss: 0.6585 - val_u0_loss: 0.7373 - val_v0_loss: 0.6186 - val_baseline_loss: 11.4596 - val_disparity_loss: 1.5576 - val_x_loss: 11.3352 - val_y_loss: 0.1072 - val_z_loss: 0.3576 - val_pitch_loss: 3.9648 - val_xWorld_loss: 125.4595 - val_yWorld_loss: 0.1483 - val_zWorld_loss: 206.4499\n",
      "Epoch 35/200\n",
      "86111/86111 [==============================] - 824s 10ms/sample - loss: 454.3789 - fx_loss: 0.4756 - fy_loss: 0.4750 - u0_loss: 0.2166 - v0_loss: 0.2144 - baseline_loss: 7.4493 - disparity_loss: 1.4902 - x_loss: 7.4501 - y_loss: 0.1671 - z_loss: 0.2733 - pitch_loss: 2.7959 - xWorld_loss: 199.7464 - yWorld_loss: 0.1725 - zWorld_loss: 233.4493 - val_loss: 367.3972 - val_fx_loss: 0.7554 - val_fy_loss: 0.6858 - val_u0_loss: 0.9150 - val_v0_loss: 0.5570 - val_baseline_loss: 11.2014 - val_disparity_loss: 1.6335 - val_x_loss: 11.0617 - val_y_loss: 0.1796 - val_z_loss: 0.2775 - val_pitch_loss: 3.9605 - val_xWorld_loss: 128.0533 - val_yWorld_loss: 0.1071 - val_zWorld_loss: 208.0509\n",
      "Epoch 36/200\n",
      "86111/86111 [==============================] - 825s 10ms/sample - loss: 451.6000 - fx_loss: 0.5021 - fy_loss: 0.5032 - u0_loss: 0.2119 - v0_loss: 0.2163 - baseline_loss: 7.1601 - disparity_loss: 1.4811 - x_loss: 7.1553 - y_loss: 0.1664 - z_loss: 0.2688 - pitch_loss: 2.7228 - xWorld_loss: 199.0209 - yWorld_loss: 0.1644 - zWorld_loss: 232.0245 - val_loss: 364.1223 - val_fx_loss: 0.9284 - val_fy_loss: 0.8824 - val_u0_loss: 0.5185 - val_v0_loss: 0.6290 - val_baseline_loss: 10.9037 - val_disparity_loss: 1.5268 - val_x_loss: 11.1547 - val_y_loss: 0.2264 - val_z_loss: 0.3015 - val_pitch_loss: 3.8922 - val_xWorld_loss: 125.7807 - val_yWorld_loss: 0.1698 - val_zWorld_loss: 207.1823\n",
      "Epoch 37/200\n",
      "86111/86111 [==============================] - 824s 10ms/sample - loss: 448.5111 - fx_loss: 0.4688 - fy_loss: 0.4695 - u0_loss: 0.2107 - v0_loss: 0.2120 - baseline_loss: 7.0481 - disparity_loss: 1.4611 - x_loss: 7.0464 - y_loss: 0.1642 - z_loss: 0.2639 - pitch_loss: 2.6626 - xWorld_loss: 197.9346 - yWorld_loss: 0.1639 - zWorld_loss: 230.4022 - val_loss: 358.6111 - val_fx_loss: 1.0660 - val_fy_loss: 0.6355 - val_u0_loss: 0.3377 - val_v0_loss: 0.3997 - val_baseline_loss: 10.7740 - val_disparity_loss: 1.5217 - val_x_loss: 10.8272 - val_y_loss: 0.1179 - val_z_loss: 0.3054 - val_pitch_loss: 3.8670 - val_xWorld_loss: 124.2556 - val_yWorld_loss: 0.1384 - val_zWorld_loss: 204.3388\n",
      "Epoch 38/200\n",
      "86111/86111 [==============================] - 823s 10ms/sample - loss: 445.7873 - fx_loss: 0.4621 - fy_loss: 0.4621 - u0_loss: 0.2082 - v0_loss: 0.2055 - baseline_loss: 6.9149 - disparity_loss: 1.4488 - x_loss: 6.9146 - y_loss: 0.1606 - z_loss: 0.2586 - pitch_loss: 2.5693 - xWorld_loss: 196.5798 - yWorld_loss: 0.1599 - zWorld_loss: 229.4545 - val_loss: 367.2120 - val_fx_loss: 0.7055 - val_fy_loss: 0.9620 - val_u0_loss: 0.6276 - val_v0_loss: 0.7528 - val_baseline_loss: 11.4891 - val_disparity_loss: 1.5515 - val_x_loss: 11.4871 - val_y_loss: 0.1078 - val_z_loss: 0.3221 - val_pitch_loss: 4.1081 - val_xWorld_loss: 127.3640 - val_yWorld_loss: 0.3302 - val_zWorld_loss: 207.3798\n",
      "Epoch 39/200\n",
      "86111/86111 [==============================] - 822s 10ms/sample - loss: 443.5221 - fx_loss: 0.4565 - fy_loss: 0.4594 - u0_loss: 0.2098 - v0_loss: 0.2098 - baseline_loss: 6.6988 - disparity_loss: 1.4456 - x_loss: 6.6992 - y_loss: 0.1649 - z_loss: 0.2605 - pitch_loss: 2.5488 - xWorld_loss: 196.3336 - yWorld_loss: 0.1645 - zWorld_loss: 227.8668 - val_loss: 356.3287 - val_fx_loss: 0.9869 - val_fy_loss: 0.9715 - val_u0_loss: 0.5812 - val_v0_loss: 0.6001 - val_baseline_loss: 10.8634 - val_disparity_loss: 1.5116 - val_x_loss: 10.9138 - val_y_loss: 0.2163 - val_z_loss: 0.2932 - val_pitch_loss: 3.6738 - val_xWorld_loss: 123.3458 - val_yWorld_loss: 0.1332 - val_zWorld_loss: 202.1968\n",
      "Epoch 40/200\n",
      "86111/86111 [==============================] - 823s 10ms/sample - loss: 440.6231 - fx_loss: 0.4496 - fy_loss: 0.4484 - u0_loss: 0.2075 - v0_loss: 0.2061 - baseline_loss: 6.5623 - disparity_loss: 1.4308 - x_loss: 6.5654 - y_loss: 0.1594 - z_loss: 0.2519 - pitch_loss: 2.4818 - xWorld_loss: 194.8715 - yWorld_loss: 0.1596 - zWorld_loss: 226.8265 - val_loss: 355.3700 - val_fx_loss: 0.9456 - val_fy_loss: 0.9368 - val_u0_loss: 0.8472 - val_v0_loss: 0.7494 - val_baseline_loss: 10.7027 - val_disparity_loss: 1.6023 - val_x_loss: 10.6317 - val_y_loss: 0.1277 - val_z_loss: 0.2947 - val_pitch_loss: 3.8198 - val_xWorld_loss: 122.8690 - val_yWorld_loss: 0.1186 - val_zWorld_loss: 201.7061\n",
      "Epoch 41/200\n",
      "86111/86111 [==============================] - 821s 10ms/sample - loss: 439.5083 - fx_loss: 0.4436 - fy_loss: 0.4457 - u0_loss: 0.2066 - v0_loss: 0.2084 - baseline_loss: 6.4959 - disparity_loss: 1.4311 - x_loss: 6.4937 - y_loss: 0.1607 - z_loss: 0.2480 - pitch_loss: 2.4404 - xWorld_loss: 194.2513 - yWorld_loss: 0.1562 - zWorld_loss: 226.5227 - val_loss: 357.6315 - val_fx_loss: 0.8230 - val_fy_loss: 0.8416 - val_u0_loss: 0.8547 - val_v0_loss: 0.5830 - val_baseline_loss: 10.8944 - val_disparity_loss: 1.5311 - val_x_loss: 10.8811 - val_y_loss: 0.1605 - val_z_loss: 0.3162 - val_pitch_loss: 3.7249 - val_xWorld_loss: 123.4080 - val_yWorld_loss: 0.1612 - val_zWorld_loss: 203.4141\n",
      "Epoch 42/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86111/86111 [==============================] - 821s 10ms/sample - loss: 437.7519 - fx_loss: 0.4479 - fy_loss: 0.4501 - u0_loss: 0.2014 - v0_loss: 0.2050 - baseline_loss: 6.4696 - disparity_loss: 1.4256 - x_loss: 6.4684 - y_loss: 0.1584 - z_loss: 0.2528 - pitch_loss: 2.4556 - xWorld_loss: 194.2136 - yWorld_loss: 0.1614 - zWorld_loss: 224.8374 - val_loss: 365.3740 - val_fx_loss: 0.7774 - val_fy_loss: 0.8662 - val_u0_loss: 0.4706 - val_v0_loss: 0.6805 - val_baseline_loss: 11.2611 - val_disparity_loss: 1.5214 - val_x_loss: 11.2778 - val_y_loss: 0.1513 - val_z_loss: 0.2914 - val_pitch_loss: 3.8158 - val_xWorld_loss: 128.0166 - val_yWorld_loss: 0.1504 - val_zWorld_loss: 206.0831\n",
      "Epoch 43/200\n",
      "86111/86111 [==============================] - 820s 10ms/sample - loss: 433.7856 - fx_loss: 0.4209 - fy_loss: 0.4188 - u0_loss: 0.1997 - v0_loss: 0.1963 - baseline_loss: 6.1721 - disparity_loss: 1.4081 - x_loss: 6.1728 - y_loss: 0.1571 - z_loss: 0.2467 - pitch_loss: 2.3358 - xWorld_loss: 192.5359 - yWorld_loss: 0.1591 - zWorld_loss: 223.3609 - val_loss: 355.6675 - val_fx_loss: 0.7608 - val_fy_loss: 0.7788 - val_u0_loss: 0.5879 - val_v0_loss: 0.6500 - val_baseline_loss: 10.6058 - val_disparity_loss: 1.5691 - val_x_loss: 10.5556 - val_y_loss: 0.1704 - val_z_loss: 0.2626 - val_pitch_loss: 3.6536 - val_xWorld_loss: 122.5718 - val_yWorld_loss: 0.1711 - val_zWorld_loss: 203.3388\n",
      "Epoch 44/200\n",
      "86111/86111 [==============================] - 820s 10ms/sample - loss: 433.4194 - fx_loss: 0.4254 - fy_loss: 0.4265 - u0_loss: 0.1928 - v0_loss: 0.1939 - baseline_loss: 6.1711 - disparity_loss: 1.4063 - x_loss: 6.1709 - y_loss: 0.1575 - z_loss: 0.2461 - pitch_loss: 2.3267 - xWorld_loss: 192.4103 - yWorld_loss: 0.1569 - zWorld_loss: 223.1317 - val_loss: 364.9147 - val_fx_loss: 0.8198 - val_fy_loss: 0.8647 - val_u0_loss: 0.5046 - val_v0_loss: 0.6638 - val_baseline_loss: 11.8359 - val_disparity_loss: 1.5762 - val_x_loss: 11.8646 - val_y_loss: 0.2278 - val_z_loss: 0.3723 - val_pitch_loss: 4.0899 - val_xWorld_loss: 125.2682 - val_yWorld_loss: 0.1362 - val_zWorld_loss: 206.6880\n",
      "Epoch 45/200\n",
      "86111/86111 [==============================] - ETA: 0s - loss: 430.7902 - fx_loss: 0.4233 - fy_loss: 0.4234 - u0_loss: 0.1989 - v0_loss: 0.1995 - baseline_loss: 6.0397 - disparity_loss: 1.3926 - x_loss: 6.0396 - y_loss: 0.1554 - z_loss: 0.2424 - pitch_loss: 2.2808 - xWorld_loss: 191.8992 - yWorld_loss: 0.1612 - zWorld_loss: 221.3335Restoring model weights from the end of the best epoch.\n",
      "86111/86111 [==============================] - 825s 10ms/sample - loss: 430.7902 - fx_loss: 0.4233 - fy_loss: 0.4234 - u0_loss: 0.1989 - v0_loss: 0.1995 - baseline_loss: 6.0397 - disparity_loss: 1.3926 - x_loss: 6.0396 - y_loss: 0.1554 - z_loss: 0.2424 - pitch_loss: 2.2808 - xWorld_loss: 191.8992 - yWorld_loss: 0.1612 - zWorld_loss: 221.3335 - val_loss: 359.2724 - val_fx_loss: 0.7754 - val_fy_loss: 0.7180 - val_u0_loss: 0.7569 - val_v0_loss: 0.5871 - val_baseline_loss: 10.8238 - val_disparity_loss: 1.5101 - val_x_loss: 10.9431 - val_y_loss: 0.1772 - val_z_loss: 0.3681 - val_pitch_loss: 3.8219 - val_xWorld_loss: 123.6099 - val_yWorld_loss: 0.1211 - val_zWorld_loss: 205.0636\n",
      "Epoch 00045: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "model_name = 'model_multi_class/'\n",
    "SAVE = \"new_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "# Save\n",
    "output_folder = SAVE + model_name\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "output_log = output_folder + \"Log/\"\n",
    "if not os.path.exists(output_log):\n",
    "    os.makedirs(output_log)\n",
    "\n",
    "output_weight = output_folder + \"Best/\"\n",
    "if not os.path.exists(output_weight):\n",
    "    os.makedirs(output_weight)\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=output_log)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=output_weight + \"weights_{epoch:02d}_{val_loss:.2f}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[Left_images[:int(len(Left_images)*0.7)]],\n",
    "    y=[Fx[:int(len(Left_images)*0.7)], Fy[:int(len(Left_images)*0.7)], U0[:int(len(Left_images)*0.7)], V0[:int(len(Left_images)*0.7)], Baseline[:int(len(Left_images)*0.7)], Disparity[:int(len(Left_images)*0.7)], Tx[:int(len(Left_images)*0.7)], Ty[:int(len(Left_images)*0.7)], Tz[:int(len(Left_images)*0.7)], Pitch[:int(len(Left_images)*0.7)], X[:int(len(Left_images)*0.7)], Y[:int(len(Left_images)*0.7)], Z[:int(len(Left_images)*0.7)]],\n",
    "    batch_size=16,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    validation_data=([Left_images[int(len(Left_images)*0.7):]], [Fx[int(len(Left_images)*0.7):], Fy[int(len(Left_images)*0.7):], U0[int(len(Left_images)*0.7):], V0[int(len(Left_images)*0.7):], Baseline[int(len(Left_images)*0.7):], Disparity[int(len(Left_images)*0.7):], Tx[int(len(Left_images)*0.7):], Ty[int(len(Left_images)*0.7):], Tz[int(len(Left_images)*0.7):], Pitch[int(len(Left_images)*0.7):], X[int(len(Left_images)*0.7):], Y[int(len(Left_images)*0.7):], Z[int(len(Left_images)*0.7):]]),\n",
    "    callbacks=[tensorboard, checkpointer, early_stopping, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "model.load_weights('./new_logs/20221216-120919/model_multi_class/Best/weights_40_355.37.h5')\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "\n",
    "output = model.predict(\n",
    "    x=[Left_images[int(len(Left_images)*0.7):]],\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23796, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% Correct')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "th_0 = 0\n",
    "th_1 = 0\n",
    "th_2 = 0\n",
    "th_3 = 0\n",
    "th_4 = 0\n",
    "th_5 = 0\n",
    "\n",
    "percent_correct = []\n",
    "\n",
    "k = 86111\n",
    "\n",
    "for i  in range(np.shape(output)[1]):\n",
    "    \n",
    "    predicted_fov = 2*np.arctan(112/(2*output[0][i][0]))\n",
    "    actual_fov = 2*np.arctan(112/(2*Fx[k]))\n",
    "    \n",
    "    if abs(predicted_fov - actual_fov) <= 0:\n",
    "        \n",
    "        th_0 += 1 \n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 1:\n",
    "        \n",
    "        th_1 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 2:\n",
    "        \n",
    "        th_2 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 3:\n",
    "        \n",
    "        th_3 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 4:\n",
    "        \n",
    "        th_4 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 5:\n",
    "        \n",
    "        th_5 += 1\n",
    "        \n",
    "    k += 1\n",
    "\n",
    "percent_correct.append(th_0/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_1/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_2/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_3/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_4/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_5/np.shape(output)[1]*100)\n",
    "\n",
    "plt.plot([0,1,2,3,4,5],percent_correct)\n",
    "plt.xlabel(\"FOV Error Threshold (degrees)\")\n",
    "plt.ylabel(\"% Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 36906, 36906, 36906, 36906, 36906)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0, th_1, th_2, th_3, th_4, th_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.0, 1.0, 1.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0/np.shape(output)[1], th_1/np.shape(output)[1], th_2/np.shape(output)[1], th_3/np.shape(output)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 1.286216490572841, 'fy': 1.3617292269398404, 'u0': 0.4937650231999256, 'v0': 0.6355269044602613, 'baseline': 0.13129135592331664, 'disparity': 0.3337598006217669, 'x': 0.15337508699687152, 'y': 0.160628789677968, 'z': 0.16428160049230398, 'pitch': 1.0439506068432465, 'xworld': 1.5492911808480934, 'yworld': 0.8043879380865393, 'zworld': 1.9885211813851058}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.015937515621385023, 'fy': 0.015789691998922144, 'u0': 0.015129069450800097, 'v0': 0.013382435791845225, 'baseline': -0.12739093357613276, 'disparity': -0.14603019263958006, 'x': -0.1265458647332407, 'y': 0.29211547592355985, 'z': -0.511076426031596, 'pitch': -0.3085142761565729, 'xworld': -1.3364487794856912, 'yworld': 0.27129192630690024, 'zworld': 4.534190158947845}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "mean_fx = 59.32098482132037\n",
    "\n",
    "mean_fy = 59.32098482132037\n",
    "\n",
    "mean_u0 = 56.0\n",
    "\n",
    "mean_v0 = 56.0\n",
    "\n",
    "mean_baseline = -84.00701782907929\n",
    "\n",
    "mean_disparity = -10.972388226877689\n",
    "\n",
    "mean_tx = -84.00701782907929\n",
    "\n",
    "mean_ty = 0.4372459762640221\n",
    "\n",
    "mean_tz = -0.5766162683574485\n",
    "\n",
    "mean_pitch = -12.380371755270145\n",
    "\n",
    "mean_xw = -91.94288567681566\n",
    "\n",
    "mean_yw = 0.4372459762640221\n",
    "\n",
    "mean_zw = 44.48843272766856\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 86111\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx) / mean_fx\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy) / mean_fy\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0) / mean_u0\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0) / mean_v0\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline) / mean_baseline\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity) / mean_disparity\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx) / mean_tx\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty) / mean_ty\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz) / mean_tz\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch) / mean_pitch\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x) / mean_xw\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y) / mean_yw\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z) / mean_zw\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
