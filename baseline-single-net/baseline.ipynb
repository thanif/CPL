{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(1)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "\n",
    "if ros_path in sys.path:\n",
    "\n",
    "    sys.path.remove(ros_path)\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_layer(tensor):\n",
    "    return tensor[0] + tensor[1]\n",
    "\n",
    "def mul_layer(tensor):\n",
    "    return tensor[0] * tensor[1]\n",
    "\n",
    "def div_layer(tensor):\n",
    "    return tensor[0] / tensor[1]\n",
    "\n",
    "def sub_layer(tensor):\n",
    "    return tensor[0] - tensor[1]\n",
    "\n",
    "def neg_layer(tensor):\n",
    "    return -tensor\n",
    "\n",
    "def cos_layer(tensor):\n",
    "    return tf.math.cos(tensor)\n",
    "\n",
    "def sin_layer(tensor):\n",
    "    return tf.math.sin(tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 6 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_image (InputLayer)         [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 112, 112, 6)  0           left_image[0][0]                 \n",
      "                                                                 right_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 55, 55, 32)   1728        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 55, 55, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 55, 55, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 53, 53, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 53, 53, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 53, 53, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 53, 53, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 53, 53, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 53, 53, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 26, 26, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 26, 26, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 26, 26, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 26, 26, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 24, 24, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24, 24, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 24, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 11, 11, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 11, 11, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 11, 11, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 11, 11, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 11, 11, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 11, 11, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 11, 11, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 11, 11, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 11, 11, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 11, 11, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 11, 11, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 11, 11, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 11, 11, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 11, 11, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 11, 11, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 11, 11, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 11, 11, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 11, 11, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 11, 11, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 11, 11, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 11, 11, 64)   16384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 11, 11, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 11, 11, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 11, 11, 48)   12288       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 11, 11, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 11, 11, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 11, 11, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 11, 11, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 11, 11, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 11, 11, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 11, 11, 64)   16384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 11, 11, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 11, 11, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 11, 11, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 11, 11, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 11, 11, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 11, 11, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 11, 11, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 11, 11, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 11, 11, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 11, 11, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 11, 11, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 11, 11, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 11, 11, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 48)   13824       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 11, 11, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 11, 11, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 11, 11, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 11, 11, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 11, 11, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 11, 11, 288)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 11, 11, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 11, 11, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 11, 11, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 11, 11, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 11, 11, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 11, 11, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 11, 11, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 11, 11, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 11, 11, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 11, 11, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 11, 11, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 11, 11, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 11, 11, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 11, 11, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 11, 11, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 11, 11, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 11, 11, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 5, 5, 384)    995328      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 5, 5, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 5, 5, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 5, 5, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5, 5, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 5, 5, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 288)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 5, 5, 128)    98304       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 5, 5, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5, 5, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 5, 5, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 5, 5, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 5, 5, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 5, 5, 128)    98304       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 5, 5, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 5, 5, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 5, 5, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 5, 5, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 5, 5, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 5, 5, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 5, 5, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 5, 5, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 5, 5, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 5, 5, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5, 5, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 5, 5, 768)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 5, 5, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 5, 5, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 5, 5, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 5, 5, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 5, 5, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 5, 5, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 5, 5, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 5, 5, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 5, 5, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 5, 5, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 5, 5, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 5, 5, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 5, 5, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 5, 5, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 5, 5, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 5, 5, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 5, 5, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 5, 5, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5, 5, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5, 5, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 5, 5, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 5, 5, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 5, 5, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 5, 5, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 5, 5, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 5, 5, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 5, 5, 768)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 5, 5, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 5, 5, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 5, 5, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 5, 5, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 5, 5, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 5, 5, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 5, 5, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 5, 5, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 5, 5, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 5, 5, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 5, 5, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 5, 5, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 5, 5, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 5, 5, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 5, 5, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 5, 5, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 5, 5, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 5, 5, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 5, 5, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 5, 5, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 5, 5, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 5, 5, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 5, 5, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 5, 5, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5, 5, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 5, 5, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 5, 5, 768)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 5, 5, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 5, 5, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 5, 5, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 5, 5, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 5, 5, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 5, 5, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 5, 5, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 5, 5, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 5, 5, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5, 5, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5, 5, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 5, 5, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 5, 5, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 5, 5, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 5, 5, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 5, 5, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 5, 5, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 5, 5, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 5, 5, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 5, 5, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 5, 5, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 5, 5, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 5, 5, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 5, 5, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 5, 5, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 5, 5, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 5, 5, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 5, 5, 768)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 5, 5, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 5, 5, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 5, 5, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 5, 5, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 5, 5, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 5, 5, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 5, 5, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 5, 5, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 5, 5, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 5, 5, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5, 5, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 5, 5, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 5, 5, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 5, 5, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 5, 5, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 5, 5, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 5, 5, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 5, 5, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 5, 5, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)    0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 2, 2, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 2, 2, 448)    573440      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 2, 2, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 384)    491520      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 2, 2, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 2, 2, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 1280)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 320)    409600      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2, 2, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 2, 2, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 2, 2, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2, 2, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 2, 2, 2048)   0           activation_76[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 448)    917504      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 2, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 2, 2, 384)    786432      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2, 2, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 2, 2, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 2, 2, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 2, 2, 2048)   0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 2, 2, 320)    655360      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 2, 2, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2, 2, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 2, 2, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2, 2, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2, 2, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 2, 2, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 2, 2, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2, 2, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 2, 2, 2048)   0           activation_85[0][0]              \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "phi-flattened (Flatten)         (None, 8192)         0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 84)           10164       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 84)           10164       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 84)           10164       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 84)           10164       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 84)           10164       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 84)           10164       dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 84)           10164       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 84)           10164       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 84)           10164       dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 84)           10164       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 84)           10164       dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 84)           10164       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 84)           10164       dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fx (Dense)                      (None, 1)            85          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "fy (Dense)                      (None, 1)            85          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "u0 (Dense)                      (None, 1)            85          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "v0 (Dense)                      (None, 1)            85          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "baseline (Dense)                (None, 1)            85          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "disparity (Dense)               (None, 1)            85          dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 1)            85          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            85          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Dense)                       (None, 1)            85          dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pitch (Dense)                   (None, 1)            85          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "xWorld (Dense)                  (None, 1)            85          dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "yWorld (Dense)                  (None, 1)            85          dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zWorld (Dense)                  (None, 1)            85          dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 34,717,965\n",
      "Trainable params: 34,683,533\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "# feature extraction from left image\n",
    "left_img = Input(shape = (112,112,3), name=\"left_image\")\n",
    "\n",
    "# feature extraction from right image\n",
    "right_img = Input(shape = (112,112,3), name=\"right_image\")\n",
    "\n",
    "concat = concatenate([left_img, right_img])\n",
    "\n",
    "phi_model = InceptionV3(weights=None, include_top=False, input_tensor=concat, input_shape=(112,112,6))\n",
    "phi_features = phi_model.output\n",
    "flat = Flatten(name='phi-flattened')(phi_features)\n",
    "\n",
    "# fx\n",
    "dense_1 = Dense(120, activation = 'relu')(flat)\n",
    "dense_2 = Dense(84, activation = 'relu')(dense_1)\n",
    "pred_fx = Dense(1, name='fx')(dense_2)\n",
    "\n",
    "# fy\n",
    "dense_3 = Dense(120, activation = 'relu')(flat)\n",
    "dense_4 = Dense(84, activation = 'relu')(dense_3)\n",
    "pred_fy = Dense(1, name='fy')(dense_4)\n",
    "\n",
    "# u0\n",
    "dense_5 = Dense(120, activation = 'relu')(flat)\n",
    "dense_6 = Dense(84, activation = 'relu')(dense_5)\n",
    "pred_u0 = Dense(1, name='u0')(dense_6)\n",
    "\n",
    "# v0\n",
    "dense_7 = Dense(120, activation = 'relu')(flat)\n",
    "dense_8 = Dense(84, activation = 'relu')(dense_7)\n",
    "pred_v0 = Dense(1, name='v0')(dense_8)\n",
    "\n",
    "# baseline\n",
    "dense_9 = Dense(120, activation = 'relu')(flat)\n",
    "dense_10 = Dense(84, activation = 'relu')(dense_9)\n",
    "pred_baseline = Dense(1, name='baseline')(dense_10)\n",
    "\n",
    "# tx\n",
    "dense_11 = Dense(120, activation = 'relu')(flat)\n",
    "dense_12 = Dense(84, activation = 'relu')(dense_11)\n",
    "pred_x = Dense(1, name='x')(dense_12)\n",
    "\n",
    "# ty\n",
    "dense_13 = Dense(120, activation = 'relu')(flat)\n",
    "dense_14 = Dense(84, activation = 'relu')(dense_13)\n",
    "pred_y = Dense(1, name='y')(dense_14)\n",
    "\n",
    "# tz\n",
    "dense_15 = Dense(120, activation = 'relu')(flat)\n",
    "dense_16 = Dense(84, activation = 'relu')(dense_15)\n",
    "pred_z = Dense(1, name='z')(dense_16)\n",
    "\n",
    "# pitch\n",
    "dense_17 = Dense(120, activation = 'relu')(flat)\n",
    "dense_18 = Dense(84, activation = 'relu')(dense_17)\n",
    "pred_pitch = Dense(1, name='pitch')(dense_18)\n",
    "\n",
    "# u\n",
    "dense_19 = Dense(120, activation = 'relu')(flat)\n",
    "dense_20 = Dense(84, activation = 'relu')(dense_19)\n",
    "pred_u = Dense(1, name='u')(dense_20)\n",
    "\n",
    "# v\n",
    "dense_21 = Dense(120, activation = 'relu')(flat)\n",
    "dense_22 = Dense(84, activation = 'relu')(dense_21)\n",
    "pred_v = Dense(1, name='v')(dense_22)\n",
    "\n",
    "# disparity\n",
    "dense_23 = Dense(120, activation = 'relu')(flat)\n",
    "dense_24 = Dense(84, activation = 'relu')(dense_23)\n",
    "pred_disparity = Dense(1, name='disparity')(dense_24)\n",
    "\n",
    "# yWorld\n",
    "dense_25 = Dense(120, activation = 'relu')(flat)\n",
    "dense_26 = Dense(84, activation = 'relu')(dense_25)\n",
    "pred_yWorld = Dense(1, name='yWorld')(dense_26)\n",
    "\n",
    "# xWorld\n",
    "dense_27 = Dense(120, activation = 'relu')(flat)\n",
    "dense_28 = Dense(84, activation = 'relu')(dense_27)\n",
    "pred_xWorld = Dense(1, name='xWorld')(dense_28)\n",
    "\n",
    "# zWorld\n",
    "dense_29 = Dense(120, activation = 'relu')(flat)\n",
    "dense_30 = Dense(84, activation = 'relu')(dense_29)\n",
    "pred_zWorld = Dense(1, name='zWorld')(dense_30)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[left_img, right_img], outputs=[pred_fx, pred_fy, pred_u0, pred_v0, pred_baseline, pred_disparity, pred_x, pred_y, pred_z, pred_pitch, pred_xWorld,pred_yWorld,pred_zWorld])\n",
    "\n",
    "# set output types\n",
    "target1 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target2 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target3 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target4 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target5 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target6 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target7 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target8 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target9 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target10 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target11 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target12 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target13 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "\n",
    "# get model summary\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"mae\", target_tensors=[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12, target13],optimizer=optimizers.Adam(lr=learning_rate))\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/\"\n",
    "\n",
    "Left_images = np.load(data_path+\"li.npy\")\n",
    "Right_images = np.load(data_path+\"ri.npy\")\n",
    "Fx = np.load(data_path+\"fx.npy\")\n",
    "Fy = np.load(data_path+\"fy.npy\") \n",
    "U0 = np.load(data_path+\"u0.npy\") \n",
    "V0 = np.load(data_path+\"v0.npy\") \n",
    "Baseline = np.load(data_path+\"b.npy\")\n",
    "Disparity = np.load(data_path+\"d.npy\") \n",
    "Tx = np.load(data_path+\"tx.npy\") \n",
    "Ty = np.load(data_path+\"ty.npy\") \n",
    "Tz = np.load(data_path+\"tz.npy\") \n",
    "Pitch = np.load(data_path+\"p.npy\")\n",
    "X = np.load(data_path+\"x.npy\")\n",
    "Y = np.load(data_path+\"y.npy\") \n",
    "Z = np.load(data_path+\"z.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  (123017,)\n"
     ]
    }
   ],
   "source": [
    "print (\"dataset: \",np.shape(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:  86111.9 Test Dataset:  36905.1\n"
     ]
    }
   ],
   "source": [
    "print (\"Training Dataset: \",len(Left_images)*0.7, \"Test Dataset: \", len(Left_images)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86111 samples, validate on 36906 samples\n",
      "Epoch 1/200\n",
      "   32/86111 [..............................] - ETA: 1:39:40 - loss: 886.3412 - fx_loss: 48.6781 - fy_loss: 49.2416 - u0_loss: 46.2155 - v0_loss: 49.2713 - baseline_loss: 84.3401 - disparity_loss: 7.7593 - x_loss: 85.3362 - y_loss: 3.0237 - z_loss: 1.6439 - pitch_loss: 18.3428 - xWorld_loss: 165.6649 - yWorld_loss: 3.0628 - zWorld_loss: 323.7610WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.2376s vs `on_train_batch_begin` time: 1.3523s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2376s vs `on_train_batch_end` time: 0.6324s). Check your callbacks.\n",
      "86111/86111 [==============================] - ETA: 0s - loss: 732.8887 - fx_loss: 6.4827 - fy_loss: 6.4464 - u0_loss: 0.8658 - v0_loss: 0.8600 - baseline_loss: 19.4572 - disparity_loss: 2.4652 - x_loss: 19.3333 - y_loss: 0.5958 - z_loss: 0.4572 - pitch_loss: 6.8092 - xWorld_loss: 298.8899 - yWorld_loss: 0.5902 - zWorld_loss: 369.6348 - ETA: 25s - loss: 743.3810 - fx_loss: 6.6075WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "86111/86111 [==============================] - 911s 11ms/sample - loss: 732.8887 - fx_loss: 6.4827 - fy_loss: 6.4464 - u0_loss: 0.8658 - v0_loss: 0.8600 - baseline_loss: 19.4572 - disparity_loss: 2.4652 - x_loss: 19.3333 - y_loss: 0.5958 - z_loss: 0.4572 - pitch_loss: 6.8092 - xWorld_loss: 298.8899 - yWorld_loss: 0.5902 - zWorld_loss: 369.6348 - val_loss: 366.1293 - val_fx_loss: 2.2739 - val_fy_loss: 2.6529 - val_u0_loss: 1.6852 - val_v0_loss: 0.4340 - val_baseline_loss: 7.4176 - val_disparity_loss: 2.2468 - val_x_loss: 6.0601 - val_y_loss: 0.1935 - val_z_loss: 0.2077 - val_pitch_loss: 2.1445 - val_xWorld_loss: 126.9337 - val_yWorld_loss: 0.2080 - val_zWorld_loss: 213.6519\n",
      "Epoch 2/200\n",
      "86111/86111 [==============================] - 920s 11ms/sample - loss: 512.5079 - fx_loss: 2.3921 - fy_loss: 2.3213 - u0_loss: 0.3892 - v0_loss: 0.3910 - baseline_loss: 6.3634 - disparity_loss: 2.0824 - x_loss: 6.3459 - y_loss: 0.2005 - z_loss: 0.1796 - pitch_loss: 2.0910 - xWorld_loss: 221.7954 - yWorld_loss: 0.2131 - zWorld_loss: 267.7403 - val_loss: 384.9946 - val_fx_loss: 2.1620 - val_fy_loss: 2.1107 - val_u0_loss: 0.9346 - val_v0_loss: 0.9374 - val_baseline_loss: 7.5470 - val_disparity_loss: 2.2471 - val_x_loss: 7.3795 - val_y_loss: 0.1847 - val_z_loss: 0.1404 - val_pitch_loss: 2.0840 - val_xWorld_loss: 132.7909 - val_yWorld_loss: 0.2010 - val_zWorld_loss: 226.2381\n",
      "Epoch 3/200\n",
      "86111/86111 [==============================] - 971s 11ms/sample - loss: 476.5632 - fx_loss: 1.6490 - fy_loss: 1.6022 - u0_loss: 0.2943 - v0_loss: 0.2990 - baseline_loss: 4.6688 - disparity_loss: 1.8789 - x_loss: 4.6396 - y_loss: 0.1432 - z_loss: 0.1272 - pitch_loss: 1.5035 - xWorld_loss: 210.1207 - yWorld_loss: 0.1510 - zWorld_loss: 249.4807 - val_loss: 314.9124 - val_fx_loss: 1.0975 - val_fy_loss: 1.4398 - val_u0_loss: 0.8896 - val_v0_loss: 1.5489 - val_baseline_loss: 3.3521 - val_disparity_loss: 1.8498 - val_x_loss: 3.0798 - val_y_loss: 0.1338 - val_z_loss: 0.0751 - val_pitch_loss: 1.0539 - val_xWorld_loss: 113.1454 - val_yWorld_loss: 0.1587 - val_zWorld_loss: 187.2895\n",
      "Epoch 4/200\n",
      "86111/86111 [==============================] - 970s 11ms/sample - loss: 462.5052 - fx_loss: 1.4051 - fy_loss: 1.3474 - u0_loss: 0.2561 - v0_loss: 0.2692 - baseline_loss: 3.9978 - disparity_loss: 1.7863 - x_loss: 3.9788 - y_loss: 0.1222 - z_loss: 0.1075 - pitch_loss: 1.2660 - xWorld_loss: 205.7242 - yWorld_loss: 0.1291 - zWorld_loss: 242.1124 - val_loss: 294.6914 - val_fx_loss: 1.0265 - val_fy_loss: 1.1373 - val_u0_loss: 0.4037 - val_v0_loss: 0.5589 - val_baseline_loss: 3.1927 - val_disparity_loss: 1.6430 - val_x_loss: 3.3323 - val_y_loss: 0.0863 - val_z_loss: 0.0748 - val_pitch_loss: 1.0022 - val_xWorld_loss: 104.9409 - val_yWorld_loss: 0.1226 - val_zWorld_loss: 177.1361\n",
      "Epoch 5/200\n",
      "86111/86111 [==============================] - 972s 11ms/sample - loss: 446.2485 - fx_loss: 1.1353 - fy_loss: 1.0934 - u0_loss: 0.2226 - v0_loss: 0.2400 - baseline_loss: 3.2546 - disparity_loss: 1.6934 - x_loss: 3.2412 - y_loss: 0.1008 - z_loss: 0.0882 - pitch_loss: 0.9970 - xWorld_loss: 200.0618 - yWorld_loss: 0.1051 - zWorld_loss: 234.0115 - val_loss: 298.2445 - val_fx_loss: 1.2129 - val_fy_loss: 1.1858 - val_u0_loss: 0.8797 - val_v0_loss: 0.5653 - val_baseline_loss: 3.5052 - val_disparity_loss: 1.6676 - val_x_loss: 2.6358 - val_y_loss: 0.0948 - val_z_loss: 0.0751 - val_pitch_loss: 0.9309 - val_xWorld_loss: 104.4474 - val_yWorld_loss: 0.0951 - val_zWorld_loss: 180.9506\n",
      "Epoch 6/200\n",
      "86111/86111 [==============================] - 799s 9ms/sample - loss: 439.4391 - fx_loss: 1.0148 - fy_loss: 0.9810 - u0_loss: 0.2052 - v0_loss: 0.2180 - baseline_loss: 3.0176 - disparity_loss: 1.6550 - x_loss: 3.0031 - y_loss: 0.0904 - z_loss: 0.0788 - pitch_loss: 0.9070 - xWorld_loss: 198.4579 - yWorld_loss: 0.0949 - zWorld_loss: 229.7111 - val_loss: 312.9648 - val_fx_loss: 1.2601 - val_fy_loss: 1.1429 - val_u0_loss: 0.3208 - val_v0_loss: 0.3361 - val_baseline_loss: 4.2414 - val_disparity_loss: 1.6357 - val_x_loss: 4.6028 - val_y_loss: 0.1288 - val_z_loss: 0.0877 - val_pitch_loss: 1.1625 - val_xWorld_loss: 109.0769 - val_yWorld_loss: 0.1598 - val_zWorld_loss: 188.7819\n",
      "Epoch 7/200\n",
      "86111/86111 [==============================] - 790s 9ms/sample - loss: 432.0126 - fx_loss: 0.9111 - fy_loss: 0.8754 - u0_loss: 0.1925 - v0_loss: 0.1964 - baseline_loss: 2.6212 - disparity_loss: 1.6071 - x_loss: 2.6063 - y_loss: 0.0826 - z_loss: 0.0702 - pitch_loss: 0.8127 - xWorld_loss: 195.7739 - yWorld_loss: 0.0843 - zWorld_loss: 226.1769 - val_loss: 274.5450 - val_fx_loss: 0.6898 - val_fy_loss: 0.7658 - val_u0_loss: 0.1764 - val_v0_loss: 0.1661 - val_baseline_loss: 2.0532 - val_disparity_loss: 1.5346 - val_x_loss: 2.1118 - val_y_loss: 0.0557 - val_z_loss: 0.1163 - val_pitch_loss: 0.6308 - val_xWorld_loss: 98.7119 - val_yWorld_loss: 0.0634 - val_zWorld_loss: 167.4426\n",
      "Epoch 8/200\n",
      "86111/86111 [==============================] - 789s 9ms/sample - loss: 427.0718 - fx_loss: 0.8070 - fy_loss: 0.7795 - u0_loss: 0.1769 - v0_loss: 0.1806 - baseline_loss: 2.4628 - disparity_loss: 1.5697 - x_loss: 2.4531 - y_loss: 0.0738 - z_loss: 0.0658 - pitch_loss: 0.7352 - xWorld_loss: 193.8145 - yWorld_loss: 0.0763 - zWorld_loss: 223.8717 - val_loss: 272.1679 - val_fx_loss: 0.6612 - val_fy_loss: 0.5708 - val_u0_loss: 0.3722 - val_v0_loss: 0.4945 - val_baseline_loss: 2.0823 - val_disparity_loss: 1.4916 - val_x_loss: 2.0124 - val_y_loss: 0.0721 - val_z_loss: 0.0398 - val_pitch_loss: 0.5523 - val_xWorld_loss: 98.0319 - val_yWorld_loss: 0.0593 - val_zWorld_loss: 165.6942\n",
      "Epoch 9/200\n",
      "86111/86111 [==============================] - 766s 9ms/sample - loss: 423.8500 - fx_loss: 0.7541 - fy_loss: 0.7192 - u0_loss: 0.1731 - v0_loss: 0.1831 - baseline_loss: 2.2702 - disparity_loss: 1.5475 - x_loss: 2.2606 - y_loss: 0.0693 - z_loss: 0.0579 - pitch_loss: 0.6808 - xWorld_loss: 192.3168 - yWorld_loss: 0.0708 - zWorld_loss: 222.7431 - val_loss: 284.3971 - val_fx_loss: 0.8167 - val_fy_loss: 1.3774 - val_u0_loss: 0.5911 - val_v0_loss: 0.6565 - val_baseline_loss: 2.5874 - val_disparity_loss: 1.4742 - val_x_loss: 2.4814 - val_y_loss: 0.0827 - val_z_loss: 0.0635 - val_pitch_loss: 0.8734 - val_xWorld_loss: 102.3645 - val_yWorld_loss: 0.0730 - val_zWorld_loss: 170.9504\n",
      "Epoch 10/200\n",
      "86111/86111 [==============================] - 790s 9ms/sample - loss: 416.9947 - fx_loss: 0.6705 - fy_loss: 0.6332 - u0_loss: 0.1658 - v0_loss: 0.1742 - baseline_loss: 2.0207 - disparity_loss: 1.5169 - x_loss: 2.0104 - y_loss: 0.0614 - z_loss: 0.0511 - pitch_loss: 0.6098 - xWorld_loss: 190.5144 - yWorld_loss: 0.0635 - zWorld_loss: 218.4989 - val_loss: 286.5101 - val_fx_loss: 1.7910 - val_fy_loss: 1.1529 - val_u0_loss: 0.8552 - val_v0_loss: 0.9380 - val_baseline_loss: 3.5336 - val_disparity_loss: 1.5194 - val_x_loss: 3.9206 - val_y_loss: 0.1063 - val_z_loss: 0.0516 - val_pitch_loss: 0.8861 - val_xWorld_loss: 99.6772 - val_yWorld_loss: 0.0910 - val_zWorld_loss: 171.9623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "86111/86111 [==============================] - 764s 9ms/sample - loss: 414.9658 - fx_loss: 0.6447 - fy_loss: 0.6074 - u0_loss: 0.1562 - v0_loss: 0.1642 - baseline_loss: 1.9409 - disparity_loss: 1.4978 - x_loss: 1.9419 - y_loss: 0.0584 - z_loss: 0.0506 - pitch_loss: 0.5696 - xWorld_loss: 189.6433 - yWorld_loss: 0.0610 - zWorld_loss: 217.6269 - val_loss: 275.4403 - val_fx_loss: 1.1987 - val_fy_loss: 1.2079 - val_u0_loss: 0.8748 - val_v0_loss: 0.7174 - val_baseline_loss: 2.7015 - val_disparity_loss: 1.4704 - val_x_loss: 3.4532 - val_y_loss: 0.0775 - val_z_loss: 0.0434 - val_pitch_loss: 0.7879 - val_xWorld_loss: 96.7540 - val_yWorld_loss: 0.0815 - val_zWorld_loss: 166.6905\n",
      "Epoch 12/200\n",
      "86111/86111 [==============================] - 800s 9ms/sample - loss: 412.7361 - fx_loss: 0.5943 - fy_loss: 0.5560 - u0_loss: 0.1444 - v0_loss: 0.1522 - baseline_loss: 1.7088 - disparity_loss: 1.4812 - x_loss: 1.7138 - y_loss: 0.0556 - z_loss: 0.0454 - pitch_loss: 0.5356 - xWorld_loss: 188.8898 - yWorld_loss: 0.0576 - zWorld_loss: 216.7973 - val_loss: 272.8016 - val_fx_loss: 1.1867 - val_fy_loss: 0.9890 - val_u0_loss: 0.3503 - val_v0_loss: 0.7074 - val_baseline_loss: 1.9149 - val_disparity_loss: 1.4513 - val_x_loss: 2.0182 - val_y_loss: 0.0802 - val_z_loss: 0.0360 - val_pitch_loss: 0.6457 - val_xWorld_loss: 96.4202 - val_yWorld_loss: 0.0680 - val_zWorld_loss: 166.9102\n",
      "Epoch 13/200\n",
      "86111/86111 [==============================] - 982s 11ms/sample - loss: 410.3598 - fx_loss: 0.5588 - fy_loss: 0.5290 - u0_loss: 0.1399 - v0_loss: 0.1521 - baseline_loss: 1.6645 - disparity_loss: 1.4605 - x_loss: 1.6568 - y_loss: 0.0522 - z_loss: 0.0424 - pitch_loss: 0.5104 - xWorld_loss: 188.1950 - yWorld_loss: 0.0545 - zWorld_loss: 215.3448 - val_loss: 263.8061 - val_fx_loss: 0.8630 - val_fy_loss: 1.1243 - val_u0_loss: 0.6597 - val_v0_loss: 0.8942 - val_baseline_loss: 2.5701 - val_disparity_loss: 1.3825 - val_x_loss: 2.2911 - val_y_loss: 0.0629 - val_z_loss: 0.0370 - val_pitch_loss: 0.6464 - val_xWorld_loss: 94.2242 - val_yWorld_loss: 0.0661 - val_zWorld_loss: 158.9506\n",
      "Epoch 14/200\n",
      "86111/86111 [==============================] - 981s 11ms/sample - loss: 405.7571 - fx_loss: 0.5203 - fy_loss: 0.5045 - u0_loss: 0.1390 - v0_loss: 0.1420 - baseline_loss: 1.4839 - disparity_loss: 1.4286 - x_loss: 1.4727 - y_loss: 0.0501 - z_loss: 0.0405 - pitch_loss: 0.4657 - xWorld_loss: 186.9391 - yWorld_loss: 0.0503 - zWorld_loss: 212.5213 - val_loss: 268.1862 - val_fx_loss: 0.8916 - val_fy_loss: 1.4115 - val_u0_loss: 0.5315 - val_v0_loss: 0.6228 - val_baseline_loss: 2.3031 - val_disparity_loss: 1.3926 - val_x_loss: 2.5973 - val_y_loss: 0.0689 - val_z_loss: 0.0475 - val_pitch_loss: 0.7114 - val_xWorld_loss: 98.2479 - val_yWorld_loss: 0.0588 - val_zWorld_loss: 159.2655\n",
      "Epoch 15/200\n",
      "86111/86111 [==============================] - 976s 11ms/sample - loss: 406.3251 - fx_loss: 0.5258 - fy_loss: 0.5129 - u0_loss: 0.1279 - v0_loss: 0.1357 - baseline_loss: 1.4784 - disparity_loss: 1.4237 - x_loss: 1.4817 - y_loss: 0.0491 - z_loss: 0.0426 - pitch_loss: 0.4610 - xWorld_loss: 187.1847 - yWorld_loss: 0.0500 - zWorld_loss: 212.8474 - val_loss: 255.6429 - val_fx_loss: 0.8364 - val_fy_loss: 0.6472 - val_u0_loss: 0.3593 - val_v0_loss: 0.3404 - val_baseline_loss: 2.0398 - val_disparity_loss: 1.4114 - val_x_loss: 1.6170 - val_y_loss: 0.0396 - val_z_loss: 0.0367 - val_pitch_loss: 0.5553 - val_xWorld_loss: 92.5705 - val_yWorld_loss: 0.0537 - val_zWorld_loss: 155.1022\n",
      "Epoch 16/200\n",
      "86111/86111 [==============================] - 930s 11ms/sample - loss: 404.4835 - fx_loss: 0.4933 - fy_loss: 0.4695 - u0_loss: 0.1230 - v0_loss: 0.1244 - baseline_loss: 1.5376 - disparity_loss: 1.4038 - x_loss: 1.5430 - y_loss: 0.0465 - z_loss: 0.0378 - pitch_loss: 0.4539 - xWorld_loss: 185.6799 - yWorld_loss: 0.0486 - zWorld_loss: 212.5190 - val_loss: 278.3978 - val_fx_loss: 1.0352 - val_fy_loss: 0.8400 - val_u0_loss: 1.0864 - val_v0_loss: 0.8174 - val_baseline_loss: 3.4645 - val_disparity_loss: 1.3785 - val_x_loss: 3.2514 - val_y_loss: 0.0760 - val_z_loss: 0.0543 - val_pitch_loss: 0.7472 - val_xWorld_loss: 96.1343 - val_yWorld_loss: 0.0513 - val_zWorld_loss: 169.4258\n",
      "Epoch 17/200\n",
      "86111/86111 [==============================] - 795s 9ms/sample - loss: 400.6640 - fx_loss: 0.4523 - fy_loss: 0.4369 - u0_loss: 0.1207 - v0_loss: 0.1220 - baseline_loss: 1.3429 - disparity_loss: 1.3894 - x_loss: 1.3455 - y_loss: 0.0433 - z_loss: 0.0361 - pitch_loss: 0.4161 - xWorld_loss: 184.6711 - yWorld_loss: 0.0436 - zWorld_loss: 210.2417 - val_loss: 275.6519 - val_fx_loss: 1.0486 - val_fy_loss: 1.2132 - val_u0_loss: 0.8301 - val_v0_loss: 0.6657 - val_baseline_loss: 3.0053 - val_disparity_loss: 1.4730 - val_x_loss: 3.1733 - val_y_loss: 0.0736 - val_z_loss: 0.0609 - val_pitch_loss: 0.9404 - val_xWorld_loss: 97.8435 - val_yWorld_loss: 0.0897 - val_zWorld_loss: 165.1970\n",
      "Epoch 18/200\n",
      "86111/86111 [==============================] - 791s 9ms/sample - loss: 399.6405 - fx_loss: 0.4410 - fy_loss: 0.4359 - u0_loss: 0.1185 - v0_loss: 0.1210 - baseline_loss: 1.3445 - disparity_loss: 1.3811 - x_loss: 1.3469 - y_loss: 0.0431 - z_loss: 0.0353 - pitch_loss: 0.4124 - xWorld_loss: 184.4396 - yWorld_loss: 0.0438 - zWorld_loss: 209.4818 - val_loss: 263.0602 - val_fx_loss: 1.2233 - val_fy_loss: 1.2744 - val_u0_loss: 0.7211 - val_v0_loss: 0.8371 - val_baseline_loss: 2.5719 - val_disparity_loss: 1.3611 - val_x_loss: 1.8689 - val_y_loss: 0.0704 - val_z_loss: 0.0468 - val_pitch_loss: 0.7174 - val_xWorld_loss: 92.0922 - val_yWorld_loss: 0.0468 - val_zWorld_loss: 160.2160\n",
      "Epoch 19/200\n",
      "86111/86111 [==============================] - 766s 9ms/sample - loss: 397.1797 - fx_loss: 0.4156 - fy_loss: 0.4106 - u0_loss: 0.1131 - v0_loss: 0.1215 - baseline_loss: 1.2004 - disparity_loss: 1.3637 - x_loss: 1.2072 - y_loss: 0.0408 - z_loss: 0.0328 - pitch_loss: 0.3819 - xWorld_loss: 183.6201 - yWorld_loss: 0.0406 - zWorld_loss: 208.2282 - val_loss: 252.4225 - val_fx_loss: 1.0473 - val_fy_loss: 0.7455 - val_u0_loss: 0.4510 - val_v0_loss: 0.5980 - val_baseline_loss: 1.1994 - val_disparity_loss: 1.3141 - val_x_loss: 1.0932 - val_y_loss: 0.0390 - val_z_loss: 0.0253 - val_pitch_loss: 0.4528 - val_xWorld_loss: 90.9244 - val_yWorld_loss: 0.0306 - val_zWorld_loss: 154.5001\n",
      "Epoch 20/200\n",
      "86111/86111 [==============================] - 767s 9ms/sample - loss: 396.6236 - fx_loss: 0.3959 - fy_loss: 0.3928 - u0_loss: 0.1098 - v0_loss: 0.1223 - baseline_loss: 1.1327 - disparity_loss: 1.3567 - x_loss: 1.1394 - y_loss: 0.0390 - z_loss: 0.0312 - pitch_loss: 0.3590 - xWorld_loss: 183.4250 - yWorld_loss: 0.0393 - zWorld_loss: 208.0771 - val_loss: 254.0450 - val_fx_loss: 0.9426 - val_fy_loss: 0.8662 - val_u0_loss: 0.7389 - val_v0_loss: 0.8854 - val_baseline_loss: 1.9328 - val_disparity_loss: 1.3388 - val_x_loss: 1.9358 - val_y_loss: 0.0556 - val_z_loss: 0.0239 - val_pitch_loss: 0.5459 - val_xWorld_loss: 89.4403 - val_yWorld_loss: 0.0421 - val_zWorld_loss: 155.2644\n",
      "Epoch 21/200\n",
      "86111/86111 [==============================] - 791s 9ms/sample - loss: 395.2336 - fx_loss: 0.3987 - fy_loss: 0.3835 - u0_loss: 0.1132 - v0_loss: 0.1158 - baseline_loss: 1.1109 - disparity_loss: 1.3440 - x_loss: 1.1210 - y_loss: 0.0389 - z_loss: 0.0326 - pitch_loss: 0.3642 - xWorld_loss: 182.8320 - yWorld_loss: 0.0386 - zWorld_loss: 207.3397 - val_loss: 248.3125 - val_fx_loss: 0.7720 - val_fy_loss: 0.6395 - val_u0_loss: 0.5461 - val_v0_loss: 0.4610 - val_baseline_loss: 2.2411 - val_disparity_loss: 1.3228 - val_x_loss: 1.5084 - val_y_loss: 0.0287 - val_z_loss: 0.0214 - val_pitch_loss: 0.4953 - val_xWorld_loss: 88.7760 - val_yWorld_loss: 0.0356 - val_zWorld_loss: 151.4366\n",
      "Epoch 22/200\n",
      "86111/86111 [==============================] - 766s 9ms/sample - loss: 394.7666 - fx_loss: 0.4016 - fy_loss: 0.3899 - u0_loss: 0.1066 - v0_loss: 0.1084 - baseline_loss: 1.1056 - disparity_loss: 1.3319 - x_loss: 1.1107 - y_loss: 0.0383 - z_loss: 0.0307 - pitch_loss: 0.3575 - xWorld_loss: 182.8873 - yWorld_loss: 0.0423 - zWorld_loss: 206.8529 - val_loss: 313.8438 - val_fx_loss: 1.3498 - val_fy_loss: 1.4228 - val_u0_loss: 0.5168 - val_v0_loss: 0.6229 - val_baseline_loss: 3.6566 - val_disparity_loss: 1.4839 - val_x_loss: 3.0005 - val_y_loss: 0.0817 - val_z_loss: 0.0790 - val_pitch_loss: 1.2934 - val_xWorld_loss: 122.3776 - val_yWorld_loss: 0.0757 - val_zWorld_loss: 177.8397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200\n",
      "86111/86111 [==============================] - 767s 9ms/sample - loss: 392.6423 - fx_loss: 0.3758 - fy_loss: 0.3714 - u0_loss: 0.1066 - v0_loss: 0.1126 - baseline_loss: 1.0688 - disparity_loss: 1.3253 - x_loss: 1.0688 - y_loss: 0.0365 - z_loss: 0.0291 - pitch_loss: 0.3418 - xWorld_loss: 182.0651 - yWorld_loss: 0.0391 - zWorld_loss: 205.6974 - val_loss: 252.5863 - val_fx_loss: 0.9316 - val_fy_loss: 0.6442 - val_u0_loss: 0.5633 - val_v0_loss: 0.4608 - val_baseline_loss: 1.9007 - val_disparity_loss: 1.3790 - val_x_loss: 1.7853 - val_y_loss: 0.0405 - val_z_loss: 0.0271 - val_pitch_loss: 0.3747 - val_xWorld_loss: 90.4851 - val_yWorld_loss: 0.0531 - val_zWorld_loss: 153.9083\n",
      "Epoch 24/200\n",
      "86111/86111 [==============================] - 790s 9ms/sample - loss: 391.9239 - fx_loss: 0.3630 - fy_loss: 0.3476 - u0_loss: 0.1057 - v0_loss: 0.1087 - baseline_loss: 1.0498 - disparity_loss: 1.3159 - x_loss: 1.0570 - y_loss: 0.0358 - z_loss: 0.0291 - pitch_loss: 0.3412 - xWorld_loss: 181.9281 - yWorld_loss: 0.0363 - zWorld_loss: 205.2025 - val_loss: 251.4694 - val_fx_loss: 0.3658 - val_fy_loss: 0.3635 - val_u0_loss: 0.1503 - val_v0_loss: 0.1751 - val_baseline_loss: 1.1335 - val_disparity_loss: 1.2859 - val_x_loss: 1.0946 - val_y_loss: 0.0508 - val_z_loss: 0.0267 - val_pitch_loss: 0.3703 - val_xWorld_loss: 90.3134 - val_yWorld_loss: 0.0429 - val_zWorld_loss: 156.0711\n",
      "Epoch 25/200\n",
      "86111/86111 [==============================] - 788s 9ms/sample - loss: 389.1346 - fx_loss: 0.3654 - fy_loss: 0.3435 - u0_loss: 0.1022 - v0_loss: 0.1113 - baseline_loss: 0.9516 - disparity_loss: 1.3038 - x_loss: 0.9597 - y_loss: 0.0351 - z_loss: 0.0271 - pitch_loss: 0.3033 - xWorld_loss: 180.7234 - yWorld_loss: 0.0357 - zWorld_loss: 203.8714 - val_loss: 245.6620 - val_fx_loss: 0.8523 - val_fy_loss: 0.8153 - val_u0_loss: 0.5549 - val_v0_loss: 0.6360 - val_baseline_loss: 1.6307 - val_disparity_loss: 1.2702 - val_x_loss: 1.5126 - val_y_loss: 0.0303 - val_z_loss: 0.0193 - val_pitch_loss: 0.5421 - val_xWorld_loss: 88.0092 - val_yWorld_loss: 0.0471 - val_zWorld_loss: 149.7076\n",
      "Epoch 26/200\n",
      "86111/86111 [==============================] - 766s 9ms/sample - loss: 390.1393 - fx_loss: 0.3615 - fy_loss: 0.3513 - u0_loss: 0.1053 - v0_loss: 0.1085 - baseline_loss: 0.9695 - disparity_loss: 1.3014 - x_loss: 0.9712 - y_loss: 0.0359 - z_loss: 0.0265 - pitch_loss: 0.3194 - xWorld_loss: 181.4275 - yWorld_loss: 0.0368 - zWorld_loss: 204.1215 - val_loss: 249.3308 - val_fx_loss: 0.7059 - val_fy_loss: 0.6779 - val_u0_loss: 0.5625 - val_v0_loss: 0.6525 - val_baseline_loss: 2.0576 - val_disparity_loss: 1.3252 - val_x_loss: 1.8242 - val_y_loss: 0.0479 - val_z_loss: 0.0224 - val_pitch_loss: 0.4489 - val_xWorld_loss: 88.9729 - val_yWorld_loss: 0.0304 - val_zWorld_loss: 152.0635\n",
      "Epoch 27/200\n",
      "86111/86111 [==============================] - 766s 9ms/sample - loss: 387.6578 - fx_loss: 0.3472 - fy_loss: 0.3399 - u0_loss: 0.1007 - v0_loss: 0.1045 - baseline_loss: 0.9100 - disparity_loss: 1.2937 - x_loss: 0.9204 - y_loss: 0.0346 - z_loss: 0.0248 - pitch_loss: 0.3009 - xWorld_loss: 180.4120 - yWorld_loss: 0.0352 - zWorld_loss: 202.8301 - val_loss: 247.6678 - val_fx_loss: 0.6692 - val_fy_loss: 0.5652 - val_u0_loss: 0.6443 - val_v0_loss: 0.6846 - val_baseline_loss: 1.2757 - val_disparity_loss: 1.2626 - val_x_loss: 1.7624 - val_y_loss: 0.0318 - val_z_loss: 0.0220 - val_pitch_loss: 0.4308 - val_xWorld_loss: 89.1452 - val_yWorld_loss: 0.0463 - val_zWorld_loss: 151.0952\n",
      "Epoch 28/200\n",
      "86111/86111 [==============================] - 821s 10ms/sample - loss: 387.3721 - fx_loss: 0.3375 - fy_loss: 0.3295 - u0_loss: 0.1013 - v0_loss: 0.1036 - baseline_loss: 0.8676 - disparity_loss: 1.2856 - x_loss: 0.8629 - y_loss: 0.0339 - z_loss: 0.0227 - pitch_loss: 0.2947 - xWorld_loss: 180.0325 - yWorld_loss: 0.0338 - zWorld_loss: 203.0632 - val_loss: 248.6697 - val_fx_loss: 1.0376 - val_fy_loss: 1.1282 - val_u0_loss: 0.8659 - val_v0_loss: 0.8174 - val_baseline_loss: 1.3907 - val_disparity_loss: 1.2666 - val_x_loss: 2.1216 - val_y_loss: 0.0404 - val_z_loss: 0.0343 - val_pitch_loss: 0.5298 - val_xWorld_loss: 88.6851 - val_yWorld_loss: 0.0421 - val_zWorld_loss: 150.6964\n",
      "Epoch 29/200\n",
      "86111/86111 [==============================] - 800s 9ms/sample - loss: 385.8892 - fx_loss: 0.3247 - fy_loss: 0.3194 - u0_loss: 0.0992 - v0_loss: 0.1083 - baseline_loss: 0.8771 - disparity_loss: 1.2761 - x_loss: 0.8805 - y_loss: 0.0331 - z_loss: 0.0244 - pitch_loss: 0.2847 - xWorld_loss: 179.3758 - yWorld_loss: 0.0330 - zWorld_loss: 202.2509 - val_loss: 244.0794 - val_fx_loss: 0.4538 - val_fy_loss: 0.5871 - val_u0_loss: 0.2228 - val_v0_loss: 0.2115 - val_baseline_loss: 0.9510 - val_disparity_loss: 1.2940 - val_x_loss: 1.2270 - val_y_loss: 0.0356 - val_z_loss: 0.0300 - val_pitch_loss: 0.2812 - val_xWorld_loss: 89.0927 - val_yWorld_loss: 0.0315 - val_zWorld_loss: 149.6730\n",
      "Epoch 30/200\n",
      "86111/86111 [==============================] - 798s 9ms/sample - loss: 384.5751 - fx_loss: 0.3156 - fy_loss: 0.3048 - u0_loss: 0.0958 - v0_loss: 0.1043 - baseline_loss: 0.8285 - disparity_loss: 1.2639 - x_loss: 0.8196 - y_loss: 0.0325 - z_loss: 0.0242 - pitch_loss: 0.2678 - xWorld_loss: 179.1209 - yWorld_loss: 0.0326 - zWorld_loss: 201.3629 - val_loss: 250.8251 - val_fx_loss: 0.9041 - val_fy_loss: 1.2942 - val_u0_loss: 0.9940 - val_v0_loss: 0.9032 - val_baseline_loss: 2.2987 - val_disparity_loss: 1.2942 - val_x_loss: 2.4433 - val_y_loss: 0.0612 - val_z_loss: 0.0258 - val_pitch_loss: 0.5435 - val_xWorld_loss: 88.9920 - val_yWorld_loss: 0.0473 - val_zWorld_loss: 151.0097\n",
      "Epoch 31/200\n",
      "86111/86111 [==============================] - 842s 10ms/sample - loss: 382.6202 - fx_loss: 0.3024 - fy_loss: 0.2901 - u0_loss: 0.0927 - v0_loss: 0.0978 - baseline_loss: 0.7615 - disparity_loss: 1.2571 - x_loss: 0.7619 - y_loss: 0.0311 - z_loss: 0.0201 - pitch_loss: 0.2511 - xWorld_loss: 178.4525 - yWorld_loss: 0.0312 - zWorld_loss: 200.2682 - val_loss: 249.8077 - val_fx_loss: 0.9408 - val_fy_loss: 1.1075 - val_u0_loss: 0.8658 - val_v0_loss: 0.6570 - val_baseline_loss: 1.9247 - val_disparity_loss: 1.2856 - val_x_loss: 2.0110 - val_y_loss: 0.0372 - val_z_loss: 0.0223 - val_pitch_loss: 0.5113 - val_xWorld_loss: 87.8903 - val_yWorld_loss: 0.0568 - val_zWorld_loss: 152.4635\n",
      "Epoch 32/200\n",
      "86111/86111 [==============================] - 812s 9ms/sample - loss: 382.1538 - fx_loss: 0.3021 - fy_loss: 0.2944 - u0_loss: 0.0968 - v0_loss: 0.0995 - baseline_loss: 0.7913 - disparity_loss: 1.2432 - x_loss: 0.7942 - y_loss: 0.0313 - z_loss: 0.0211 - pitch_loss: 0.2452 - xWorld_loss: 178.1782 - yWorld_loss: 0.0316 - zWorld_loss: 200.0213 - val_loss: 245.4127 - val_fx_loss: 0.7277 - val_fy_loss: 0.8249 - val_u0_loss: 0.5246 - val_v0_loss: 0.3810 - val_baseline_loss: 1.2305 - val_disparity_loss: 1.2616 - val_x_loss: 0.9333 - val_y_loss: 0.0658 - val_z_loss: 0.0182 - val_pitch_loss: 0.3773 - val_xWorld_loss: 88.3881 - val_yWorld_loss: 0.0485 - val_zWorld_loss: 150.6004\n",
      "Epoch 33/200\n",
      "86111/86111 [==============================] - 795s 9ms/sample - loss: 381.8711 - fx_loss: 0.3097 - fy_loss: 0.3037 - u0_loss: 0.0922 - v0_loss: 0.1030 - baseline_loss: 0.7826 - disparity_loss: 1.2469 - x_loss: 0.7891 - y_loss: 0.0315 - z_loss: 0.0212 - pitch_loss: 0.2537 - xWorld_loss: 178.3980 - yWorld_loss: 0.0313 - zWorld_loss: 199.5147 - val_loss: 253.1517 - val_fx_loss: 1.2992 - val_fy_loss: 1.2559 - val_u0_loss: 1.0478 - val_v0_loss: 0.9336 - val_baseline_loss: 2.3240 - val_disparity_loss: 1.3501 - val_x_loss: 2.1281 - val_y_loss: 0.0619 - val_z_loss: 0.0237 - val_pitch_loss: 0.5158 - val_xWorld_loss: 88.5843 - val_yWorld_loss: 0.0475 - val_zWorld_loss: 153.5453\n",
      "Epoch 34/200\n",
      "86111/86111 [==============================] - ETA: 0s - loss: 380.2470 - fx_loss: 0.2819 - fy_loss: 0.2688 - u0_loss: 0.0932 - v0_loss: 0.0988 - baseline_loss: 0.7308 - disparity_loss: 1.2375 - x_loss: 0.7363 - y_loss: 0.0298 - z_loss: 0.0210 - pitch_loss: 0.2421 - xWorld_loss: 177.7817 - yWorld_loss: 0.0297 - zWorld_loss: 198.6956Restoring model weights from the end of the best epoch.\n",
      "86111/86111 [==============================] - 794s 9ms/sample - loss: 380.2470 - fx_loss: 0.2819 - fy_loss: 0.2688 - u0_loss: 0.0932 - v0_loss: 0.0988 - baseline_loss: 0.7308 - disparity_loss: 1.2375 - x_loss: 0.7363 - y_loss: 0.0298 - z_loss: 0.0210 - pitch_loss: 0.2421 - xWorld_loss: 177.7817 - yWorld_loss: 0.0297 - zWorld_loss: 198.6956 - val_loss: 252.3062 - val_fx_loss: 0.9338 - val_fy_loss: 0.8685 - val_u0_loss: 0.8486 - val_v0_loss: 0.8427 - val_baseline_loss: 1.9246 - val_disparity_loss: 1.2276 - val_x_loss: 1.9127 - val_y_loss: 0.0503 - val_z_loss: 0.0238 - val_pitch_loss: 0.6023 - val_xWorld_loss: 89.7284 - val_yWorld_loss: 0.0445 - val_zWorld_loss: 153.2721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00034: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "model_name = 'model_multi_class/'\n",
    "SAVE = \"new_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "# Save\n",
    "output_folder = SAVE + model_name\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "output_log = output_folder + \"Log/\"\n",
    "if not os.path.exists(output_log):\n",
    "    os.makedirs(output_log)\n",
    "\n",
    "output_weight = output_folder + \"Best/\"\n",
    "if not os.path.exists(output_weight):\n",
    "    os.makedirs(output_weight)\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=output_log)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=output_weight + \"weights_{epoch:02d}_{val_loss:.2f}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[Left_images[:int(len(Left_images)*0.7)], Right_images[:int(len(Left_images)*0.7)]],\n",
    "    y=[Fx[:int(len(Left_images)*0.7)], Fy[:int(len(Left_images)*0.7)], U0[:int(len(Left_images)*0.7)], V0[:int(len(Left_images)*0.7)], Baseline[:int(len(Left_images)*0.7)], Disparity[:int(len(Left_images)*0.7)], Tx[:int(len(Left_images)*0.7)], Ty[:int(len(Left_images)*0.7)], Tz[:int(len(Left_images)*0.7)], Pitch[:int(len(Left_images)*0.7)], X[:int(len(Left_images)*0.7)], Y[:int(len(Left_images)*0.7)], Z[:int(len(Left_images)*0.7)]],\n",
    "    batch_size=16,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    validation_data=([Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]], [Fx[int(len(Left_images)*0.7):], Fy[int(len(Left_images)*0.7):], U0[int(len(Left_images)*0.7):], V0[int(len(Left_images)*0.7):], Baseline[int(len(Left_images)*0.7):], Disparity[int(len(Left_images)*0.7):], Tx[int(len(Left_images)*0.7):], Ty[int(len(Left_images)*0.7):], Tz[int(len(Left_images)*0.7):], Pitch[int(len(Left_images)*0.7):], X[int(len(Left_images)*0.7):], Y[int(len(Left_images)*0.7):], Z[int(len(Left_images)*0.7):]]),\n",
    "    callbacks=[tensorboard, checkpointer, early_stopping, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2070: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "model.load_weights('./new_logs/20221212-115736/model_multi_class/Best/weights_29_244.08.h5')\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "\n",
    "output = model.predict(\n",
    "    x=[Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]],\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23796, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% Correct')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "th_0 = 0\n",
    "th_1 = 0\n",
    "th_2 = 0\n",
    "th_3 = 0\n",
    "th_4 = 0\n",
    "th_5 = 0\n",
    "\n",
    "percent_correct = []\n",
    "\n",
    "k = 86111\n",
    "\n",
    "for i  in range(np.shape(output)[1]):\n",
    "    \n",
    "    predicted_fov = 2*np.arctan(112/(2*output[0][i][0]))\n",
    "    actual_fov = 2*np.arctan(112/(2*Fx[k]))\n",
    "    \n",
    "    if abs(predicted_fov - actual_fov) <= 0:\n",
    "        \n",
    "        th_0 += 1 \n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 1:\n",
    "        \n",
    "        th_1 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 2:\n",
    "        \n",
    "        th_2 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 3:\n",
    "        \n",
    "        th_3 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 4:\n",
    "        \n",
    "        th_4 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 5:\n",
    "        \n",
    "        th_5 += 1\n",
    "        \n",
    "    k += 1\n",
    "\n",
    "percent_correct.append(th_0/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_1/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_2/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_3/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_4/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_5/np.shape(output)[1]*100)\n",
    "\n",
    "plt.plot([0,1,2,3,4,5],percent_correct)\n",
    "plt.xlabel(\"FOV Error Threshold (degrees)\")\n",
    "plt.ylabel(\"% Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 36905, 36906, 36906, 36906, 36906)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0, th_1, th_2, th_3, th_4, th_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.999972904134829, 1.0, 1.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0/np.shape(output)[1], th_1/np.shape(output)[1], th_2/np.shape(output)[1], th_3/np.shape(output)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 2.56447778162921, 'fy': 2.5077656248367135, 'u0': 0.9909523976592581, 'v0': 0.43225231225159133, 'baseline': 0.18138129833085653, 'disparity': 0.07412419337481978, 'x': 0.2028581381325041, 'y': 0.2504432190714974, 'z': 0.20325201591998113, 'pitch': 2.0349170707578237, 'xworld': 2.8327124718997885, 'yworld': 1.2974903015155659, 'zworld': 3.6014432195759385}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 86111\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math \n",
    "\n",
    "def normalize(x):\n",
    "    \n",
    "    return (math.atan(x) + 3.14/2) / 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.704324636002951, 'fy': 0.7011265011993358, 'u0': 0.741233327244525, 'v0': 0.6225792847523145, 'baseline': 0.5424079886365989, 'disparity': 0.5220462137263711, 'x': 0.5496942729323498, 'y': 0.5549662015883875, 'z': 0.5506254601468478, 'pitch': 0.7614908957207112, 'xworld': 0.679104856887752, 'yworld': 0.6440751307842089, 'zworld': 0.7611606317563646}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fx - actual_fx))\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fy - actual_fy))\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_u0 - actual_u0))\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_v0 - actual_v0))\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_baseline - actual_baseline))\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_disparity - actual_disparity))\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tx - actual_tx))\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_ty - actual_ty))\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tz - actual_tz))\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_pitch - actual_pitch))\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_x - actual_x))\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_y - actual_y))\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_z - actual_z))\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23796, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79320"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123.13403306510597"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(error.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.0007976620305556979, 'fy': 0.0012225649635422629, 'u0': 0.0004547655283298268, 'v0': 0.00018118127261668288, 'baseline': 0.007994659936512135, 'disparity': 0.0005506914696565865, 'x': 0.008941413789216495, 'y': 0.007562384366596746, 'z': 0.0118155685456004, 'pitch': 0.0004519001652961751, 'xworld': 0.007330101547401548, 'yworld': 0.0007070058987466843, 'zworld': 0.010618019049435198}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "min_fx = 1.9073486e-06\n",
    "max_fx = 3214.9907\n",
    "\n",
    "min_fy = 2.9563904e-05\n",
    "max_fy = 2051.209\n",
    "\n",
    "min_u0 = 1.9073486e-05\n",
    "max_u0 = 2178.9983\n",
    "\n",
    "min_v0 = 3.8146973e-06\n",
    "max_v0 = 2385.7239\n",
    "\n",
    "min_baseline = 4.7683716e-06\n",
    "max_baseline = 22.68721567997021\n",
    "\n",
    "min_disparity = 9.536743e-07\n",
    "max_disparity = 134.60031\n",
    "\n",
    "min_tx = 2.384185791015625e-06\n",
    "max_tx = 22.68721567997021\n",
    "\n",
    "min_ty = 2.3841858e-07\n",
    "max_ty = 33.11693576309983\n",
    "\n",
    "min_tz = 2.3841858e-06\n",
    "max_tz = 17.20185265614626\n",
    "\n",
    "min_pitch = 4.57763671875e-05\n",
    "max_pitch = 4502.9224\n",
    "\n",
    "min_xw = 5.219264654243716e-06\n",
    "max_xw = 386.4486\n",
    "\n",
    "min_yw = 3.8146973e-06\n",
    "max_yw = 1835.1849\n",
    "\n",
    "min_zw = 0.00011349\n",
    "max_zw = 339.17166\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fx - actual_fx) - min_fx)/(max_fx - min_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fy - actual_fy) - min_fy)/(max_fy - min_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_u0 - actual_u0) - min_u0)/(max_u0 - min_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_v0 - actual_v0) - min_v0)/(max_v0 - min_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_baseline - actual_baseline) - min_baseline)/(max_baseline - min_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_disparity - actual_disparity) - min_disparity)/(max_disparity - min_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tx - actual_tx) - min_tx)/(max_tx - min_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_ty - actual_ty) - min_ty)/(max_ty - min_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tz - actual_tz) - min_tz)/(max_tz - min_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_pitch - actual_pitch) - min_pitch)/(max_pitch - min_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_x - actual_x) - min_xw)/(max_xw - min_xw)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_y - actual_y) - min_yw)/(max_yw - min_yw)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_z - actual_z) - min_zw)/(max_zw - min_zw)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.007649257519189005, 'fy': 0.009897692040581059, 'u0': 0.003979347379927954, 'v0': 0.0037760760361821187, 'baseline': -0.011321183643390402, 'disparity': -0.11792258941342948, 'x': -0.014606987002143947, 'y': 0.08134225513810385, 'z': -0.05191752080609494, 'pitch': -0.02270443842944377, 'xworld': -0.9689973522151569, 'yworld': 0.07193816136114588, 'zworld': 3.36405837901377}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "mean_fx = 59.32098482132037\n",
    "\n",
    "mean_fy = 59.32098482132037\n",
    "\n",
    "mean_u0 = 56.0\n",
    "\n",
    "mean_v0 = 56.0\n",
    "\n",
    "mean_baseline = -84.00701782907929\n",
    "\n",
    "mean_disparity = -10.972388226877689\n",
    "\n",
    "mean_tx = -84.00701782907929\n",
    "\n",
    "mean_ty = 0.4372459762640221\n",
    "\n",
    "mean_tz = -0.5766162683574485\n",
    "\n",
    "mean_pitch = -12.380371755270145\n",
    "\n",
    "mean_xw = -91.94288567681566\n",
    "\n",
    "mean_yw = 0.4372459762640221\n",
    "\n",
    "mean_zw = 44.48843272766856\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 86111\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx) / mean_fx\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy) / mean_fy\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0) / mean_u0\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0) / mean_v0\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline) / mean_baseline\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity) / mean_disparity\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx) / mean_tx\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty) / mean_ty\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz) / mean_tz\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch) / mean_pitch\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x) / mean_xw\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y) / mean_yw\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z) / mean_zw\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
