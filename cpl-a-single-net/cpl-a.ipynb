{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(1)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import json\n",
    "from tensorflow.keras.losses import mse\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import sys\n",
    "ros_path = '/opt/ros/kinetic/lib/python2.7/dist-packages'\n",
    "\n",
    "if ros_path in sys.path:\n",
    "\n",
    "    sys.path.remove(ros_path)\n",
    "\n",
    "import cv2\n",
    "\n",
    "sys.path.append('/opt/ros/kinetic/lib/python2.7/dist-packages')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Dense, Input, concatenate, Conv2D, MaxPooling2D, Flatten, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(tensor):\n",
    "    return tensor[0] + tensor[1]\n",
    "\n",
    "def mul_layer(tensor):\n",
    "    return tensor[0] * tensor[1]\n",
    "\n",
    "def div_layer(tensor):\n",
    "    return tensor[0] / tensor[1]\n",
    "\n",
    "def sub_layer(tensor):\n",
    "    return tensor[0] - tensor[1]\n",
    "\n",
    "def neg_layer(tensor):\n",
    "    return -tensor\n",
    "\n",
    "def cos_layer(tensor):\n",
    "    return tf.math.cos(tensor)\n",
    "\n",
    "def sin_layer(tensor):\n",
    "    return tf.math.sin(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/imagenet_utils.py:331: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 6 input channels.\n",
      "  warnings.warn('This model usually expects 1 or 3 input channels. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "left_image (InputLayer)         [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "right_image (InputLayer)        [(None, 112, 112, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 112, 112, 6)  0           left_image[0][0]                 \n",
      "                                                                 right_image[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 55, 55, 32)   1728        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 55, 55, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 55, 55, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 53, 53, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 53, 53, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 53, 53, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 53, 53, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 53, 53, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 53, 53, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 26, 26, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 26, 26, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 26, 26, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 26, 26, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 24, 24, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 24, 24, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 24, 24, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 11, 11, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 11, 11, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 11, 11, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 11, 11, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 11, 11, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 11, 11, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 11, 11, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 11, 11, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 11, 11, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 11, 11, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 11, 11, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 11, 11, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 11, 11, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 11, 11, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 11, 11, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 11, 11, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 11, 11, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 11, 11, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 11, 11, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 11, 11, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 11, 11, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 11, 11, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 11, 11, 64)   16384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 11, 11, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 11, 11, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 11, 11, 48)   12288       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 11, 11, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 11, 11, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 11, 11, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 11, 11, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 11, 11, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 11, 11, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 11, 11, 64)   16384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 11, 11, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 11, 11, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 11, 11, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 11, 11, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 11, 11, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 11, 11, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 11, 11, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 11, 11, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 11, 11, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 11, 11, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 11, 11, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 11, 11, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 11, 11, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 11, 11, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 11, 11, 48)   13824       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 11, 11, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 11, 11, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 11, 11, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 11, 11, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 11, 11, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 11, 11, 288)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 11, 11, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 11, 11, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 11, 11, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 11, 11, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 11, 11, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 11, 11, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 11, 11, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 11, 11, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 11, 11, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 11, 11, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 11, 11, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 11, 11, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 11, 11, 64)   18432       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 11, 11, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 11, 11, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 11, 11, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 11, 11, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 11, 11, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 5, 5, 384)    995328      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 5, 5, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 5, 5, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 5, 5, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5, 5, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 5, 5, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 288)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5, 5, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 5, 5, 128)    98304       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 5, 5, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5, 5, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 5, 5, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 5, 5, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 5, 5, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 5, 5, 128)    98304       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 5, 5, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 5, 5, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 5, 5, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 5, 5, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 5, 5, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 5, 5, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 5, 5, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 5, 5, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 5, 5, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 5, 5, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5, 5, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 5, 5, 768)    0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 5, 5, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 5, 5, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 5, 5, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 5, 5, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 5, 5, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 5, 5, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 5, 5, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 5, 5, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 5, 5, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 5, 5, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 5, 5, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 5, 5, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 5, 5, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 5, 5, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 5, 5, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 5, 5, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 5, 5, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 5, 5, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 5, 5, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5, 5, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5, 5, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 5, 5, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 5, 5, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 5, 5, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 5, 5, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 5, 5, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 5, 5, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 5, 5, 768)    0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 5, 5, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 5, 5, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 5, 5, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 5, 5, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 5, 5, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 5, 5, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 5, 5, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 5, 5, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 5, 5, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 5, 5, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 5, 5, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 5, 5, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 5, 5, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 5, 5, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 5, 5, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 5, 5, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 5, 5, 160)    122880      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 5, 5, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 5, 5, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 5, 5, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 5, 5, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 5, 5, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 5, 5, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 5, 5, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 5, 5, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 5, 5, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5, 5, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 5, 5, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 5, 5, 768)    0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 5, 5, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 5, 5, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 5, 5, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 5, 5, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 5, 5, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 5, 5, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 5, 5, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 5, 5, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 5, 5, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5, 5, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 5, 5, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 5, 5, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 5, 5, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 5, 5, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 5, 5, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 5, 5, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 5, 5, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 5, 5, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 5, 5, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 5, 5, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 5, 5, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 5, 5, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 5, 5, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 5, 5, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 5, 5, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 5, 5, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 5, 5, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 5, 5, 768)    0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 5, 5, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 5, 5, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 5, 5, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 5, 5, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 5, 5, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 5, 5, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 5, 5, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 5, 5, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 5, 5, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 5, 5, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 5, 5, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 5, 5, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 5, 5, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 5, 5, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 5, 5, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 5, 5, 192)    147456      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 5, 5, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 5, 5, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 5, 5, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 5, 5, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 5, 5, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)    0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 2, 2, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 2, 2, 448)    573440      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 2, 2, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 384)    491520      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 2, 2, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 2, 2, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 1280)   0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 320)    409600      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2, 2, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 2, 2, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 2, 2, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 2, 2, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 2, 2, 2048)   0           activation_76[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 448)    917504      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 2, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 2, 2, 384)    786432      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2, 2, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 2, 2, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 2, 2, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 2, 2, 2048)   0           concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 2, 2, 320)    655360      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 2, 2, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2, 2, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 2, 2, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2, 2, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2, 2, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 2, 2, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 2, 2, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2, 2, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 2, 2, 2048)   0           activation_85[0][0]              \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "phi-flattened (Flatten)         (None, 8192)         0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 84)           10164       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 84)           10164       dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "fx (Dense)                      (None, 1)            85          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "baseline (Dense)                (None, 1)            85          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 84)           10164       dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 84)           10164       dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 84)           10164       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "disparity (Dense)               (None, 1)            85          dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 1)            0           fx[0][0]                         \n",
      "                                                                 baseline[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 84)           10164       dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fy (Dense)                      (None, 1)            85          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "v0 (Dense)                      (None, 1)            85          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 84)           10164       dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           lambda[0][0]                     \n",
      "                                                                 disparity[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "v (Dense)                       (None, 1)            85          dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 84)           10164       dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pitch (Dense)                   (None, 1)            85          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "                                                                 fy[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           v0[0][0]                         \n",
      "                                                                 v[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 84)           10164       dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "u0 (Dense)                      (None, 1)            85          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1)            0           lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "                                                                 fx[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "u (Dense)                       (None, 1)            85          dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1)            0           pitch[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 84)           10164       dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 84)           10164       dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 84)           10164       dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           lambda_1[0][0]                   \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1)            0           lambda_8[0][0]                   \n",
      "                                                                 lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1)            0           u[0][0]                          \n",
      "                                                                 u0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1)            0           lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1)            0           lambda_8[0][0]                   \n",
      "                                                                 lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 120)          983160      phi-flattened[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "x (Dense)                       (None, 1)            85          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "y (Dense)                       (None, 1)            85          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z (Dense)                       (None, 1)            85          dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1)            0           lambda_10[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 84)           10164       dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           lambda_5[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 84)           10164       dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1)            0           lambda_16[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 84)           10164       dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           lambda_14[0][0]                  \n",
      "                                                                 x[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "w_xworld (Dense)                (None, 1)            85          dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           lambda_4[0][0]                   \n",
      "                                                                 y[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "w_yworld (Dense)                (None, 1)            85          dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1)            0           lambda_21[0][0]                  \n",
      "                                                                 z[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "w_zworld (Dense)                (None, 1)            85          dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "xWorld (Lambda)                 (None, 1)            0           lambda_15[0][0]                  \n",
      "                                                                 w_xworld[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "yWorld (Lambda)                 (None, 1)            0           lambda_9[0][0]                   \n",
      "                                                                 w_yworld[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zWorld (Lambda)                 (None, 1)            0           lambda_22[0][0]                  \n",
      "                                                                 w_zworld[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 36,704,783\n",
      "Trainable params: 36,670,351\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# feature extraction from left image\n",
    "left_img = Input(shape = (112,112,3), name=\"left_image\")\n",
    "\n",
    "# feature extraction from right image\n",
    "right_img = Input(shape = (112,112,3), name=\"right_image\")\n",
    "\n",
    "concat = concatenate([left_img, right_img])\n",
    "\n",
    "phi_model = InceptionV3(weights=None, include_top=False, input_tensor=concat, input_shape=(112,112,6))\n",
    "phi_features = phi_model.output\n",
    "flat = Flatten(name='phi-flattened')(phi_features)\n",
    "\n",
    "# fx\n",
    "dense_1 = Dense(120, activation = 'relu')(flat)\n",
    "dense_2 = Dense(84, activation = 'relu')(dense_1)\n",
    "pred_fx = Dense(1, name='fx')(dense_2)\n",
    "\n",
    "# fy\n",
    "dense_3 = Dense(120, activation = 'relu')(flat)\n",
    "dense_4 = Dense(84, activation = 'relu')(dense_3)\n",
    "pred_fy = Dense(1, name='fy')(dense_4)\n",
    "\n",
    "# u0\n",
    "dense_5 = Dense(120, activation = 'relu')(flat)\n",
    "dense_6 = Dense(84, activation = 'relu')(dense_5)\n",
    "pred_u0 = Dense(1, name='u0')(dense_6)\n",
    "\n",
    "# v0\n",
    "dense_7 = Dense(120, activation = 'relu')(flat)\n",
    "dense_8 = Dense(84, activation = 'relu')(dense_7)\n",
    "pred_v0 = Dense(1, name='v0')(dense_8)\n",
    "\n",
    "# baseline\n",
    "dense_9 = Dense(120, activation = 'relu')(flat)\n",
    "dense_10 = Dense(84, activation = 'relu')(dense_9)\n",
    "pred_baseline = Dense(1, name='baseline')(dense_10)\n",
    "\n",
    "# tx\n",
    "dense_11 = Dense(120, activation = 'relu')(flat)\n",
    "dense_12 = Dense(84, activation = 'relu')(dense_11)\n",
    "pred_x = Dense(1, name='x')(dense_12)\n",
    "\n",
    "# ty\n",
    "dense_13 = Dense(120, activation = 'relu')(flat)\n",
    "dense_14 = Dense(84, activation = 'relu')(dense_13)\n",
    "pred_y = Dense(1, name='y')(dense_14)\n",
    "\n",
    "# tz\n",
    "dense_15 = Dense(120, activation = 'relu')(flat)\n",
    "dense_16 = Dense(84, activation = 'relu')(dense_15)\n",
    "pred_z = Dense(1, name='z')(dense_16)\n",
    "\n",
    "# pitch\n",
    "dense_17 = Dense(120, activation = 'relu')(flat)\n",
    "dense_18 = Dense(84, activation = 'relu')(dense_17)\n",
    "pred_pitch = Dense(1, name='pitch')(dense_18)\n",
    "\n",
    "# u\n",
    "dense_19 = Dense(120, activation = 'relu')(flat)\n",
    "dense_20 = Dense(84, activation = 'relu')(dense_19)\n",
    "pred_u = Dense(1, name='u')(dense_20)\n",
    "\n",
    "# v\n",
    "dense_21 = Dense(120, activation = 'relu')(flat)\n",
    "dense_22 = Dense(84, activation = 'relu')(dense_21)\n",
    "pred_v = Dense(1, name='v')(dense_22)\n",
    "\n",
    "# disparity\n",
    "dense_23 = Dense(120, activation = 'relu')(flat)\n",
    "dense_24 = Dense(84, activation = 'relu')(dense_23)\n",
    "pred_disparity = Dense(1, name='disparity')(dense_24)\n",
    "\n",
    "# w_xcam\n",
    "#dense_25 = Dense(120, activation = 'relu')(flat)\n",
    "#dense_26 = Dense(84, activation = 'relu')(dense_25)\n",
    "#w_xcam = Dense(1, name='w_xcam', activation = 'sigmoid')(dense_26)\n",
    "\n",
    "# w_ycam\n",
    "#dense_27 = Dense(120, activation = 'relu')(flat)\n",
    "#dense_28 = Dense(84, activation = 'relu')(dense_27)\n",
    "#w_ycam = Dense(1, name='w_ycam', activation = 'sigmoid')(dense_28)\n",
    "\n",
    "# w_zcam\n",
    "#dense_29 = Dense(120, activation = 'relu')(flat)\n",
    "#dense_30 = Dense(84, activation = 'relu')(dense_29)\n",
    "#w_zcam = Dense(1, name='w_zcam', activation = 'sigmoid')(dense_30)\n",
    "\n",
    "# w_xworld\n",
    "dense_31 = Dense(120, activation = 'relu')(flat)\n",
    "dense_32 = Dense(84, activation = 'relu')(dense_31)\n",
    "w_xworld = Dense(1, name='w_xworld', activation = 'sigmoid')(dense_32)\n",
    "\n",
    "# w_yworld\n",
    "dense_33 = Dense(120, activation = 'relu')(flat)\n",
    "dense_34 = Dense(84, activation = 'relu')(dense_33)\n",
    "w_yworld = Dense(1, name='w_yworld', activation = 'sigmoid')(dense_34)\n",
    "\n",
    "# w_zworld\n",
    "dense_35 = Dense(120, activation = 'relu')(flat)\n",
    "dense_36 = Dense(84, activation = 'relu')(dense_35)\n",
    "w_zworld = Dense(1, name='w_zworld', activation = 'sigmoid')(dense_36)\n",
    "\n",
    "\n",
    "# xCam = (self.intrinsic.fx * self.extrinsic.baseline) / disparity\n",
    "mul_1 = Lambda(mul_layer)([pred_fx, pred_baseline])\n",
    "xCam = Lambda(div_layer)([mul_1, pred_disparity])\n",
    "#xCam = Lambda(mul_layer, name='xCam')([xCam, w_xcam])\n",
    "\n",
    "# yCam = - (xCam / self.intrinsic.fx) * (u - self.intrinsic.u0)\n",
    "div_1 = Lambda(div_layer)([xCam, pred_fx])\n",
    "sub_1 = Lambda(sub_layer)([pred_u, pred_u0])\n",
    "yCam = Lambda(mul_layer)([Lambda(neg_layer)(div_1), sub_1])\n",
    "#yCam = Lambda(mul_layer, name='yCam')([yCam, w_ycam])\n",
    "\n",
    "# zCam = (xCam / self.intrinsic.fy) * (self.intrinsic.v0 - v)\n",
    "div_2 = Lambda(div_layer)([xCam, pred_fy])\n",
    "sub_2 = Lambda(sub_layer)([pred_v0, pred_v])\n",
    "zCam = Lambda(mul_layer)([div_2, sub_2])\n",
    "#zCam = Lambda(mul_layer, name='zCam')([zCam, w_zcam])\n",
    "\n",
    "# Y = yCam + self.extrinsic.y\n",
    "pred_yWorld = Lambda(add_layer)([yCam, pred_y])\n",
    "pred_yWorld = Lambda(mul_layer, name='yWorld')([pred_yWorld, w_yworld])\n",
    "\n",
    "# X = xCam * math.cos(self.extrinsic.pitch) + zCam * math.sin(self.extrinsic.pitch) + self.extrinsic.x\n",
    "mul_2 = Lambda(mul_layer)([xCam, Lambda(cos_layer)(pred_pitch)])\n",
    "mul_3 = Lambda(mul_layer)([zCam, Lambda(sin_layer)(pred_pitch)])\n",
    "add_1 = Lambda(add_layer)([mul_2, mul_3])\n",
    "pred_xWorld = Lambda(add_layer)([add_1, pred_x])\n",
    "pred_xWorld = Lambda(mul_layer, name='xWorld')([pred_xWorld, w_xworld])\n",
    "\n",
    "# Z = - xCam * math.sin(self.extrinsic.pitch) + zCam * math.cos(self.extrinsic.pitch) + self.extrinsic.z\n",
    "mul_4 = Lambda(mul_layer)([Lambda(neg_layer)(xCam), Lambda(sin_layer)(pred_pitch)])\n",
    "mul_5 = Lambda(mul_layer)([zCam, Lambda(cos_layer)(pred_pitch)])\n",
    "add_2 = Lambda(add_layer)([mul_4, mul_5])\n",
    "pred_zWorld = Lambda(add_layer)([add_2, pred_z])\n",
    "pred_zWorld = Lambda(mul_layer, name='zWorld')([pred_zWorld, w_zworld])\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[left_img, right_img], outputs=[pred_fx, pred_fy, pred_u0, pred_v0, pred_baseline, pred_disparity, pred_x, pred_y, pred_z, pred_pitch, pred_xWorld,pred_yWorld,pred_zWorld])\n",
    "\n",
    "# set output types\n",
    "target1 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target2 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target3 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target4 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target5 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target6 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target7 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target8 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target9 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target10 = tf.placeholder(dtype='float32', shape=(1,1)) \n",
    "target11 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target12 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "target13 = tf.placeholder(dtype='float32', shape=(1,1))\n",
    "\n",
    "# get model summary\n",
    "model.summary()\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "# compile model\n",
    "model.compile(loss=\"mae\", target_tensors=[target1, target2, target3, target4, target5, target6, target7, target8, target9, target10, target11, target12, target13],optimizer=optimizers.Adam(lr=learning_rate))\n",
    "#plot_model(model, to_file='model.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/\"\n",
    "\n",
    "Left_images = np.load(data_path+\"li.npy\")\n",
    "Right_images = np.load(data_path+\"ri.npy\")\n",
    "Fx = np.load(data_path+\"fx.npy\")\n",
    "Fy = np.load(data_path+\"fy.npy\") \n",
    "U0 = np.load(data_path+\"u0.npy\") \n",
    "V0 = np.load(data_path+\"v0.npy\") \n",
    "Baseline = np.load(data_path+\"b.npy\")\n",
    "Disparity = np.load(data_path+\"d.npy\") \n",
    "Tx = np.load(data_path+\"tx.npy\") \n",
    "Ty = np.load(data_path+\"ty.npy\") \n",
    "Tz = np.load(data_path+\"tz.npy\") \n",
    "Pitch = np.load(data_path+\"p.npy\")\n",
    "X = np.load(data_path+\"x.npy\")\n",
    "Y = np.load(data_path+\"y.npy\") \n",
    "Z = np.load(data_path+\"z.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset:  (123017,)\n"
     ]
    }
   ],
   "source": [
    "print (\"dataset: \",np.shape(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset:  86111.9 Test Dataset:  36905.1\n"
     ]
    }
   ],
   "source": [
    "print (\"Training Dataset: \",len(Left_images)*0.7, \"Test Dataset: \", len(Left_images)*0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 86111 samples, validate on 36906 samples\n",
      "Epoch 1/200\n",
      "   32/86111 [..............................] - ETA: 1:33:21 - loss: 1311.2400 - fx_loss: 65.1879 - fy_loss: 66.7514 - u0_loss: 51.1899 - v0_loss: 50.8490 - baseline_loss: 84.2235 - disparity_loss: 8.2132 - x_loss: 83.4730 - y_loss: 6.2724 - z_loss: 1.0494 - pitch_loss: 15.6749 - xWorld_loss: 353.2623 - yWorld_loss: 4.1329 - zWorld_loss: 520.9602WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.3159s vs `on_train_batch_begin` time: 0.8370s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.3159s vs `on_train_batch_end` time: 0.9280s). Check your callbacks.\n",
      "86111/86111 [==============================] - ETA: 0s - loss: 1016.2901 - fx_loss: 18.6157 - fy_loss: 20.4880 - u0_loss: 1.8641 - v0_loss: 2.6867 - baseline_loss: 40.2858 - disparity_loss: 3.1825 - x_loss: 40.0164 - y_loss: 1.9616 - z_loss: 0.6809 - pitch_loss: 18.7202 - xWorld_loss: 386.7445 - yWorld_loss: 2.8720 - zWorld_loss: 478.1660WARNING:tensorflow:From /home/talha/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "86111/86111 [==============================] - 901s 10ms/sample - loss: 1016.2901 - fx_loss: 18.6157 - fy_loss: 20.4880 - u0_loss: 1.8641 - v0_loss: 2.6867 - baseline_loss: 40.2858 - disparity_loss: 3.1825 - x_loss: 40.0164 - y_loss: 1.9616 - z_loss: 0.6809 - pitch_loss: 18.7202 - xWorld_loss: 386.7445 - yWorld_loss: 2.8720 - zWorld_loss: 478.1660 - val_loss: 820.0528 - val_fx_loss: 7.5794 - val_fy_loss: 7.6144 - val_u0_loss: 1.1307 - val_v0_loss: 1.4474 - val_baseline_loss: 30.1950 - val_disparity_loss: 2.6865 - val_x_loss: 30.4975 - val_y_loss: 0.7485 - val_z_loss: 0.6689 - val_pitch_loss: 12.6611 - val_xWorld_loss: 294.8943 - val_yWorld_loss: 2.8593 - val_zWorld_loss: 427.0979\n",
      "Epoch 2/200\n",
      "86111/86111 [==============================] - 892s 10ms/sample - loss: 950.5970 - fx_loss: 7.2713 - fy_loss: 7.1952 - u0_loss: 0.8169 - v0_loss: 0.9357 - baseline_loss: 26.3136 - disparity_loss: 2.3915 - x_loss: 26.3002 - y_loss: 0.8538 - z_loss: 0.6654 - pitch_loss: 10.9558 - xWorld_loss: 386.7447 - yWorld_loss: 2.8551 - zWorld_loss: 477.2933 - val_loss: 839.4978 - val_fx_loss: 11.2787 - val_fy_loss: 10.9580 - val_u0_loss: 5.0403 - val_v0_loss: 5.0417 - val_baseline_loss: 33.6000 - val_disparity_loss: 3.0141 - val_x_loss: 32.2498 - val_y_loss: 0.7905 - val_z_loss: 0.6689 - val_pitch_loss: 12.0296 - val_xWorld_loss: 294.8691 - val_yWorld_loss: 2.8594 - val_zWorld_loss: 427.0547\n",
      "Epoch 3/200\n",
      "86111/86111 [==============================] - 881s 10ms/sample - loss: 936.0809 - fx_loss: 5.9211 - fy_loss: 5.9433 - u0_loss: 0.5147 - v0_loss: 0.5747 - baseline_loss: 21.9203 - disparity_loss: 2.2231 - x_loss: 21.8719 - y_loss: 0.6255 - z_loss: 0.6654 - pitch_loss: 8.9230 - xWorld_loss: 386.7456 - yWorld_loss: 2.8551 - zWorld_loss: 477.2926 - val_loss: 5509.6216 - val_fx_loss: 891.5959 - val_fy_loss: 889.5588 - val_u0_loss: 724.7434 - val_v0_loss: 743.8591 - val_baseline_loss: 843.4310 - val_disparity_loss: 76.9176 - val_x_loss: 603.8577 - val_y_loss: 1.2977 - val_z_loss: 0.6679 - val_pitch_loss: 8.1706 - val_xWorld_loss: 294.9043 - val_yWorld_loss: 2.8594 - val_zWorld_loss: 427.1671\n",
      "Epoch 4/200\n",
      "86111/86111 [==============================] - 848s 10ms/sample - loss: 917.8510 - fx_loss: 4.5386 - fy_loss: 4.5532 - u0_loss: 0.4402 - v0_loss: 0.4833 - baseline_loss: 15.6128 - disparity_loss: 2.0550 - x_loss: 15.5705 - y_loss: 0.5564 - z_loss: 0.6653 - pitch_loss: 6.4775 - xWorld_loss: 386.7451 - yWorld_loss: 2.8551 - zWorld_loss: 477.2960 - val_loss: 842.1952 - val_fx_loss: 17.6097 - val_fy_loss: 16.4249 - val_u0_loss: 12.6665 - val_v0_loss: 13.8598 - val_baseline_loss: 26.1200 - val_disparity_loss: 4.0944 - val_x_loss: 17.9261 - val_y_loss: 0.4160 - val_z_loss: 0.6683 - val_pitch_loss: 7.5687 - val_xWorld_loss: 294.8572 - val_yWorld_loss: 2.8593 - val_zWorld_loss: 427.0528\n",
      "Epoch 5/200\n",
      "86111/86111 [==============================] - 824s 10ms/sample - loss: 902.1532 - fx_loss: 3.2137 - fy_loss: 3.2269 - u0_loss: 0.3494 - v0_loss: 0.3898 - baseline_loss: 10.2999 - disparity_loss: 1.9235 - x_loss: 10.2423 - y_loss: 0.3986 - z_loss: 0.6653 - pitch_loss: 4.5458 - xWorld_loss: 386.7459 - yWorld_loss: 2.8551 - zWorld_loss: 477.2983 - val_loss: 1070.3751 - val_fx_loss: 45.1708 - val_fy_loss: 47.4360 - val_u0_loss: 44.1209 - val_v0_loss: 48.9940 - val_baseline_loss: 77.6189 - val_disparity_loss: 8.7192 - val_x_loss: 63.3890 - val_y_loss: 0.8909 - val_z_loss: 0.6693 - val_pitch_loss: 8.4887 - val_xWorld_loss: 294.8644 - val_yWorld_loss: 2.8593 - val_zWorld_loss: 427.0654\n",
      "Epoch 6/200\n",
      "86111/86111 [==============================] - 839s 10ms/sample - loss: 942.9460 - fx_loss: 7.6992 - fy_loss: 7.6903 - u0_loss: 0.3751 - v0_loss: 0.4144 - baseline_loss: 22.6430 - disparity_loss: 2.2310 - x_loss: 22.5067 - y_loss: 0.7868 - z_loss: 0.6653 - pitch_loss: 10.9981 - xWorld_loss: 386.7440 - yWorld_loss: 2.8551 - zWorld_loss: 477.3320 - val_loss: 806.1324 - val_fx_loss: 8.1806 - val_fy_loss: 9.1842 - val_u0_loss: 5.6481 - val_v0_loss: 6.7594 - val_baseline_loss: 24.0456 - val_disparity_loss: 2.8831 - val_x_loss: 17.5348 - val_y_loss: 0.4171 - val_z_loss: 0.6684 - val_pitch_loss: 5.9798 - val_xWorld_loss: 294.8715 - val_yWorld_loss: 2.8593 - val_zWorld_loss: 427.0517\n",
      "Epoch 7/200\n",
      "86111/86111 [==============================] - 830s 10ms/sample - loss: 909.0149 - fx_loss: 4.1089 - fy_loss: 4.1132 - u0_loss: 0.3255 - v0_loss: 0.3500 - baseline_loss: 12.3901 - disparity_loss: 1.9066 - x_loss: 12.3816 - y_loss: 0.4059 - z_loss: 0.6653 - pitch_loss: 5.4701 - xWorld_loss: 386.7444 - yWorld_loss: 2.8551 - zWorld_loss: 477.2921 - val_loss: 797.6806 - val_fx_loss: 9.5681 - val_fy_loss: 10.2119 - val_u0_loss: 7.6401 - val_v0_loss: 9.4420 - val_baseline_loss: 16.1033 - val_disparity_loss: 3.0466 - val_x_loss: 11.3836 - val_y_loss: 0.4009 - val_z_loss: 0.6682 - val_pitch_loss: 4.3812 - val_xWorld_loss: 294.8654 - val_yWorld_loss: 2.8592 - val_zWorld_loss: 427.0498\n",
      "Epoch 8/200\n",
      "86111/86111 [==============================] - 808s 9ms/sample - loss: 897.5554 - fx_loss: 2.8542 - fy_loss: 2.8677 - u0_loss: 0.2835 - v0_loss: 0.3027 - baseline_loss: 8.8554 - disparity_loss: 1.8052 - x_loss: 8.8384 - y_loss: 0.2835 - z_loss: 0.6652 - pitch_loss: 3.9018 - xWorld_loss: 386.7461 - yWorld_loss: 2.8551 - zWorld_loss: 477.2975 - val_loss: 772.7341 - val_fx_loss: 5.9615 - val_fy_loss: 5.3400 - val_u0_loss: 3.5412 - val_v0_loss: 3.7722 - val_baseline_loss: 13.1764 - val_disparity_loss: 2.3000 - val_x_loss: 9.8729 - val_y_loss: 0.2563 - val_z_loss: 0.6677 - val_pitch_loss: 3.0153 - val_xWorld_loss: 294.8677 - val_yWorld_loss: 2.8592 - val_zWorld_loss: 427.0915\n",
      "Epoch 9/200\n",
      "86111/86111 [==============================] - 830s 10ms/sample - loss: 890.3752 - fx_loss: 2.1711 - fy_loss: 2.1769 - u0_loss: 0.2546 - v0_loss: 0.2717 - baseline_loss: 6.5335 - disparity_loss: 1.7488 - x_loss: 6.5340 - y_loss: 0.2250 - z_loss: 0.6652 - pitch_loss: 2.8965 - xWorld_loss: 386.7443 - yWorld_loss: 2.8551 - zWorld_loss: 477.2946 - val_loss: 834.2756 - val_fx_loss: 13.6347 - val_fy_loss: 13.2714 - val_u0_loss: 12.7144 - val_v0_loss: 12.3663 - val_baseline_loss: 30.8324 - val_disparity_loss: 4.1212 - val_x_loss: 18.6558 - val_y_loss: 0.8299 - val_z_loss: 0.6684 - val_pitch_loss: 2.5740 - val_xWorld_loss: 294.8691 - val_yWorld_loss: 2.8593 - val_zWorld_loss: 427.0645\n",
      "Epoch 10/200\n",
      "86111/86111 [==============================] - 809s 9ms/sample - loss: 887.4726 - fx_loss: 1.8759 - fy_loss: 1.8796 - u0_loss: 0.2256 - v0_loss: 0.2379 - baseline_loss: 5.6736 - disparity_loss: 1.7156 - x_loss: 5.6659 - y_loss: 0.1972 - z_loss: 0.6652 - pitch_loss: 2.4385 - xWorld_loss: 386.7445 - yWorld_loss: 2.8551 - zWorld_loss: 477.2933 - val_loss: 839.9605 - val_fx_loss: 18.0808 - val_fy_loss: 16.3198 - val_u0_loss: 13.6768 - val_v0_loss: 9.3601 - val_baseline_loss: 29.7792 - val_disparity_loss: 4.7434 - val_x_loss: 17.8181 - val_y_loss: 0.2540 - val_z_loss: 0.6678 - val_pitch_loss: 4.4255 - val_xWorld_loss: 294.8804 - val_yWorld_loss: 2.8594 - val_zWorld_loss: 427.0652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "86111/86111 [==============================] - 810s 9ms/sample - loss: 887.1838 - fx_loss: 1.8572 - fy_loss: 1.8562 - u0_loss: 0.2239 - v0_loss: 0.2345 - baseline_loss: 5.5767 - disparity_loss: 1.7104 - x_loss: 5.5649 - y_loss: 0.1985 - z_loss: 0.6651 - pitch_loss: 2.3986 - xWorld_loss: 386.7446 - yWorld_loss: 2.8551 - zWorld_loss: 477.2958 - val_loss: 957.0209 - val_fx_loss: 36.8610 - val_fy_loss: 35.1431 - val_u0_loss: 17.6052 - val_v0_loss: 18.2841 - val_baseline_loss: 66.3628 - val_disparity_loss: 7.9166 - val_x_loss: 45.1315 - val_y_loss: 1.4699 - val_z_loss: 0.6683 - val_pitch_loss: 2.8547 - val_xWorld_loss: 294.8619 - val_yWorld_loss: 2.8594 - val_zWorld_loss: 427.0438\n",
      "Epoch 12/200\n",
      "86111/86111 [==============================] - 809s 9ms/sample - loss: 884.0795 - fx_loss: 1.4956 - fy_loss: 1.4901 - u0_loss: 0.2031 - v0_loss: 0.1983 - baseline_loss: 4.6490 - disparity_loss: 1.6713 - x_loss: 4.6448 - y_loss: 0.1585 - z_loss: 0.6652 - pitch_loss: 2.0059 - xWorld_loss: 386.7443 - yWorld_loss: 2.8551 - zWorld_loss: 477.2933 - val_loss: 1207.2680 - val_fx_loss: 82.8685 - val_fy_loss: 74.7182 - val_u0_loss: 39.0125 - val_v0_loss: 41.8833 - val_baseline_loss: 134.3178 - val_disparity_loss: 12.0900 - val_x_loss: 89.5417 - val_y_loss: 4.8504 - val_z_loss: 0.6679 - val_pitch_loss: 2.4160 - val_xWorld_loss: 294.8402 - val_yWorld_loss: 2.8593 - val_zWorld_loss: 427.0474\n",
      "Epoch 13/200\n",
      "86111/86111 [==============================] - ETA: 0s - loss: 882.1640 - fx_loss: 1.3365 - fy_loss: 1.3413 - u0_loss: 0.2045 - v0_loss: 0.2076 - baseline_loss: 3.9938 - disparity_loss: 1.6296 - x_loss: 3.9875 - y_loss: 0.1494 - z_loss: 0.6651 - pitch_loss: 1.7510 - xWorld_loss: 386.7464 - yWorld_loss: 2.8551 - zWorld_loss: 477.2946Restoring model weights from the end of the best epoch.\n",
      "86111/86111 [==============================] - 831s 10ms/sample - loss: 882.1640 - fx_loss: 1.3365 - fy_loss: 1.3413 - u0_loss: 0.2045 - v0_loss: 0.2076 - baseline_loss: 3.9938 - disparity_loss: 1.6296 - x_loss: 3.9875 - y_loss: 0.1494 - z_loss: 0.6651 - pitch_loss: 1.7510 - xWorld_loss: 386.7464 - yWorld_loss: 2.8551 - zWorld_loss: 477.2946 - val_loss: 902.6400 - val_fx_loss: 28.0487 - val_fy_loss: 26.0782 - val_u0_loss: 18.6397 - val_v0_loss: 18.4863 - val_baseline_loss: 48.6741 - val_disparity_loss: 5.3672 - val_x_loss: 24.8594 - val_y_loss: 0.7949 - val_z_loss: 0.6685 - val_pitch_loss: 6.1710 - val_xWorld_loss: 294.8689 - val_yWorld_loss: 2.8594 - val_zWorld_loss: 427.0520\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "#from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "model_name = 'model_multi_class/'\n",
    "SAVE = \"new_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "# Save\n",
    "output_folder = SAVE + model_name\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "output_log = output_folder + \"Log/\"\n",
    "if not os.path.exists(output_log):\n",
    "    os.makedirs(output_log)\n",
    "\n",
    "output_weight = output_folder + \"Best/\"\n",
    "if not os.path.exists(output_weight):\n",
    "    os.makedirs(output_weight)\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=output_log)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=output_weight + \"weights_{epoch:02d}_{val_loss:.2f}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[Left_images[:int(len(Left_images)*0.7)], Right_images[:int(len(Left_images)*0.7)]],\n",
    "    y=[Fx[:int(len(Left_images)*0.7)], Fy[:int(len(Left_images)*0.7)], U0[:int(len(Left_images)*0.7)], V0[:int(len(Left_images)*0.7)], Baseline[:int(len(Left_images)*0.7)], Disparity[:int(len(Left_images)*0.7)], Tx[:int(len(Left_images)*0.7)], Ty[:int(len(Left_images)*0.7)], Tz[:int(len(Left_images)*0.7)], Pitch[:int(len(Left_images)*0.7)], X[:int(len(Left_images)*0.7)], Y[:int(len(Left_images)*0.7)], Z[:int(len(Left_images)*0.7)]],\n",
    "    batch_size=16,\n",
    "    epochs=200,\n",
    "    verbose=1,\n",
    "    shuffle=True,\n",
    "    initial_epoch=0,\n",
    "    validation_data=([Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]], [Fx[int(len(Left_images)*0.7):], Fy[int(len(Left_images)*0.7):], U0[int(len(Left_images)*0.7):], V0[int(len(Left_images)*0.7):], Baseline[int(len(Left_images)*0.7):], Disparity[int(len(Left_images)*0.7):], Tx[int(len(Left_images)*0.7):], Ty[int(len(Left_images)*0.7):], Tz[int(len(Left_images)*0.7):], Pitch[int(len(Left_images)*0.7):], X[int(len(Left_images)*0.7):], Y[int(len(Left_images)*0.7):], Z[int(len(Left_images)*0.7):]]),\n",
    "    callbacks=[tensorboard, checkpointer, early_stopping, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.callbacks import TensorBoard, LearningRateScheduler\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "from utils_regressor_focal_dist import RotNetDataGenerator, angle_error, CustomModelCheckpoint\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import glob, math\n",
    "from shutil import copyfile\n",
    "import datetime, random\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "\n",
    "model.load_weights('./new_logs/20221214-113705/model_multi_class/Best/weights_08_772.73.h5')\n",
    "\n",
    "\n",
    "\n",
    "input_shape = (112, 112, 3)\n",
    "\n",
    "\n",
    "output = model.predict(\n",
    "    x=[Left_images[int(len(Left_images)*0.7):], Right_images[int(len(Left_images)*0.7):]],\n",
    "    batch_size=16,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23796, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, '% Correct')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "th_0 = 0\n",
    "th_1 = 0\n",
    "th_2 = 0\n",
    "th_3 = 0\n",
    "th_4 = 0\n",
    "th_5 = 0\n",
    "\n",
    "percent_correct = []\n",
    "\n",
    "k = 86111\n",
    "\n",
    "for i  in range(np.shape(output)[1]):\n",
    "    \n",
    "    predicted_fov = 2*np.arctan(112/(2*output[0][i][0]))\n",
    "    actual_fov = 2*np.arctan(112/(2*Fx[k]))\n",
    "    \n",
    "    if abs(predicted_fov - actual_fov) <= 0:\n",
    "        \n",
    "        th_0 += 1 \n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 1:\n",
    "        \n",
    "        th_1 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 2:\n",
    "        \n",
    "        th_2 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 3:\n",
    "        \n",
    "        th_3 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 4:\n",
    "        \n",
    "        th_4 += 1\n",
    "        \n",
    "    if abs(predicted_fov - actual_fov) <= 5:\n",
    "        \n",
    "        th_5 += 1\n",
    "        \n",
    "    k += 1\n",
    "\n",
    "percent_correct.append(th_0/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_1/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_2/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_3/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_4/np.shape(output)[1]*100)\n",
    "percent_correct.append(th_5/np.shape(output)[1]*100)\n",
    "\n",
    "plt.plot([0,1,2,3,4,5],percent_correct)\n",
    "plt.xlabel(\"FOV Error Threshold (degrees)\")\n",
    "plt.ylabel(\"% Correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 36616, 36906, 36906, 36906, 36906)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0, th_1, th_2, th_3, th_4, th_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.9921421991004172, 1.0, 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th_0/np.shape(output)[1], th_1/np.shape(output)[1], th_2/np.shape(output)[1], th_3/np.shape(output)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 1.9435690568003283, 'fy': 1.8801497877873317, 'u0': 0.2296023047417227, 'v0': 0.37571040063891054, 'baseline': 0.29330045409885086, 'disparity': 0.040379390242220085, 'x': 0.3047712246025885, 'y': 0.38303970816175886, 'z': 0.28045512941489203, 'pitch': 1.4408267310215137, 'xworld': 31.613377053173448, 'yworld': 25.092866140117593, 'zworld': 42.71013880363322}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1124.5992"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(output[0])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math \n",
    "\n",
    "def normalize(x):\n",
    "    \n",
    "    return (math.atan(x) + 3.14/2) / 3.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.684497496430667, 'fy': 0.6713817717857442, 'u0': 0.5705035358475947, 'v0': 0.6118069484633926, 'baseline': 0.5626533126677936, 'disparity': 0.5113574002642848, 'x': 0.5665639359234423, 'y': 0.5831061090361146, 'z': 0.5675817035001748, 'pitch': 0.7123594741106813, 'xworld': 0.9745200899244825, 'yworld': 0.9819812579767454, 'zworld': 0.9770998745414592}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fx - actual_fx))\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_fy - actual_fy))\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_u0 - actual_u0))\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_v0 - actual_v0))\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_baseline - actual_baseline))\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_disparity - actual_disparity))\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tx - actual_tx))\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_ty - actual_ty))\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_tz - actual_tz))\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_pitch - actual_pitch))\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_x - actual_x))\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_y - actual_y))\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += normalize(abs(predicted_z - actual_z))\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.0006045328123734624, 'fy': 0.000916591329541554, 'u0': 0.00010536181074296743, 'v0': 0.00015748116198789617, 'baseline': 0.012927798122878219, 'disparity': 0.0002999877035648339, 'x': 0.01343350695203612, 'y': 0.011566271694155127, 'z': 0.016303638032724194, 'pitch': 0.0003199657518740856, 'xworld': 0.08180485648251173, 'yworld': 0.01367320664940879, 'zworld': 0.12592455279078085}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "min_fx = 1.9073486e-06\n",
    "max_fx = 3214.9907\n",
    "\n",
    "min_fy = 2.9563904e-05\n",
    "max_fy = 2051.209\n",
    "\n",
    "min_u0 = 1.9073486e-05\n",
    "max_u0 = 2178.9983\n",
    "\n",
    "min_v0 = 3.8146973e-06\n",
    "max_v0 = 2385.7239\n",
    "\n",
    "min_baseline = 4.7683716e-06\n",
    "max_baseline = 22.68721567997021\n",
    "\n",
    "min_disparity = 9.536743e-07\n",
    "max_disparity = 134.60031\n",
    "\n",
    "min_tx = 2.384185791015625e-06\n",
    "max_tx = 22.68721567997021\n",
    "\n",
    "min_ty = 2.3841858e-07\n",
    "max_ty = 33.11693576309983\n",
    "\n",
    "min_tz = 2.3841858e-06\n",
    "max_tz = 17.20185265614626\n",
    "\n",
    "min_pitch = 4.57763671875e-05\n",
    "max_pitch = 4502.9224\n",
    "\n",
    "min_xw = 5.219264654243716e-06\n",
    "max_xw = 386.4486\n",
    "\n",
    "min_yw = 3.8146973e-06\n",
    "max_yw = 1835.1849\n",
    "\n",
    "min_zw = 0.00011349\n",
    "max_zw = 339.17166\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 55524\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fx - actual_fx) - min_fx)/(max_fx - min_fx)\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_fy - actual_fy) - min_fy)/(max_fy - min_fy)\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_u0 - actual_u0) - min_u0)/(max_u0 - min_u0)\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_v0 - actual_v0) - min_v0)/(max_v0 - min_v0)\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_baseline - actual_baseline) - min_baseline)/(max_baseline - min_baseline)\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_disparity - actual_disparity) - min_disparity)/(max_disparity - min_disparity)\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tx - actual_tx) - min_tx)/(max_tx - min_tx)\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_ty - actual_ty) - min_ty)/(max_ty - min_ty)\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_tz - actual_tz) - min_tz)/(max_tz - min_tz)\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_pitch - actual_pitch) - min_pitch)/(max_pitch - min_pitch)\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_x - actual_x) - min_xw)/(max_xw - min_xw)\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_y - actual_y) - min_yw)/(max_yw - min_yw)\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += (abs(predicted_z - actual_z) - min_zw)/(max_zw - min_zw)\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fx': 0.10050679804813027, 'fy': 0.09002908984656888, 'u0': 0.06324488649820799, 'v0': 0.06737065062931312, 'baseline': -0.15687149331138522, 'disparity': -0.20961895565345692, 'x': -0.11754179379199736, 'y': 0.5863262634261561, 'z': -1.1579805405220696, 'pitch': -0.24357299386511252, 'xworld': -3.207166548449957, 'yworld': 6.539443514904524, 'zworld': 9.600002824296283}\n"
     ]
    }
   ],
   "source": [
    "error = {}\n",
    "\n",
    "error[\"fx\"] = 0\n",
    "error[\"fy\"] = 0\n",
    "error[\"u0\"] = 0\n",
    "error[\"v0\"] = 0\n",
    "error[\"baseline\"] = 0\n",
    "error[\"disparity\"] = 0\n",
    "error[\"x\"] = 0\n",
    "error[\"y\"] = 0\n",
    "error[\"z\"] = 0\n",
    "error[\"pitch\"] = 0\n",
    "error[\"xworld\"] = 0\n",
    "error[\"yworld\"] = 0\n",
    "error[\"zworld\"] = 0\n",
    "\n",
    "mean_fx = 59.32098482132037\n",
    "\n",
    "mean_fy = 59.32098482132037\n",
    "\n",
    "mean_u0 = 56.0\n",
    "\n",
    "mean_v0 = 56.0\n",
    "\n",
    "mean_baseline = -84.00701782907929\n",
    "\n",
    "mean_disparity = -10.972388226877689\n",
    "\n",
    "mean_tx = -84.00701782907929\n",
    "\n",
    "mean_ty = 0.4372459762640221\n",
    "\n",
    "mean_tz = -0.5766162683574485\n",
    "\n",
    "mean_pitch = -12.380371755270145\n",
    "\n",
    "mean_xw = -91.94288567681566\n",
    "\n",
    "mean_yw = 0.4372459762640221\n",
    "\n",
    "mean_zw = 44.48843272766856\n",
    "\n",
    "key_counter = 0\n",
    "\n",
    "for i in error.keys():\n",
    "    \n",
    "    k = 86111\n",
    "\n",
    "    for j  in range(np.shape(output)[1]):\n",
    "        \n",
    "        if key_counter == 0: \n",
    "    \n",
    "            predicted_fx = output[key_counter][j][0]\n",
    "            actual_fx = Fx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fx - actual_fx) / mean_fx\n",
    "        \n",
    "        if key_counter == 1: \n",
    "    \n",
    "            predicted_fy = output[key_counter][j][0]\n",
    "            actual_fy = Fy[k]\n",
    "    \n",
    "            error[i] += abs(predicted_fy - actual_fy) / mean_fy\n",
    "        \n",
    "        if key_counter == 2: \n",
    "    \n",
    "            predicted_u0 = output[key_counter][j][0]\n",
    "            actual_u0 = U0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_u0 - actual_u0) / mean_u0\n",
    "        \n",
    "        if key_counter == 3: \n",
    "    \n",
    "            predicted_v0 = output[key_counter][j][0]\n",
    "            actual_v0 = V0[k]\n",
    "    \n",
    "            error[i] += abs(predicted_v0 - actual_v0) / mean_v0\n",
    "        \n",
    "        if key_counter == 4: \n",
    "    \n",
    "            predicted_baseline = output[key_counter][j][0]\n",
    "            actual_baseline = Baseline[k]\n",
    "    \n",
    "            error[i] += abs(predicted_baseline - actual_baseline) / mean_baseline\n",
    "        \n",
    "        if key_counter == 5: \n",
    "    \n",
    "            predicted_disparity = output[key_counter][j][0]\n",
    "            actual_disparity = Disparity[k]\n",
    "    \n",
    "            error[i] += abs(predicted_disparity - actual_disparity) / mean_disparity\n",
    "        \n",
    "        if key_counter == 6: \n",
    "    \n",
    "            predicted_tx = output[key_counter][j][0]\n",
    "            actual_tx = Tx[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tx - actual_tx) / mean_tx\n",
    "        \n",
    "        if key_counter == 7: \n",
    "    \n",
    "            predicted_ty = output[key_counter][j][0]\n",
    "            actual_ty = Ty[k]\n",
    "    \n",
    "            error[i] += abs(predicted_ty - actual_ty) / mean_ty\n",
    "        \n",
    "        if key_counter == 8: \n",
    "    \n",
    "            predicted_tz = output[key_counter][j][0]\n",
    "            actual_tz = Tz[k]\n",
    "    \n",
    "            error[i] += abs(predicted_tz - actual_tz) / mean_tz\n",
    "        \n",
    "        if key_counter == 9: \n",
    "    \n",
    "            predicted_pitch = output[key_counter][j][0]\n",
    "            actual_pitch = Pitch[k]\n",
    "    \n",
    "            error[i] += abs(predicted_pitch - actual_pitch) / mean_pitch\n",
    "        \n",
    "        if key_counter == 10: \n",
    "    \n",
    "            predicted_x = output[key_counter][j][0]\n",
    "            actual_x = X[k]\n",
    "    \n",
    "            error[i] += abs(predicted_x - actual_x) / mean_xw\n",
    "        \n",
    "        if key_counter == 11: \n",
    "    \n",
    "            predicted_y = output[key_counter][j][0]\n",
    "            actual_y = Y[k]\n",
    "    \n",
    "            error[i] += abs(predicted_y - actual_y) / mean_yw\n",
    "        \n",
    "        if key_counter == 12: \n",
    "    \n",
    "            predicted_z = output[key_counter][j][0]\n",
    "            actual_z = Z[k]\n",
    "    \n",
    "            error[i] += abs(predicted_z - actual_z) / mean_zw\n",
    "        \n",
    "        k += 1\n",
    "    \n",
    "    \n",
    "    error[i] /= np.shape(output)[1]\n",
    "    \n",
    "    key_counter += 1\n",
    "\n",
    "print (error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 23796, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79320"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401.2137982147371"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(error.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
